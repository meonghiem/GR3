{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "scaler = MinMaxScaler()\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN, LSTM, TimeDistributed, Input, Dropout, GRU\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from keras.saving import register_keras_serializable\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0, len(dataset)-2 *look_back+1, look_back):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back: i+ 2*look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def exponential_moving_average(data, span):\n",
    "    return data.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def read_data(file_path, num_features = 1):\n",
    "    from pandas import read_csv\n",
    "    series_influ_A_df = read_csv(file_path, index_col=0, engine='python')\n",
    "    series_influ_A_df = series_influ_A_df.rename(columns= {\"Influenza A - All types of surveillance\": \"case\"})\n",
    "    series_influ_A_df = series_influ_A_df[[\"case\", \"humidity\", \"temp\", \"dew\",\"windspeed\", \"tempmax\",][:num_features]]\n",
    "    return series_influ_A_df.dropna()\n",
    "\n",
    "def prepare_data(series, look_back, scaler, is_ema = False):\n",
    "    if is_ema:\n",
    "        span = 52  # Bạn có thể điều chỉnh độ dài span tùy ý\n",
    "        series['case'] = exponential_moving_average(series['case'], span)\n",
    "    series = series.astype('float32')\n",
    "    series = series.values\n",
    "    if scaler is not None:\n",
    "        flattened_dataset = series.flatten()\n",
    "        dataset = scaler.fit_transform(flattened_dataset.reshape(-1,1))\n",
    "        dataset = dataset.reshape(series.shape)\n",
    "\n",
    "    else: \n",
    "        dataset = series\n",
    "\n",
    "    rest = len(dataset) % look_back\n",
    "    dataset = dataset[rest:, :]\n",
    "    trainsize = len(dataset) - look_back\n",
    "    train = dataset[:trainsize, :]\n",
    "    test = dataset[trainsize - look_back:, :]\n",
    "\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "def forecast(input, model):\n",
    "    predicted = model.predict(input, verbose=0)\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def save_plot(x,y, file_path):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy import stats\n",
    "\n",
    "    # Generate some sample data\n",
    "    # x = y_inverse.flatten()\n",
    "    # y = y_hat_inverse.flatten()\n",
    "\n",
    "    # Compute the linear regression line\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    # Create the R-squared line\n",
    "    r2_line = slope * x + intercept\n",
    "    r2 = r2_score(x, y)\n",
    "    r2_pearson = r_value**2\n",
    "    squared_error = np.square(x-y)\n",
    "\n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(x, y, label='Data Points')\n",
    "    plt.plot(x, squared_error, color='red', marker=\"o\", label=f'squared Error (R²={r2:.2f})')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('actual number of infection')\n",
    "    plt.ylabel('forecast number of infection')\n",
    "    plt.title('Scatter Plot with R-squared Line')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "\n",
    "def inverse_transform(data, scaler):\n",
    "    flattened_data = data.flatten()\n",
    "    inverse_flattened_data = scaler.inverse_transform(flattened_data.reshape(-1,1))\n",
    "    return inverse_flattened_data.reshape(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class MyLSTM (Sequential):\n",
    "    def __init__(self, look_back, dense_units =[],unit=64, optimizer='adam',name='lstm'):\n",
    "        super().__init__(name=name)\n",
    "        self.look_back = look_back\n",
    "        self.add(Input(shape=(look_back,1)))\n",
    "        self.add(LSTM(units=unit, activation='relu', return_sequences=True))\n",
    "        for unit in dense_units:\n",
    "            self.add(Dense(units=unit, activation='relu'))\n",
    "        self.add(TimeDistributed(Dense(units=5, activation='sigmoid' )))\n",
    "        self.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "\n",
    "def build_model(input_shape, dropout=None, dense_units = [], unit=64, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    #Encoder:\n",
    "    # First LSTM layer with Dropout regularisation\n",
    "    model.add(LSTM(units=dense_units[0], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(units=dense_units[1], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Third LSTM layer\n",
    "    model.add(LSTM(units=dense_units[2], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Decoder\n",
    "    # Fourth GRU layer\n",
    "    model.add(GRU(units=dense_units[2], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(GRU(units=dense_units[1], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Fourth GRU layer\n",
    "    model.add(GRU(units=dense_units[0], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # if first_additional_layer:\n",
    "    #     model.add(LSTM(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "\n",
    "    # if second_additional_layer:\n",
    "    #     model.add(LSTM(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "\n",
    "    # if third_additional_layer:\n",
    "    #     model.add(GRU(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "    model.add(TimeDistributed(Dense(units=input_shape[1], activation='sigmoid' )))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(testY, forecasts):\n",
    "    import matplotlib.pyplot as plt\n",
    "    forecastsPlot = forecasts[:,:,0].reshape(-1)\n",
    "    testPlot = testY[:,:,0].reshape(-1)\n",
    "    plt.plot(testPlot, \"-y\", label=\"actual\", marker= '.')\n",
    "    plt.plot(forecastsPlot, color = 'green',marker='x', label=\"forecast\")\n",
    "    plt.ylabel(\"Number of infections\")\n",
    "    plt.legend([\"actual\", \"forecast\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os, json\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def LSTM_HyperParameter_Tuning(config, df, scaler):\n",
    "    \n",
    "    num_features, layers, n_neurons, n_batch_sizes, dropouts, look_backs, is_emas = config\n",
    "    possible_combinations = list(itertools.product(num_features, layers, n_neurons, n_batch_sizes, dropouts, look_backs, is_emas))\n",
    "    \n",
    "    print(possible_combinations)\n",
    "    print('\\n')\n",
    "    \n",
    "    hist = []\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "        print(f'{i+1}th combination: \\n')\n",
    "        print('--------------------------------------------------------------------')\n",
    "        num_features, layers, n_neurons, n_batch_size, dropout, look_back, is_ema = possible_combinations[i]\n",
    "\n",
    "        df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=num_features)\n",
    "        \n",
    "        trainX, trainY, testX, testY = prepare_data(df, look_back, scaler, is_ema=is_ema)\n",
    "        model = build_model(\n",
    "            input_shape=(trainX.shape[1], trainX.shape[2]),\n",
    "            # first_additional_layer= layers[0],\n",
    "            # second_additional_layer=layers[1],\n",
    "            # third_additional_layer=layers[2],\n",
    "            dense_units=n_neurons[1:],\n",
    "            unit=n_neurons[0])\n",
    "\n",
    "        es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "        '''''\n",
    "        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n",
    "        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n",
    "        '''''\n",
    "        a = 'ema' if is_ema else 'not_ema'\n",
    "        lstm_dir = os.path.join(\"../result\", f\"\"\"lstmA_gruE_{a}\"\"\")\n",
    "        lstm_combination_dir = os.path.join(lstm_dir, str(i))\n",
    "        os.makedirs(lstm_combination_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(lstm_combination_dir, 'best_lstm_m2m_model.keras')\n",
    "\n",
    "        mc = ModelCheckpoint(file_path, monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "        '''''\n",
    "        cb = Callback(...)  # First, callbacks must be instantiated.\n",
    "        cb_list = [cb, ...]  # Then, one or more callbacks that you intend to use must be added to a Python list.\n",
    "        model.fit(..., callbacks=cb_list)  # Finally, the list of callbacks is provided to the callback argument when fitting the model.\n",
    "        '''''\n",
    "\n",
    "        model.fit(trainX, trainY,batch_size=n_batch_size, callbacks=[es, mc], verbose=0, epochs=200)\n",
    "        train_accuracy = model.evaluate(trainX, trainY, verbose=0)\n",
    "        # test_accuracy = model.evaluate(testX, testY, verbose=0)\n",
    "        # hist.append(list((n_neurons, n_batch_size, dropout,look_back,\n",
    "        #                   train_accuracy, test_accuracy)))\n",
    "        hist.append(list((n_neurons, n_batch_size, dropout,look_back,\n",
    "                          train_accuracy)))\n",
    "        \n",
    "        \n",
    "        config= {\n",
    "            \"num_features\": num_features,\n",
    "            \"layers\": layers,\n",
    "            \"units\": n_neurons,\n",
    "            \"n_batch_size\": n_batch_size,\n",
    "            \"dropout\": dropout,\n",
    "            \"look_back\": look_back,\n",
    "            \"is_ema\": is_ema\n",
    "        }\n",
    "        with open(os.path.join(lstm_combination_dir,'config.json'), 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "        \n",
    "\n",
    "        # print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy}')\n",
    "        \n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "\n",
    "        num_features, layers, n_neurons, n_batch_size, dropout, look_back, is_ema = possible_combinations[i]\n",
    "        df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=num_features)\n",
    "        trainX, trainY, testX, testY = prepare_data(df, look_back, scaler, is_ema=is_ema)\n",
    "\n",
    "        a = 'ema' if is_ema else 'not_ema'\n",
    "        lstm_dir = os.path.join(\"../result\", f\"\"\"lstmA_gruE_{a}\"\"\")\n",
    "        lstm_combination_dir = os.path.join(lstm_dir, str(i))\n",
    "        os.makedirs(lstm_combination_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(lstm_combination_dir, 'best_lstm_m2m_model.keras')\n",
    "\n",
    "\n",
    "        model = load_model(file_path)\n",
    "\n",
    "        #TODO: save r square\n",
    "        testY_hat = forecast(testX, model)\n",
    "        y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "        y_inverse = inverse_transform(testY, scaler)\n",
    "\n",
    "        r2_image_path = os.path.join(lstm_combination_dir, 'r2_image.png')\n",
    "        save_plot(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten(), r2_image_path)\n",
    "        \n",
    "    import pandas as pd\n",
    "    hist_df = pd.DataFrame(hist)\n",
    "    hist_df = hist_df.rename(columns={0: 'units', 1: 'batch_size', 2: 'dropout', 3: 'look_back', 4: 'train_loss'})\n",
    "    hist_df = hist_df.sort_values(by=['train_loss'], ascending=True)\n",
    "    hist_df.to_csv(os.path.join(lstm_dir, 'history.csv'))\n",
    "    return hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, [False, True, True], [64, 64, 32, 16], 1, 0.2, 10, True), (1, [False, True, True], [64, 64, 32, 16], 1, 0.2, 12, True), (1, [False, True, True], [64, 64, 32, 16], 1, 0.2, 15, True), (1, [False, True, True], [64, 64, 32, 16], 1, 0.2, 17, True), (1, [False, True, True], [64, 64, 32, 16], 2, 0.2, 10, True), (1, [False, True, True], [64, 64, 32, 16], 2, 0.2, 12, True), (1, [False, True, True], [64, 64, 32, 16], 2, 0.2, 15, True), (1, [False, True, True], [64, 64, 32, 16], 2, 0.2, 17, True), (1, [False, True, True], [64, 64, 32, 16], 4, 0.2, 10, True), (1, [False, True, True], [64, 64, 32, 16], 4, 0.2, 12, True), (1, [False, True, True], [64, 64, 32, 16], 4, 0.2, 15, True), (1, [False, True, True], [64, 64, 32, 16], 4, 0.2, 17, True), (1, [False, True, True], [64, 64, 32, 16], 8, 0.2, 10, True), (1, [False, True, True], [64, 64, 32, 16], 8, 0.2, 12, True), (1, [False, True, True], [64, 64, 32, 16], 8, 0.2, 15, True), (1, [False, True, True], [64, 64, 32, 16], 8, 0.2, 17, True), (1, [False, True, True], [64, 128, 64, 32], 1, 0.2, 10, True), (1, [False, True, True], [64, 128, 64, 32], 1, 0.2, 12, True), (1, [False, True, True], [64, 128, 64, 32], 1, 0.2, 15, True), (1, [False, True, True], [64, 128, 64, 32], 1, 0.2, 17, True), (1, [False, True, True], [64, 128, 64, 32], 2, 0.2, 10, True), (1, [False, True, True], [64, 128, 64, 32], 2, 0.2, 12, True), (1, [False, True, True], [64, 128, 64, 32], 2, 0.2, 15, True), (1, [False, True, True], [64, 128, 64, 32], 2, 0.2, 17, True), (1, [False, True, True], [64, 128, 64, 32], 4, 0.2, 10, True), (1, [False, True, True], [64, 128, 64, 32], 4, 0.2, 12, True), (1, [False, True, True], [64, 128, 64, 32], 4, 0.2, 15, True), (1, [False, True, True], [64, 128, 64, 32], 4, 0.2, 17, True), (1, [False, True, True], [64, 128, 64, 32], 8, 0.2, 10, True), (1, [False, True, True], [64, 128, 64, 32], 8, 0.2, 12, True), (1, [False, True, True], [64, 128, 64, 32], 8, 0.2, 15, True), (1, [False, True, True], [64, 128, 64, 32], 8, 0.2, 17, True), (2, [False, True, True], [64, 64, 32, 16], 1, 0.2, 10, True), (2, [False, True, True], [64, 64, 32, 16], 1, 0.2, 12, True), (2, [False, True, True], [64, 64, 32, 16], 1, 0.2, 15, True), (2, [False, True, True], [64, 64, 32, 16], 1, 0.2, 17, True), (2, [False, True, True], [64, 64, 32, 16], 2, 0.2, 10, True), (2, [False, True, True], [64, 64, 32, 16], 2, 0.2, 12, True), (2, [False, True, True], [64, 64, 32, 16], 2, 0.2, 15, True), (2, [False, True, True], [64, 64, 32, 16], 2, 0.2, 17, True), (2, [False, True, True], [64, 64, 32, 16], 4, 0.2, 10, True), (2, [False, True, True], [64, 64, 32, 16], 4, 0.2, 12, True), (2, [False, True, True], [64, 64, 32, 16], 4, 0.2, 15, True), (2, [False, True, True], [64, 64, 32, 16], 4, 0.2, 17, True), (2, [False, True, True], [64, 64, 32, 16], 8, 0.2, 10, True), (2, [False, True, True], [64, 64, 32, 16], 8, 0.2, 12, True), (2, [False, True, True], [64, 64, 32, 16], 8, 0.2, 15, True), (2, [False, True, True], [64, 64, 32, 16], 8, 0.2, 17, True), (2, [False, True, True], [64, 128, 64, 32], 1, 0.2, 10, True), (2, [False, True, True], [64, 128, 64, 32], 1, 0.2, 12, True), (2, [False, True, True], [64, 128, 64, 32], 1, 0.2, 15, True), (2, [False, True, True], [64, 128, 64, 32], 1, 0.2, 17, True), (2, [False, True, True], [64, 128, 64, 32], 2, 0.2, 10, True), (2, [False, True, True], [64, 128, 64, 32], 2, 0.2, 12, True), (2, [False, True, True], [64, 128, 64, 32], 2, 0.2, 15, True), (2, [False, True, True], [64, 128, 64, 32], 2, 0.2, 17, True), (2, [False, True, True], [64, 128, 64, 32], 4, 0.2, 10, True), (2, [False, True, True], [64, 128, 64, 32], 4, 0.2, 12, True), (2, [False, True, True], [64, 128, 64, 32], 4, 0.2, 15, True), (2, [False, True, True], [64, 128, 64, 32], 4, 0.2, 17, True), (2, [False, True, True], [64, 128, 64, 32], 8, 0.2, 10, True), (2, [False, True, True], [64, 128, 64, 32], 8, 0.2, 12, True), (2, [False, True, True], [64, 128, 64, 32], 8, 0.2, 15, True), (2, [False, True, True], [64, 128, 64, 32], 8, 0.2, 17, True)]\n",
      "\n",
      "\n",
      "1th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05302, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05302 to 0.04008, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04008 to 0.03402, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03402 to 0.03102, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03102 to 0.03079, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03079 to 0.02621, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02621 to 0.02594, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02594 to 0.02169, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02169 to 0.02046, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02046 to 0.01733, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.01733\n",
      "\n",
      "Epoch 12: loss improved from 0.01733 to 0.01724, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01724\n",
      "\n",
      "Epoch 14: loss improved from 0.01724 to 0.01707, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01707 to 0.01530, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01530\n",
      "\n",
      "Epoch 17: loss improved from 0.01530 to 0.01431, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01431\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01431\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01431\n",
      "\n",
      "Epoch 21: loss improved from 0.01431 to 0.01425, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01425 to 0.01338, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01338\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01338\n",
      "\n",
      "Epoch 25: loss improved from 0.01338 to 0.01335, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01335\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01335\n",
      "\n",
      "Epoch 28: loss improved from 0.01335 to 0.01223, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01223\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01223\n",
      "\n",
      "Epoch 31: loss improved from 0.01223 to 0.01205, saving model to ../result\\lstmA_gruE_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01205\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01205\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01205\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01205\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01205\n",
      "Epoch 36: early stopping\n",
      "2th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05050, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05050 to 0.03790, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03790 to 0.03397, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03397 to 0.03062, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03062 to 0.02925, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02925 to 0.02760, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.02760\n",
      "\n",
      "Epoch 8: loss improved from 0.02760 to 0.02427, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02427 to 0.02231, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02231\n",
      "\n",
      "Epoch 11: loss improved from 0.02231 to 0.02079, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02079 to 0.01924, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01924\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01924\n",
      "\n",
      "Epoch 15: loss improved from 0.01924 to 0.01726, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01726\n",
      "\n",
      "Epoch 17: loss improved from 0.01726 to 0.01648, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01648 to 0.01639, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01639\n",
      "\n",
      "Epoch 20: loss improved from 0.01639 to 0.01602, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01602 to 0.01497, saving model to ../result\\lstmA_gruE_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01497\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01497\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01497\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01497\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01497\n",
      "Epoch 26: early stopping\n",
      "3th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05780, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05780 to 0.04066, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04066 to 0.03747, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03747 to 0.03358, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03358 to 0.03307, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.03307\n",
      "\n",
      "Epoch 7: loss improved from 0.03307 to 0.02983, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02983 to 0.02880, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02880 to 0.02868, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02868 to 0.02524, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02524 to 0.02470, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02470 to 0.02435, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02435 to 0.02227, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02227 to 0.02158, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02158\n",
      "\n",
      "Epoch 16: loss improved from 0.02158 to 0.01970, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01970 to 0.01931, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01931\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01931\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01931\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01931\n",
      "\n",
      "Epoch 22: loss improved from 0.01931 to 0.01880, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01880\n",
      "\n",
      "Epoch 24: loss improved from 0.01880 to 0.01809, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01809\n",
      "\n",
      "Epoch 26: loss improved from 0.01809 to 0.01778, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01778\n",
      "\n",
      "Epoch 28: loss improved from 0.01778 to 0.01708, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01708\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01708\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01708\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01708\n",
      "\n",
      "Epoch 33: loss improved from 0.01708 to 0.01626, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01626\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01626\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01626\n",
      "\n",
      "Epoch 37: loss improved from 0.01626 to 0.01571, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01571\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01571\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01571\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01571\n",
      "\n",
      "Epoch 42: loss improved from 0.01571 to 0.01559, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.01559 to 0.01539, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01539\n",
      "\n",
      "Epoch 45: loss improved from 0.01539 to 0.01493, saving model to ../result\\lstmA_gruE_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 50: loss did not improve from 0.01493\n",
      "Epoch 50: early stopping\n",
      "4th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05585, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05585 to 0.04284, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04284 to 0.03919, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03919 to 0.03721, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03721 to 0.03670, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03670 to 0.03354, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03354 to 0.03340, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03340 to 0.02962, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02962 to 0.02795, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02795\n",
      "\n",
      "Epoch 11: loss improved from 0.02795 to 0.02583, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02583 to 0.02432, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02432\n",
      "\n",
      "Epoch 14: loss improved from 0.02432 to 0.02224, saving model to ../result\\lstmA_gruE_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02224\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02224\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02224\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02224\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02224\n",
      "Epoch 19: early stopping\n",
      "5th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05427, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05427 to 0.04222, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04222 to 0.03475, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03475 to 0.03257, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03257 to 0.03162, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03162 to 0.02989, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02989 to 0.02932, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02932 to 0.02596, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02596 to 0.02434, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02434 to 0.02358, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02358 to 0.02165, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02165\n",
      "\n",
      "Epoch 13: loss improved from 0.02165 to 0.01987, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01987 to 0.01887, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01887\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01887\n",
      "\n",
      "Epoch 17: loss improved from 0.01887 to 0.01725, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01725 to 0.01562, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01562\n",
      "\n",
      "Epoch 20: loss improved from 0.01562 to 0.01460, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01460\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01460\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01460\n",
      "\n",
      "Epoch 24: loss improved from 0.01460 to 0.01418, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01418\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01418\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01418\n",
      "\n",
      "Epoch 28: loss improved from 0.01418 to 0.01381, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01381\n",
      "\n",
      "Epoch 30: loss improved from 0.01381 to 0.01368, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.01368 to 0.01327, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01327\n",
      "\n",
      "Epoch 33: loss improved from 0.01327 to 0.01294, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.01294 to 0.01281, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.01281 to 0.01247, saving model to ../result\\lstmA_gruE_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01247\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01247\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01247\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01247\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01247\n",
      "Epoch 40: early stopping\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000021F06768160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "6th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05770, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05770 to 0.04226, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04226 to 0.03720, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03720 to 0.03365, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03365 to 0.03139, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03139 to 0.02967, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.02967\n",
      "\n",
      "Epoch 8: loss improved from 0.02967 to 0.02867, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02867 to 0.02488, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02488 to 0.02358, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02358\n",
      "\n",
      "Epoch 12: loss improved from 0.02358 to 0.02319, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02319 to 0.02290, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02290 to 0.01935, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01935\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01935\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01935\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01935\n",
      "\n",
      "Epoch 19: loss improved from 0.01935 to 0.01844, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01844 to 0.01825, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01825\n",
      "\n",
      "Epoch 22: loss improved from 0.01825 to 0.01782, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01782 to 0.01699, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01699 to 0.01653, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01653 to 0.01627, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01627 to 0.01399, saving model to ../result\\lstmA_gruE_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01399\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01399\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01399\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01399\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01399\n",
      "Epoch 31: early stopping\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x0000021F18B8BBE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "7th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06175, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06175 to 0.04127, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss did not improve from 0.04127\n",
      "\n",
      "Epoch 4: loss improved from 0.04127 to 0.03717, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03717 to 0.03295, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.03295\n",
      "\n",
      "Epoch 7: loss improved from 0.03295 to 0.03252, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03252 to 0.03050, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03050 to 0.02965, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02965\n",
      "\n",
      "Epoch 11: loss improved from 0.02965 to 0.02838, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02838 to 0.02722, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02722 to 0.02668, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02668 to 0.02496, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02496 to 0.02380, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02380\n",
      "\n",
      "Epoch 17: loss improved from 0.02380 to 0.02175, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02175\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02175\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02175\n",
      "\n",
      "Epoch 21: loss improved from 0.02175 to 0.02065, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02065 to 0.02035, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02035\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02035\n",
      "\n",
      "Epoch 25: loss improved from 0.02035 to 0.01903, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01903\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01903\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01903\n",
      "\n",
      "Epoch 29: loss improved from 0.01903 to 0.01856, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01856\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01856\n",
      "\n",
      "Epoch 32: loss improved from 0.01856 to 0.01844, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01844 to 0.01810, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01810\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01810\n",
      "\n",
      "Epoch 36: loss improved from 0.01810 to 0.01788, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01788\n",
      "\n",
      "Epoch 38: loss improved from 0.01788 to 0.01709, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01709\n",
      "\n",
      "Epoch 40: loss improved from 0.01709 to 0.01705, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.01705 to 0.01654, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01654\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01654\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01654\n",
      "\n",
      "Epoch 45: loss improved from 0.01654 to 0.01596, saving model to ../result\\lstmA_gruE_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01596\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01596\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01596\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01596\n",
      "\n",
      "Epoch 50: loss did not improve from 0.01596\n",
      "Epoch 50: early stopping\n",
      "8th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05870, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05870 to 0.04501, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04501 to 0.03866, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03866 to 0.03738, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03738 to 0.03560, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03560 to 0.03419, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03419 to 0.03384, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03384 to 0.03225, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.03225\n",
      "\n",
      "Epoch 10: loss improved from 0.03225 to 0.03008, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.03008\n",
      "\n",
      "Epoch 12: loss improved from 0.03008 to 0.02783, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02783 to 0.02766, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02766 to 0.02569, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02569 to 0.02563, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02563\n",
      "\n",
      "Epoch 17: loss improved from 0.02563 to 0.02521, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02521\n",
      "\n",
      "Epoch 19: loss improved from 0.02521 to 0.02520, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02520 to 0.02331, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02331 to 0.02183, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02183\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02183\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02183\n",
      "\n",
      "Epoch 25: loss improved from 0.02183 to 0.02159, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02159 to 0.02087, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02087\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02087\n",
      "\n",
      "Epoch 29: loss improved from 0.02087 to 0.02077, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.02077 to 0.02000, saving model to ../result\\lstmA_gruE_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.02000\n",
      "\n",
      "Epoch 32: loss did not improve from 0.02000\n",
      "\n",
      "Epoch 33: loss did not improve from 0.02000\n",
      "\n",
      "Epoch 34: loss did not improve from 0.02000\n",
      "\n",
      "Epoch 35: loss did not improve from 0.02000\n",
      "Epoch 35: early stopping\n",
      "9th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05560, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05560 to 0.04783, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04783 to 0.04116, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04116 to 0.03558, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03558 to 0.03230, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.03230\n",
      "\n",
      "Epoch 7: loss improved from 0.03230 to 0.03022, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.03022\n",
      "\n",
      "Epoch 9: loss improved from 0.03022 to 0.02939, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02939 to 0.02654, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02654 to 0.02630, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02630\n",
      "\n",
      "Epoch 13: loss improved from 0.02630 to 0.02396, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02396 to 0.02233, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02233 to 0.02231, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02231 to 0.02108, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02108 to 0.01928, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01928 to 0.01873, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01873\n",
      "\n",
      "Epoch 20: loss improved from 0.01873 to 0.01800, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01800\n",
      "\n",
      "Epoch 22: loss improved from 0.01800 to 0.01670, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01670\n",
      "\n",
      "Epoch 24: loss improved from 0.01670 to 0.01633, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01633 to 0.01599, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01599\n",
      "\n",
      "Epoch 27: loss improved from 0.01599 to 0.01517, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01517\n",
      "\n",
      "Epoch 29: loss improved from 0.01517 to 0.01511, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01511\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01511\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01511\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01511\n",
      "\n",
      "Epoch 34: loss improved from 0.01511 to 0.01333, saving model to ../result\\lstmA_gruE_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01333\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01333\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01333\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01333\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01333\n",
      "Epoch 39: early stopping\n",
      "10th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06436, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06436 to 0.04677, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04677 to 0.04179, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04179 to 0.03960, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03960 to 0.03502, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03502 to 0.03303, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03303 to 0.03076, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03076 to 0.02996, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02996 to 0.02979, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02979 to 0.02807, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02807 to 0.02711, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02711 to 0.02694, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02694 to 0.02631, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02631\n",
      "\n",
      "Epoch 15: loss improved from 0.02631 to 0.02296, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02296\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02296\n",
      "\n",
      "Epoch 18: loss improved from 0.02296 to 0.02174, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02174 to 0.02081, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02081 to 0.02036, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02036 to 0.01929, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01929\n",
      "\n",
      "Epoch 23: loss improved from 0.01929 to 0.01897, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01897 to 0.01846, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01846\n",
      "\n",
      "Epoch 26: loss improved from 0.01846 to 0.01800, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01800\n",
      "\n",
      "Epoch 28: loss improved from 0.01800 to 0.01693, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01693 to 0.01688, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01688\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01688\n",
      "\n",
      "Epoch 32: loss improved from 0.01688 to 0.01623, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01623\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01623\n",
      "\n",
      "Epoch 35: loss improved from 0.01623 to 0.01588, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01588\n",
      "\n",
      "Epoch 37: loss improved from 0.01588 to 0.01531, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01531\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01531\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01531\n",
      "\n",
      "Epoch 41: loss improved from 0.01531 to 0.01497, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01497\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01497\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01497\n",
      "\n",
      "Epoch 45: loss improved from 0.01497 to 0.01482, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.01482 to 0.01474, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.01474 to 0.01409, saving model to ../result\\lstmA_gruE_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01409\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01409\n",
      "\n",
      "Epoch 50: loss did not improve from 0.01409\n",
      "\n",
      "Epoch 51: loss did not improve from 0.01409\n",
      "\n",
      "Epoch 52: loss did not improve from 0.01409\n",
      "Epoch 52: early stopping\n",
      "11th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06542, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06542 to 0.04902, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04902 to 0.04214, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04214 to 0.03970, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03970 to 0.03679, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03679 to 0.03541, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03541 to 0.03320, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03320 to 0.03230, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03230 to 0.03180, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.03180\n",
      "\n",
      "Epoch 11: loss improved from 0.03180 to 0.02966, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02966 to 0.02907, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02907\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02907\n",
      "\n",
      "Epoch 15: loss improved from 0.02907 to 0.02692, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02692 to 0.02553, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02553 to 0.02509, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02509 to 0.02424, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02424 to 0.02342, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02342\n",
      "\n",
      "Epoch 21: loss improved from 0.02342 to 0.02233, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02233\n",
      "\n",
      "Epoch 23: loss improved from 0.02233 to 0.02171, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02171 to 0.02123, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02123\n",
      "\n",
      "Epoch 26: loss improved from 0.02123 to 0.01968, saving model to ../result\\lstmA_gruE_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01968\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01968\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01968\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01968\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01968\n",
      "Epoch 31: early stopping\n",
      "12th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06871, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06871 to 0.05058, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05058 to 0.04519, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04519 to 0.04224, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04224 to 0.03888, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03888 to 0.03728, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03728 to 0.03548, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03548 to 0.03434, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03434 to 0.03397, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03397 to 0.03267, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03267 to 0.03192, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.03192\n",
      "\n",
      "Epoch 13: loss did not improve from 0.03192\n",
      "\n",
      "Epoch 14: loss improved from 0.03192 to 0.02990, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02990 to 0.02861, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02861\n",
      "\n",
      "Epoch 17: loss improved from 0.02861 to 0.02806, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02806\n",
      "\n",
      "Epoch 19: loss improved from 0.02806 to 0.02797, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02797 to 0.02611, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02611 to 0.02421, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02421\n",
      "\n",
      "Epoch 23: loss improved from 0.02421 to 0.02386, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02386\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02386\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02386\n",
      "\n",
      "Epoch 27: loss improved from 0.02386 to 0.02362, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02362\n",
      "\n",
      "Epoch 29: loss improved from 0.02362 to 0.02249, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.02249 to 0.02169, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.02169\n",
      "\n",
      "Epoch 32: loss did not improve from 0.02169\n",
      "\n",
      "Epoch 33: loss did not improve from 0.02169\n",
      "\n",
      "Epoch 34: loss improved from 0.02169 to 0.02125, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.02125\n",
      "\n",
      "Epoch 36: loss improved from 0.02125 to 0.02002, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.02002\n",
      "\n",
      "Epoch 38: loss improved from 0.02002 to 0.01956, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01956\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01956\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01956\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01956\n",
      "\n",
      "Epoch 43: loss improved from 0.01956 to 0.01947, saving model to ../result\\lstmA_gruE_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01947\n",
      "\n",
      "Epoch 45: loss did not improve from 0.01947\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01947\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01947\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01947\n",
      "Epoch 48: early stopping\n",
      "13th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06906, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06906 to 0.04643, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04643 to 0.04477, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04477 to 0.04248, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04248 to 0.04050, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04050 to 0.03716, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03716 to 0.03422, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03422 to 0.03239, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03239 to 0.03119, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03119 to 0.03001, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.03001\n",
      "\n",
      "Epoch 12: loss improved from 0.03001 to 0.02859, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02859 to 0.02756, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02756 to 0.02728, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02728 to 0.02552, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02552 to 0.02484, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02484 to 0.02413, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02413 to 0.02303, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02303 to 0.02151, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02151\n",
      "\n",
      "Epoch 21: loss improved from 0.02151 to 0.02129, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02129 to 0.02005, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02005\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02005\n",
      "\n",
      "Epoch 25: loss improved from 0.02005 to 0.01968, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01968\n",
      "\n",
      "Epoch 27: loss improved from 0.01968 to 0.01747, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01747\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01747\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01747\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01747\n",
      "\n",
      "Epoch 32: loss improved from 0.01747 to 0.01672, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01672 to 0.01625, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01625\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01625\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01625\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01625\n",
      "\n",
      "Epoch 38: loss improved from 0.01625 to 0.01616, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01616\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01616\n",
      "\n",
      "Epoch 41: loss improved from 0.01616 to 0.01454, saving model to ../result\\lstmA_gruE_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01454\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01454\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01454\n",
      "\n",
      "Epoch 45: loss did not improve from 0.01454\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01454\n",
      "Epoch 46: early stopping\n",
      "14th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07472, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07472 to 0.05257, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05257 to 0.04558, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04558 to 0.04311, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04311 to 0.04166, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04166 to 0.04019, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04019 to 0.03675, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03675 to 0.03371, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03371 to 0.03347, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03347 to 0.03196, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03196 to 0.03095, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.03095\n",
      "\n",
      "Epoch 13: loss improved from 0.03095 to 0.02956, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02956 to 0.02883, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02883 to 0.02862, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02862 to 0.02736, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02736 to 0.02727, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02727 to 0.02588, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02588 to 0.02484, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02484 to 0.02386, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02386 to 0.02355, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02355\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02355\n",
      "\n",
      "Epoch 24: loss improved from 0.02355 to 0.02304, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.02304 to 0.02227, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02227 to 0.02150, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.02150 to 0.02135, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.02135 to 0.02080, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.02080 to 0.01986, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01986 to 0.01985, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.01985 to 0.01943, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01943\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01943\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01943\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01943\n",
      "\n",
      "Epoch 36: loss improved from 0.01943 to 0.01926, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.01926 to 0.01826, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.01826 to 0.01825, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01825\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01825\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01825\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01825\n",
      "\n",
      "Epoch 43: loss improved from 0.01825 to 0.01720, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01720\n",
      "\n",
      "Epoch 45: loss improved from 0.01720 to 0.01688, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.01688 to 0.01638, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01638\n",
      "\n",
      "Epoch 48: loss improved from 0.01638 to 0.01634, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.01634 to 0.01604, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.01604 to 0.01579, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss did not improve from 0.01579\n",
      "\n",
      "Epoch 52: loss improved from 0.01579 to 0.01500, saving model to ../result\\lstmA_gruE_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss did not improve from 0.01500\n",
      "\n",
      "Epoch 54: loss did not improve from 0.01500\n",
      "\n",
      "Epoch 55: loss did not improve from 0.01500\n",
      "\n",
      "Epoch 56: loss did not improve from 0.01500\n",
      "\n",
      "Epoch 57: loss did not improve from 0.01500\n",
      "Epoch 57: early stopping\n",
      "15th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07705, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07705 to 0.05585, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05585 to 0.04630, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04630 to 0.04313, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04313 to 0.04190, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04190 to 0.04177, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04177 to 0.04153, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.04153 to 0.04058, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.04058 to 0.03931, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03931 to 0.03831, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03831 to 0.03594, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03594 to 0.03438, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03438 to 0.03305, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.03305 to 0.03257, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.03257 to 0.03224, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.03224 to 0.03119, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03119 to 0.03026, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.03026\n",
      "\n",
      "Epoch 19: loss improved from 0.03026 to 0.03010, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.03010 to 0.02948, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02948 to 0.02746, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02746\n",
      "\n",
      "Epoch 23: loss improved from 0.02746 to 0.02643, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02643\n",
      "\n",
      "Epoch 25: loss improved from 0.02643 to 0.02547, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02547\n",
      "\n",
      "Epoch 27: loss improved from 0.02547 to 0.02457, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02457\n",
      "\n",
      "Epoch 29: loss improved from 0.02457 to 0.02348, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.02348\n",
      "\n",
      "Epoch 31: loss did not improve from 0.02348\n",
      "\n",
      "Epoch 32: loss improved from 0.02348 to 0.02346, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.02346\n",
      "\n",
      "Epoch 34: loss did not improve from 0.02346\n",
      "\n",
      "Epoch 35: loss did not improve from 0.02346\n",
      "\n",
      "Epoch 36: loss improved from 0.02346 to 0.02117, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.02117\n",
      "\n",
      "Epoch 38: loss did not improve from 0.02117\n",
      "\n",
      "Epoch 39: loss did not improve from 0.02117\n",
      "\n",
      "Epoch 40: loss did not improve from 0.02117\n",
      "\n",
      "Epoch 41: loss improved from 0.02117 to 0.02072, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.02072\n",
      "\n",
      "Epoch 43: loss did not improve from 0.02072\n",
      "\n",
      "Epoch 44: loss did not improve from 0.02072\n",
      "\n",
      "Epoch 45: loss did not improve from 0.02072\n",
      "\n",
      "Epoch 46: loss improved from 0.02072 to 0.02040, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.02040 to 0.01939, saving model to ../result\\lstmA_gruE_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01939\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01939\n",
      "\n",
      "Epoch 50: loss did not improve from 0.01939\n",
      "\n",
      "Epoch 51: loss did not improve from 0.01939\n",
      "\n",
      "Epoch 52: loss did not improve from 0.01939\n",
      "Epoch 52: early stopping\n",
      "16th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07839, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07839 to 0.05945, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05945 to 0.04818, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04818 to 0.04515, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04515 to 0.04190, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.04190\n",
      "\n",
      "Epoch 7: loss improved from 0.04190 to 0.04085, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.04085 to 0.03999, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03999 to 0.03926, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03926 to 0.03743, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03743 to 0.03673, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03673 to 0.03543, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03543 to 0.03493, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.03493\n",
      "\n",
      "Epoch 15: loss did not improve from 0.03493\n",
      "\n",
      "Epoch 16: loss improved from 0.03493 to 0.03320, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03320 to 0.03298, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.03298 to 0.03253, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.03253 to 0.03182, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.03182 to 0.03131, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.03131 to 0.03050, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.03050 to 0.02967, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02967 to 0.02937, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02937 to 0.02916, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02916\n",
      "\n",
      "Epoch 26: loss improved from 0.02916 to 0.02893, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.02893 to 0.02643, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02643\n",
      "\n",
      "Epoch 29: loss did not improve from 0.02643\n",
      "\n",
      "Epoch 30: loss did not improve from 0.02643\n",
      "\n",
      "Epoch 31: loss did not improve from 0.02643\n",
      "\n",
      "Epoch 32: loss improved from 0.02643 to 0.02613, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.02613 to 0.02555, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.02555 to 0.02494, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.02494 to 0.02407, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.02407 to 0.02375, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.02375\n",
      "\n",
      "Epoch 38: loss improved from 0.02375 to 0.02353, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.02353\n",
      "\n",
      "Epoch 40: loss did not improve from 0.02353\n",
      "\n",
      "Epoch 41: loss improved from 0.02353 to 0.02315, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.02315\n",
      "\n",
      "Epoch 43: loss improved from 0.02315 to 0.02280, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.02280 to 0.02163, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss did not improve from 0.02163\n",
      "\n",
      "Epoch 46: loss did not improve from 0.02163\n",
      "\n",
      "Epoch 47: loss improved from 0.02163 to 0.02111, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.02111 to 0.02048, saving model to ../result\\lstmA_gruE_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.02048\n",
      "\n",
      "Epoch 50: loss did not improve from 0.02048\n",
      "\n",
      "Epoch 51: loss did not improve from 0.02048\n",
      "\n",
      "Epoch 52: loss did not improve from 0.02048\n",
      "\n",
      "Epoch 53: loss did not improve from 0.02048\n",
      "Epoch 53: early stopping\n",
      "17th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04769, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04769 to 0.03443, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03443 to 0.03236, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03236 to 0.02954, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02954 to 0.02883, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02883 to 0.02366, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02366 to 0.02286, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02286 to 0.01992, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01992 to 0.01714, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01714 to 0.01599, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.01599\n",
      "\n",
      "Epoch 12: loss improved from 0.01599 to 0.01460, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01460\n",
      "\n",
      "Epoch 14: loss improved from 0.01460 to 0.01367, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01367\n",
      "\n",
      "Epoch 16: loss improved from 0.01367 to 0.01300, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01300 to 0.01202, saving model to ../result\\lstmA_gruE_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01202\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01202\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01202\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01202\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01202\n",
      "Epoch 22: early stopping\n",
      "18th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04772, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04772 to 0.04094, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04094 to 0.03500, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03500 to 0.02863, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02863 to 0.02791, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02791 to 0.02305, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02305 to 0.02191, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.02191\n",
      "\n",
      "Epoch 9: loss improved from 0.02191 to 0.01968, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.01968\n",
      "\n",
      "Epoch 11: loss improved from 0.01968 to 0.01627, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.01627\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01627\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01627\n",
      "\n",
      "Epoch 15: loss improved from 0.01627 to 0.01582, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01582\n",
      "\n",
      "Epoch 17: loss improved from 0.01582 to 0.01502, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01502 to 0.01406, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01406\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01406\n",
      "\n",
      "Epoch 21: loss improved from 0.01406 to 0.01362, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01362\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01362\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01362\n",
      "\n",
      "Epoch 25: loss improved from 0.01362 to 0.01318, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01318\n",
      "\n",
      "Epoch 27: loss improved from 0.01318 to 0.01295, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01295\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01295\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01295\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01295\n",
      "\n",
      "Epoch 32: loss improved from 0.01295 to 0.01254, saving model to ../result\\lstmA_gruE_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01254\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01254\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01254\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01254\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01254\n",
      "Epoch 37: early stopping\n",
      "19th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05051, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05051 to 0.04100, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04100 to 0.03488, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03488 to 0.03146, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03146 to 0.02846, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.02846\n",
      "\n",
      "Epoch 7: loss improved from 0.02846 to 0.02767, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02767 to 0.02608, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02608 to 0.02318, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02318 to 0.02118, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02118 to 0.02093, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02093\n",
      "\n",
      "Epoch 13: loss improved from 0.02093 to 0.02036, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02036\n",
      "\n",
      "Epoch 15: loss improved from 0.02036 to 0.01981, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01981 to 0.01833, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01833 to 0.01709, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01709 to 0.01690, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01690\n",
      "\n",
      "Epoch 20: loss improved from 0.01690 to 0.01617, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01617\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01617\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01617\n",
      "\n",
      "Epoch 24: loss improved from 0.01617 to 0.01521, saving model to ../result\\lstmA_gruE_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01521\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01521\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01521\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01521\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01521\n",
      "Epoch 29: early stopping\n",
      "20th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05491, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05491 to 0.04441, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04441 to 0.03953, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03953 to 0.03774, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03774 to 0.03285, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03285 to 0.03199, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03199 to 0.03106, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03106 to 0.02902, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02902 to 0.02673, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02673 to 0.02353, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02353\n",
      "\n",
      "Epoch 12: loss improved from 0.02353 to 0.02200, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02200\n",
      "\n",
      "Epoch 14: loss improved from 0.02200 to 0.02049, saving model to ../result\\lstmA_gruE_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02049\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02049\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02049\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02049\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02049\n",
      "Epoch 19: early stopping\n",
      "21th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05128, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05128 to 0.04153, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04153 to 0.03359, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03359 to 0.02920, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02920 to 0.02838, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02838 to 0.02552, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02552 to 0.02336, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02336 to 0.02041, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02041\n",
      "\n",
      "Epoch 10: loss improved from 0.02041 to 0.01818, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01818 to 0.01806, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01806 to 0.01649, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01649 to 0.01533, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01533 to 0.01396, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01396\n",
      "\n",
      "Epoch 16: loss improved from 0.01396 to 0.01384, saving model to ../result\\lstmA_gruE_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01384\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01384\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01384\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01384\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01384\n",
      "Epoch 21: early stopping\n",
      "22th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05843, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05843 to 0.04295, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04295 to 0.03379, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03379 to 0.03270, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03270 to 0.02972, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02972 to 0.02763, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02763 to 0.02528, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02528 to 0.02495, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02495 to 0.02340, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02340 to 0.02050, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02050\n",
      "\n",
      "Epoch 12: loss improved from 0.02050 to 0.01886, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01886 to 0.01791, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01791\n",
      "\n",
      "Epoch 15: loss improved from 0.01791 to 0.01756, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01756 to 0.01592, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01592\n",
      "\n",
      "Epoch 18: loss improved from 0.01592 to 0.01547, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01547 to 0.01482, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01482 to 0.01376, saving model to ../result\\lstmA_gruE_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01376\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01376\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01376\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01376\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01376\n",
      "Epoch 25: early stopping\n",
      "23th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05190, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05190 to 0.03915, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03915 to 0.03657, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss did not improve from 0.03657\n",
      "\n",
      "Epoch 5: loss improved from 0.03657 to 0.03502, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03502 to 0.03049, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03049 to 0.02973, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02973 to 0.02798, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02798 to 0.02525, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02525\n",
      "\n",
      "Epoch 11: loss improved from 0.02525 to 0.02234, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02234\n",
      "\n",
      "Epoch 13: loss improved from 0.02234 to 0.02109, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02109\n",
      "\n",
      "Epoch 15: loss improved from 0.02109 to 0.01963, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01963\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01963\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01963\n",
      "\n",
      "Epoch 19: loss improved from 0.01963 to 0.01957, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01957 to 0.01834, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01834\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01834\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01834\n",
      "\n",
      "Epoch 24: loss improved from 0.01834 to 0.01713, saving model to ../result\\lstmA_gruE_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01713\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01713\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01713\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01713\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01713\n",
      "Epoch 29: early stopping\n",
      "24th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05480, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05480 to 0.04350, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04350 to 0.03646, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss did not improve from 0.03646\n",
      "\n",
      "Epoch 5: loss improved from 0.03646 to 0.03411, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03411 to 0.03301, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.03301\n",
      "\n",
      "Epoch 8: loss improved from 0.03301 to 0.03020, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03020 to 0.02866, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02866 to 0.02696, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02696 to 0.02626, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02626 to 0.02358, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02358\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02358\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02358\n",
      "\n",
      "Epoch 16: loss improved from 0.02358 to 0.02091, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02091 to 0.02063, saving model to ../result\\lstmA_gruE_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02063\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02063\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02063\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02063\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02063\n",
      "Epoch 22: early stopping\n",
      "25th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06520, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06520 to 0.04314, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04314 to 0.04084, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04084 to 0.03481, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03481 to 0.03379, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03379 to 0.03141, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03141 to 0.02993, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02993 to 0.02749, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02749 to 0.02572, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02572 to 0.02464, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02464 to 0.02356, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02356 to 0.02231, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02231\n",
      "\n",
      "Epoch 14: loss improved from 0.02231 to 0.01825, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01825 to 0.01798, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01798 to 0.01710, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01710\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01710\n",
      "\n",
      "Epoch 19: loss improved from 0.01710 to 0.01587, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01587 to 0.01584, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01584\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01584\n",
      "\n",
      "Epoch 23: loss improved from 0.01584 to 0.01454, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01454 to 0.01384, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01384 to 0.01378, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01378\n",
      "\n",
      "Epoch 27: loss improved from 0.01378 to 0.01305, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01305\n",
      "\n",
      "Epoch 29: loss improved from 0.01305 to 0.01233, saving model to ../result\\lstmA_gruE_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01233\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01233\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01233\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01233\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01233\n",
      "Epoch 34: early stopping\n",
      "26th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05752, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05752 to 0.04283, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04283 to 0.03531, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03531 to 0.03216, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03216 to 0.03114, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03114 to 0.02818, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02818 to 0.02755, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.02755\n",
      "\n",
      "Epoch 9: loss improved from 0.02755 to 0.02438, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02438 to 0.02208, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02208 to 0.02160, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02160 to 0.02084, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02084\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02084\n",
      "\n",
      "Epoch 15: loss improved from 0.02084 to 0.02007, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02007 to 0.01826, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01826 to 0.01624, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01624\n",
      "\n",
      "Epoch 19: loss improved from 0.01624 to 0.01602, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01602 to 0.01493, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 25: loss improved from 0.01493 to 0.01386, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01386 to 0.01380, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01380\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01380\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01380\n",
      "\n",
      "Epoch 30: loss improved from 0.01380 to 0.01333, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01333\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01333\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01333\n",
      "\n",
      "Epoch 34: loss improved from 0.01333 to 0.01295, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01295\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01295\n",
      "\n",
      "Epoch 37: loss improved from 0.01295 to 0.01287, saving model to ../result\\lstmA_gruE_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01287\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01287\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01287\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01287\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01287\n",
      "Epoch 42: early stopping\n",
      "27th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06028, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06028 to 0.05127, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05127 to 0.04114, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04114 to 0.03639, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03639 to 0.03523, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03523 to 0.03444, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.03444\n",
      "\n",
      "Epoch 8: loss improved from 0.03444 to 0.03094, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03094 to 0.02889, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02889 to 0.02755, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02755 to 0.02521, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02521\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02521\n",
      "\n",
      "Epoch 14: loss improved from 0.02521 to 0.02451, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02451 to 0.02196, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02196 to 0.02149, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02149 to 0.02136, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02136\n",
      "\n",
      "Epoch 19: loss improved from 0.02136 to 0.02096, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02096 to 0.02001, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02001\n",
      "\n",
      "Epoch 22: loss improved from 0.02001 to 0.01840, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01840\n",
      "\n",
      "Epoch 24: loss improved from 0.01840 to 0.01814, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01814\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01814\n",
      "\n",
      "Epoch 27: loss improved from 0.01814 to 0.01721, saving model to ../result\\lstmA_gruE_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01721\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01721\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01721\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01721\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01721\n",
      "Epoch 32: early stopping\n",
      "28th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06171, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06171 to 0.05340, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05340 to 0.04140, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04140 to 0.03900, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03900 to 0.03542, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.03542\n",
      "\n",
      "Epoch 7: loss did not improve from 0.03542\n",
      "\n",
      "Epoch 8: loss did not improve from 0.03542\n",
      "\n",
      "Epoch 9: loss improved from 0.03542 to 0.03258, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03258 to 0.03227, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03227 to 0.02910, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02910 to 0.02786, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02786\n",
      "\n",
      "Epoch 14: loss improved from 0.02786 to 0.02755, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02755 to 0.02524, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02524\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02524\n",
      "\n",
      "Epoch 18: loss improved from 0.02524 to 0.02343, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02343 to 0.02324, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02324 to 0.02249, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02249 to 0.02225, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02225\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02225\n",
      "\n",
      "Epoch 24: loss improved from 0.02225 to 0.02130, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.02130 to 0.02071, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02071\n",
      "\n",
      "Epoch 27: loss improved from 0.02071 to 0.02037, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02037\n",
      "\n",
      "Epoch 29: loss improved from 0.02037 to 0.01945, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01945\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01945\n",
      "\n",
      "Epoch 32: loss improved from 0.01945 to 0.01864, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01864\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01864\n",
      "\n",
      "Epoch 35: loss improved from 0.01864 to 0.01833, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.01833 to 0.01785, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.01785 to 0.01774, saving model to ../result\\lstmA_gruE_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01774\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01774\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01774\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01774\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01774\n",
      "Epoch 42: early stopping\n",
      "29th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06255, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06255 to 0.04998, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04998 to 0.04211, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04211 to 0.03744, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03744 to 0.03421, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03421 to 0.03217, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03217 to 0.03090, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03090 to 0.02903, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02903 to 0.02862, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02862 to 0.02637, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02637 to 0.02501, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02501\n",
      "\n",
      "Epoch 13: loss improved from 0.02501 to 0.02474, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02474 to 0.02245, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02245\n",
      "\n",
      "Epoch 16: loss improved from 0.02245 to 0.02157, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02157 to 0.01975, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01975 to 0.01904, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01904\n",
      "\n",
      "Epoch 20: loss improved from 0.01904 to 0.01799, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01799 to 0.01786, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01786 to 0.01731, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01731 to 0.01606, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01606 to 0.01561, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01561 to 0.01508, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01508\n",
      "\n",
      "Epoch 27: loss improved from 0.01508 to 0.01431, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01431\n",
      "\n",
      "Epoch 29: loss improved from 0.01431 to 0.01431, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01431\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01431\n",
      "\n",
      "Epoch 32: loss improved from 0.01431 to 0.01406, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01406\n",
      "\n",
      "Epoch 34: loss improved from 0.01406 to 0.01368, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01368\n",
      "\n",
      "Epoch 36: loss improved from 0.01368 to 0.01349, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.01349 to 0.01289, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01289\n",
      "\n",
      "Epoch 39: loss improved from 0.01289 to 0.01267, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01267\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01267\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01267\n",
      "\n",
      "Epoch 43: loss improved from 0.01267 to 0.01187, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01187\n",
      "\n",
      "Epoch 45: loss improved from 0.01187 to 0.01183, saving model to ../result\\lstmA_gruE_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01183\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01183\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01183\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01183\n",
      "\n",
      "Epoch 50: loss did not improve from 0.01183\n",
      "Epoch 50: early stopping\n",
      "30th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06988, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06988 to 0.04898, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04898 to 0.04282, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04282 to 0.04147, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04147 to 0.03811, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03811 to 0.03444, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03444 to 0.03196, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03196 to 0.03115, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03115 to 0.02887, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02887\n",
      "\n",
      "Epoch 11: loss improved from 0.02887 to 0.02681, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02681 to 0.02519, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02519 to 0.02277, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02277\n",
      "\n",
      "Epoch 15: loss improved from 0.02277 to 0.02185, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02185 to 0.02146, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02146 to 0.02061, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02061\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02061\n",
      "\n",
      "Epoch 20: loss improved from 0.02061 to 0.01871, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01871\n",
      "\n",
      "Epoch 22: loss improved from 0.01871 to 0.01809, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01809 to 0.01796, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01796 to 0.01715, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01715\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01715\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01715\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01715\n",
      "\n",
      "Epoch 29: loss improved from 0.01715 to 0.01617, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01617\n",
      "\n",
      "Epoch 31: loss improved from 0.01617 to 0.01590, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01590 to 0.01471, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01471\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01471\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01471\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01471\n",
      "\n",
      "Epoch 37: loss improved from 0.01471 to 0.01430, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01430\n",
      "\n",
      "Epoch 39: loss improved from 0.01430 to 0.01416, saving model to ../result\\lstmA_gruE_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01416\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01416\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01416\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01416\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01416\n",
      "Epoch 44: early stopping\n",
      "31th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07192, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07192 to 0.04958, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04958 to 0.04484, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04484 to 0.03993, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss did not improve from 0.03993\n",
      "\n",
      "Epoch 6: loss improved from 0.03993 to 0.03605, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03605 to 0.03468, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03468 to 0.03406, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03406 to 0.03230, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03230 to 0.03121, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03121 to 0.03063, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03063 to 0.02945, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02945 to 0.02858, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02858 to 0.02620, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02620 to 0.02587, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02587 to 0.02545, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02545\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02545\n",
      "\n",
      "Epoch 19: loss improved from 0.02545 to 0.02353, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02353\n",
      "\n",
      "Epoch 21: loss improved from 0.02353 to 0.02326, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02326 to 0.02259, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02259 to 0.02174, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02174\n",
      "\n",
      "Epoch 25: loss improved from 0.02174 to 0.02032, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02032 to 0.01998, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01998\n",
      "\n",
      "Epoch 28: loss improved from 0.01998 to 0.01931, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01931\n",
      "\n",
      "Epoch 30: loss improved from 0.01931 to 0.01830, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01830\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01830\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01830\n",
      "\n",
      "Epoch 34: loss improved from 0.01830 to 0.01782, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01782\n",
      "\n",
      "Epoch 36: loss improved from 0.01782 to 0.01758, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01758\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01758\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01758\n",
      "\n",
      "Epoch 40: loss improved from 0.01758 to 0.01702, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.01702 to 0.01700, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01700\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01700\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01700\n",
      "\n",
      "Epoch 45: loss improved from 0.01700 to 0.01689, saving model to ../result\\lstmA_gruE_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01689\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01689\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01689\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01689\n",
      "\n",
      "Epoch 50: loss did not improve from 0.01689\n",
      "Epoch 50: early stopping\n",
      "32th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07236, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07236 to 0.05289, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05289 to 0.04418, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04418 to 0.04173, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04173 to 0.04116, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04116 to 0.03891, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03891 to 0.03744, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03744 to 0.03526, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.03526\n",
      "\n",
      "Epoch 10: loss improved from 0.03526 to 0.03294, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.03294\n",
      "\n",
      "Epoch 12: loss improved from 0.03294 to 0.03182, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.03182\n",
      "\n",
      "Epoch 14: loss improved from 0.03182 to 0.03000, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.03000 to 0.02947, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02947 to 0.02849, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02849 to 0.02783, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02783 to 0.02725, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02725 to 0.02687, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02687 to 0.02602, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02602\n",
      "\n",
      "Epoch 22: loss improved from 0.02602 to 0.02463, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02463 to 0.02399, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02399 to 0.02358, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.02358 to 0.02330, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02330 to 0.02306, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.02306 to 0.02177, saving model to ../result\\lstmA_gruE_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02177\n",
      "\n",
      "Epoch 29: loss did not improve from 0.02177\n",
      "\n",
      "Epoch 30: loss did not improve from 0.02177\n",
      "\n",
      "Epoch 31: loss did not improve from 0.02177\n",
      "\n",
      "Epoch 32: loss did not improve from 0.02177\n",
      "Epoch 32: early stopping\n",
      "33th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.03834, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.03834 to 0.01097, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01097 to 0.00687, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.00687 to 0.00539, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00539 to 0.00536, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00536 to 0.00526, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.00526\n",
      "\n",
      "Epoch 8: loss improved from 0.00526 to 0.00502, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.00502\n",
      "\n",
      "Epoch 10: loss improved from 0.00502 to 0.00481, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00481 to 0.00470, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00470\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00470\n",
      "\n",
      "Epoch 14: loss improved from 0.00470 to 0.00457, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00457\n",
      "\n",
      "Epoch 16: loss improved from 0.00457 to 0.00449, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00449\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00449\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00449\n",
      "\n",
      "Epoch 20: loss improved from 0.00449 to 0.00433, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00433\n",
      "\n",
      "Epoch 22: loss improved from 0.00433 to 0.00431, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 24: loss improved from 0.00431 to 0.00427, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00427 to 0.00425, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00425 to 0.00423, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00423 to 0.00414, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 29: loss improved from 0.00414 to 0.00400, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 32: loss improved from 0.00400 to 0.00398, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00398\n",
      "\n",
      "Epoch 34: loss improved from 0.00398 to 0.00386, saving model to ../result\\lstmA_gruE_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00386\n",
      "Epoch 39: early stopping\n",
      "34th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04290, saving model to ../result\\lstmA_gruE_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04290 to 0.01266, saving model to ../result\\lstmA_gruE_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01266 to 0.00836, saving model to ../result\\lstmA_gruE_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.00836 to 0.00608, saving model to ../result\\lstmA_gruE_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00608 to 0.00593, saving model to ../result\\lstmA_gruE_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00593 to 0.00579, saving model to ../result\\lstmA_gruE_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00579 to 0.00546, saving model to ../result\\lstmA_gruE_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00546 to 0.00498, saving model to ../result\\lstmA_gruE_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.00498\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00498\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00498\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00498\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00498\n",
      "Epoch 13: early stopping\n",
      "35th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04675, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04675 to 0.01406, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01406 to 0.01145, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01145 to 0.00785, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00785 to 0.00683, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00683 to 0.00632, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00632 to 0.00571, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.00571\n",
      "\n",
      "Epoch 9: loss improved from 0.00571 to 0.00536, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00536 to 0.00504, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00504\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00504\n",
      "\n",
      "Epoch 13: loss improved from 0.00504 to 0.00503, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00503\n",
      "\n",
      "Epoch 15: loss improved from 0.00503 to 0.00503, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00503\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00503\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00503\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00503\n",
      "\n",
      "Epoch 20: loss improved from 0.00503 to 0.00490, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 25: loss improved from 0.00490 to 0.00484, saving model to ../result\\lstmA_gruE_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00484\n",
      "Epoch 30: early stopping\n",
      "36th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04760, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04760 to 0.01530, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01530 to 0.01079, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01079 to 0.00838, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00838 to 0.00745, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00745 to 0.00637, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00637 to 0.00596, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00596 to 0.00566, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00566 to 0.00549, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00549 to 0.00538, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00538 to 0.00529, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00529\n",
      "\n",
      "Epoch 13: loss improved from 0.00529 to 0.00508, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00508\n",
      "\n",
      "Epoch 15: loss improved from 0.00508 to 0.00499, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 18: loss improved from 0.00499 to 0.00494, saving model to ../result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00494\n",
      "Epoch 23: early stopping\n",
      "37th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06138, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06138 to 0.01761, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01761 to 0.01219, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01219 to 0.01029, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01029 to 0.00718, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00718 to 0.00586, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00586 to 0.00576, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00576 to 0.00545, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00545 to 0.00530, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00530 to 0.00523, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00523 to 0.00522, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00522 to 0.00511, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00511\n",
      "\n",
      "Epoch 14: loss improved from 0.00511 to 0.00495, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00495\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00495\n",
      "\n",
      "Epoch 17: loss improved from 0.00495 to 0.00494, saving model to ../result\\lstmA_gruE_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00494\n",
      "Epoch 22: early stopping\n",
      "38th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05873, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05873 to 0.01746, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01746 to 0.01355, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01355 to 0.01121, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01121 to 0.00826, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00826 to 0.00654, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00654 to 0.00619, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00619 to 0.00554, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00554 to 0.00549, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00549 to 0.00536, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00536 to 0.00499, saving model to ../result\\lstmA_gruE_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00499\n",
      "Epoch 16: early stopping\n",
      "39th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06857, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06857 to 0.02033, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02033 to 0.01529, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01529 to 0.01318, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01318 to 0.01114, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01114 to 0.00908, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00908 to 0.00786, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00786 to 0.00726, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00726 to 0.00653, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00653 to 0.00574, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00574 to 0.00568, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00568\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00568\n",
      "\n",
      "Epoch 14: loss improved from 0.00568 to 0.00525, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00525\n",
      "\n",
      "Epoch 16: loss improved from 0.00525 to 0.00513, saving model to ../result\\lstmA_gruE_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00513\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00513\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00513\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00513\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00513\n",
      "Epoch 21: early stopping\n",
      "40th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07352, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07352 to 0.02120, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02120 to 0.01622, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01622 to 0.01403, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01403 to 0.01295, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01295 to 0.01174, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01174 to 0.01049, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01049 to 0.00887, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00887 to 0.00764, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00764 to 0.00679, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00679 to 0.00625, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00625\n",
      "\n",
      "Epoch 13: loss improved from 0.00625 to 0.00580, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00580 to 0.00564, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00564 to 0.00562, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00562 to 0.00544, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00544 to 0.00535, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00535 to 0.00518, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00518\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00518\n",
      "\n",
      "Epoch 21: loss improved from 0.00518 to 0.00516, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00516 to 0.00513, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00513 to 0.00499, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 28: loss improved from 0.00499 to 0.00493, saving model to ../result\\lstmA_gruE_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00493\n",
      "Epoch 33: early stopping\n",
      "41th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.09077, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.09077 to 0.02611, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02611 to 0.01710, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01710 to 0.01323, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01323 to 0.01062, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01062 to 0.00869, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00869 to 0.00739, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00739 to 0.00669, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00669 to 0.00615, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00615 to 0.00578, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00578 to 0.00571, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00571 to 0.00563, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00563 to 0.00545, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00545 to 0.00537, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00537 to 0.00504, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00504\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00504\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00504\n",
      "\n",
      "Epoch 19: loss improved from 0.00504 to 0.00503, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00503\n",
      "\n",
      "Epoch 21: loss improved from 0.00503 to 0.00490, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 26: loss improved from 0.00490 to 0.00477, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00477\n",
      "\n",
      "Epoch 28: loss improved from 0.00477 to 0.00475, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 30: loss improved from 0.00475 to 0.00468, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00468 to 0.00465, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00465\n",
      "\n",
      "Epoch 33: loss improved from 0.00465 to 0.00452, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00452 to 0.00450, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00450\n",
      "\n",
      "Epoch 36: loss improved from 0.00450 to 0.00445, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 39: loss improved from 0.00445 to 0.00438, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00438\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00438\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00438\n",
      "\n",
      "Epoch 43: loss improved from 0.00438 to 0.00436, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00436 to 0.00425, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00425\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00425\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00425\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00425\n",
      "\n",
      "Epoch 49: loss improved from 0.00425 to 0.00420, saving model to ../result\\lstmA_gruE_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00420\n",
      "Epoch 54: early stopping\n",
      "42th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11158, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11158 to 0.03342, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03342 to 0.02147, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02147 to 0.01668, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01668 to 0.01448, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01448 to 0.01310, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01310 to 0.01196, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01196 to 0.01098, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01098 to 0.00950, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00950 to 0.00803, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00803 to 0.00739, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00739 to 0.00669, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00669 to 0.00620, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00620 to 0.00603, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00603 to 0.00559, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00559 to 0.00548, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00548\n",
      "\n",
      "Epoch 18: loss improved from 0.00548 to 0.00526, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00526 to 0.00523, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00523 to 0.00518, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00518\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00518\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00518\n",
      "\n",
      "Epoch 24: loss improved from 0.00518 to 0.00493, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 26: loss improved from 0.00493 to 0.00489, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00489\n",
      "\n",
      "Epoch 28: loss improved from 0.00489 to 0.00476, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00476\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00476\n",
      "\n",
      "Epoch 31: loss improved from 0.00476 to 0.00472, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 36: loss improved from 0.00472 to 0.00472, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 40: loss improved from 0.00472 to 0.00452, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00452 to 0.00449, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00449\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00449\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00449\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00449\n",
      "\n",
      "Epoch 46: loss improved from 0.00449 to 0.00437, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 48: loss improved from 0.00437 to 0.00432, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00432\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00432\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00432\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00432\n",
      "\n",
      "Epoch 53: loss improved from 0.00432 to 0.00428, saving model to ../result\\lstmA_gruE_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00428\n",
      "Epoch 58: early stopping\n",
      "43th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11016, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11016 to 0.03399, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03399 to 0.02074, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02074 to 0.01737, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01737 to 0.01541, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01541 to 0.01439, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01439 to 0.01351, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01351 to 0.01266, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01266 to 0.01202, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01202 to 0.01146, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01146 to 0.01120, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01120 to 0.01003, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01003 to 0.00929, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00929 to 0.00734, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00734 to 0.00697, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00697 to 0.00658, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00658 to 0.00610, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00610 to 0.00596, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00596 to 0.00585, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00585 to 0.00556, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00556 to 0.00525, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00525\n",
      "\n",
      "Epoch 23: loss improved from 0.00525 to 0.00523, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00523 to 0.00512, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00512\n",
      "\n",
      "Epoch 26: loss improved from 0.00512 to 0.00505, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00505\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00505\n",
      "\n",
      "Epoch 29: loss improved from 0.00505 to 0.00495, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00495 to 0.00490, saving model to ../result\\lstmA_gruE_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00490\n",
      "Epoch 35: early stopping\n",
      "44th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10273, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.10273 to 0.03441, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03441 to 0.02235, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02235 to 0.01862, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01862 to 0.01658, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01658 to 0.01502, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01502 to 0.01444, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01444 to 0.01376, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01376 to 0.01319, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01319 to 0.01272, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01272 to 0.01212, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01212 to 0.01184, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01184 to 0.01092, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01092 to 0.00973, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00973 to 0.00871, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00871 to 0.00801, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00801 to 0.00726, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00726 to 0.00702, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00702 to 0.00683, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00683\n",
      "\n",
      "Epoch 21: loss improved from 0.00683 to 0.00650, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00650 to 0.00642, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00642 to 0.00608, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00608 to 0.00584, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00584 to 0.00568, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00568 to 0.00564, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00564\n",
      "\n",
      "Epoch 28: loss improved from 0.00564 to 0.00559, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00559 to 0.00537, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00537\n",
      "\n",
      "Epoch 31: loss improved from 0.00537 to 0.00522, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00522\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00522\n",
      "\n",
      "Epoch 34: loss improved from 0.00522 to 0.00519, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00519 to 0.00512, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00512 to 0.00511, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00511\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00511\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00511\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00511\n",
      "\n",
      "Epoch 41: loss improved from 0.00511 to 0.00509, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00509\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00509\n",
      "\n",
      "Epoch 44: loss improved from 0.00509 to 0.00507, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00507 to 0.00505, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00505\n",
      "\n",
      "Epoch 47: loss improved from 0.00505 to 0.00499, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 50: loss improved from 0.00499 to 0.00493, saving model to ../result\\lstmA_gruE_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00493\n",
      "Epoch 55: early stopping\n",
      "45th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12003, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12003 to 0.05807, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05807 to 0.02972, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02972 to 0.02393, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02393 to 0.01981, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01981 to 0.01732, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01732 to 0.01593, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01593 to 0.01465, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01465 to 0.01359, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01359 to 0.01295, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01295 to 0.01195, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01195 to 0.01129, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01129 to 0.01108, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01108 to 0.00997, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00997 to 0.00925, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00925 to 0.00817, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00817 to 0.00722, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00722 to 0.00688, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00688 to 0.00653, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00653 to 0.00640, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00640 to 0.00627, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00627 to 0.00588, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00588 to 0.00581, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00581 to 0.00559, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00559 to 0.00556, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00556\n",
      "\n",
      "Epoch 27: loss improved from 0.00556 to 0.00539, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00539\n",
      "\n",
      "Epoch 29: loss improved from 0.00539 to 0.00524, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00524 to 0.00516, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00516 to 0.00498, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00498\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00498\n",
      "\n",
      "Epoch 34: loss improved from 0.00498 to 0.00480, saving model to ../result\\lstmA_gruE_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00480\n",
      "Epoch 39: early stopping\n",
      "46th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12400, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12400 to 0.07377, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.07377 to 0.03022, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03022 to 0.02514, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02514 to 0.02226, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02226 to 0.01898, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01898 to 0.01690, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01690 to 0.01547, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01547 to 0.01412, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01412 to 0.01358, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01358 to 0.01267, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01267 to 0.01196, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01196 to 0.01051, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01051 to 0.00971, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00971 to 0.00911, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00911 to 0.00860, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00860 to 0.00789, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00789\n",
      "\n",
      "Epoch 19: loss improved from 0.00789 to 0.00755, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00755 to 0.00706, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00706 to 0.00679, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00679 to 0.00644, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00644 to 0.00619, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00619 to 0.00609, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00609 to 0.00592, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00592 to 0.00572, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 28: loss improved from 0.00572 to 0.00562, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00562 to 0.00560, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00560 to 0.00542, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00542\n",
      "\n",
      "Epoch 32: loss improved from 0.00542 to 0.00533, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00533 to 0.00532, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00532 to 0.00518, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00518\n",
      "\n",
      "Epoch 36: loss improved from 0.00518 to 0.00514, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00514\n",
      "\n",
      "Epoch 38: loss improved from 0.00514 to 0.00510, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00510 to 0.00490, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 44: loss improved from 0.00490 to 0.00489, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00489 to 0.00483, saving model to ../result\\lstmA_gruE_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00483\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00483\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00483\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00483\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00483\n",
      "Epoch 50: early stopping\n",
      "47th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12629, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12629 to 0.08005, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.08005 to 0.03444, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03444 to 0.02544, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02544 to 0.02192, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02192 to 0.01775, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01775 to 0.01685, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01685 to 0.01598, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01598 to 0.01466, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01466 to 0.01425, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01425 to 0.01384, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01384 to 0.01289, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01289 to 0.01281, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01281 to 0.01184, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01184 to 0.01164, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01164 to 0.01095, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01095 to 0.00954, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00954 to 0.00952, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00952 to 0.00899, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00899 to 0.00870, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00870 to 0.00827, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00827 to 0.00780, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00780 to 0.00750, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00750 to 0.00708, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00708\n",
      "\n",
      "Epoch 26: loss improved from 0.00708 to 0.00684, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00684\n",
      "\n",
      "Epoch 28: loss improved from 0.00684 to 0.00648, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00648 to 0.00627, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00627\n",
      "\n",
      "Epoch 31: loss improved from 0.00627 to 0.00610, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00610 to 0.00600, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00600\n",
      "\n",
      "Epoch 34: loss improved from 0.00600 to 0.00577, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00577\n",
      "\n",
      "Epoch 36: loss improved from 0.00577 to 0.00552, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00552\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00552\n",
      "\n",
      "Epoch 39: loss improved from 0.00552 to 0.00545, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00545\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00545\n",
      "\n",
      "Epoch 42: loss improved from 0.00545 to 0.00526, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00526\n",
      "\n",
      "Epoch 44: loss improved from 0.00526 to 0.00517, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00517\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00517\n",
      "\n",
      "Epoch 47: loss improved from 0.00517 to 0.00513, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00513 to 0.00512, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00512 to 0.00506, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00506 to 0.00505, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.00505 to 0.00504, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00504\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00504\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00504\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00504\n",
      "\n",
      "Epoch 56: loss improved from 0.00504 to 0.00499, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00499 to 0.00493, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.00493 to 0.00488, saving model to ../result\\lstmA_gruE_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 60: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 62: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 63: loss did not improve from 0.00488\n",
      "Epoch 63: early stopping\n",
      "48th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13039, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13039 to 0.09998, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.09998 to 0.05032, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.05032 to 0.02873, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02873 to 0.02512, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02512 to 0.02174, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02174 to 0.01816, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01816 to 0.01647, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01647 to 0.01524, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01524 to 0.01452, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01452 to 0.01328, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01328 to 0.01316, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01316 to 0.01237, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01237 to 0.01117, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01117 to 0.01037, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01037 to 0.01006, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01006 to 0.00955, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00955 to 0.00918, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00918 to 0.00886, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00886 to 0.00848, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00848 to 0.00802, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00802 to 0.00794, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00794 to 0.00778, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00778 to 0.00758, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00758 to 0.00728, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00728\n",
      "\n",
      "Epoch 27: loss improved from 0.00728 to 0.00685, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00685 to 0.00668, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00668 to 0.00637, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00637\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00637\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00637\n",
      "\n",
      "Epoch 33: loss improved from 0.00637 to 0.00608, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00608 to 0.00601, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00601 to 0.00585, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00585\n",
      "\n",
      "Epoch 37: loss improved from 0.00585 to 0.00580, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00580 to 0.00575, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00575\n",
      "\n",
      "Epoch 40: loss improved from 0.00575 to 0.00573, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00573 to 0.00560, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00560 to 0.00541, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00541 to 0.00532, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00532 to 0.00530, saving model to ../result\\lstmA_gruE_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00530\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00530\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00530\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00530\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00530\n",
      "Epoch 49: early stopping\n",
      "49th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.02972, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.02972 to 0.01044, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01044 to 0.00658, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.00658 to 0.00526, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00526 to 0.00490, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 7: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 8: loss improved from 0.00490 to 0.00484, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 10: loss improved from 0.00484 to 0.00475, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00475 to 0.00470, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00470\n",
      "\n",
      "Epoch 13: loss improved from 0.00470 to 0.00458, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00458 to 0.00454, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00454 to 0.00436, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00436 to 0.00430, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00430\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00430\n",
      "\n",
      "Epoch 19: loss improved from 0.00430 to 0.00409, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00409 to 0.00394, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00394\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00394\n",
      "\n",
      "Epoch 23: loss improved from 0.00394 to 0.00392, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 28: loss improved from 0.00392 to 0.00381, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00381 to 0.00365, saving model to ../result\\lstmA_gruE_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00365\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00365\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00365\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00365\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00365\n",
      "Epoch 34: early stopping\n",
      "50th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.03579, saving model to ../result\\lstmA_gruE_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.03579 to 0.01278, saving model to ../result\\lstmA_gruE_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01278 to 0.01069, saving model to ../result\\lstmA_gruE_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01069 to 0.00931, saving model to ../result\\lstmA_gruE_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00931 to 0.00567, saving model to ../result\\lstmA_gruE_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.00567\n",
      "\n",
      "Epoch 7: loss improved from 0.00567 to 0.00535, saving model to ../result\\lstmA_gruE_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00535 to 0.00505, saving model to ../result\\lstmA_gruE_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.00505\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00505\n",
      "\n",
      "Epoch 11: loss improved from 0.00505 to 0.00499, saving model to ../result\\lstmA_gruE_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00499 to 0.00481, saving model to ../result\\lstmA_gruE_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00481\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00481\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00481\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00481\n",
      "\n",
      "Epoch 17: loss improved from 0.00481 to 0.00479, saving model to ../result\\lstmA_gruE_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00479\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00479\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00479\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00479\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00479\n",
      "Epoch 22: early stopping\n",
      "51th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.03645, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.03645 to 0.01351, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01351 to 0.01007, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01007 to 0.00817, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00817 to 0.00609, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00609 to 0.00574, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00574 to 0.00541, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00541 to 0.00509, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00509 to 0.00495, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00495\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00495\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00495\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00495\n",
      "\n",
      "Epoch 14: loss improved from 0.00495 to 0.00493, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 16: loss improved from 0.00493 to 0.00489, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00489 to 0.00487, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00487\n",
      "\n",
      "Epoch 19: loss improved from 0.00487 to 0.00480, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 24: loss improved from 0.00480 to 0.00478, saving model to ../result\\lstmA_gruE_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00478\n",
      "Epoch 29: early stopping\n",
      "52th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04037, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04037 to 0.01307, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01307 to 0.01048, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01048 to 0.00773, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00773 to 0.00608, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.00608\n",
      "\n",
      "Epoch 7: loss improved from 0.00608 to 0.00533, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00533 to 0.00520, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.00520\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00520\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00520\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00520\n",
      "\n",
      "Epoch 13: loss improved from 0.00520 to 0.00499, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00499 to 0.00496, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00496\n",
      "\n",
      "Epoch 16: loss improved from 0.00496 to 0.00493, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 21: loss improved from 0.00493 to 0.00491, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00491\n",
      "\n",
      "Epoch 23: loss improved from 0.00491 to 0.00485, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00485 to 0.00479, saving model to ../result\\lstmA_gruE_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00479\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00479\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00479\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00479\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00479\n",
      "Epoch 29: early stopping\n",
      "53th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04705, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04705 to 0.01414, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01414 to 0.01106, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01106 to 0.00987, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00987 to 0.00835, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00835 to 0.00591, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00591 to 0.00528, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00528 to 0.00510, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00510 to 0.00505, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00505 to 0.00468, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00468\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00468\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00468\n",
      "\n",
      "Epoch 14: loss improved from 0.00468 to 0.00453, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00453\n",
      "\n",
      "Epoch 16: loss improved from 0.00453 to 0.00449, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00449 to 0.00443, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00443 to 0.00435, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 20: loss improved from 0.00435 to 0.00420, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 24: loss improved from 0.00420 to 0.00417, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 26: loss improved from 0.00417 to 0.00404, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 30: loss improved from 0.00404 to 0.00402, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00402 to 0.00394, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00394 to 0.00373, saving model to ../result\\lstmA_gruE_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00373\n",
      "Epoch 37: early stopping\n",
      "54th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05240, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05240 to 0.01500, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01500 to 0.01191, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01191 to 0.01060, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01060 to 0.00979, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00979 to 0.00909, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00909 to 0.00786, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00786 to 0.00579, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00579 to 0.00540, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00540 to 0.00508, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00508\n",
      "\n",
      "Epoch 12: loss improved from 0.00508 to 0.00499, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00499 to 0.00484, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 16: loss improved from 0.00484 to 0.00479, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00479 to 0.00468, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00468\n",
      "\n",
      "Epoch 19: loss improved from 0.00468 to 0.00465, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00465\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00465\n",
      "\n",
      "Epoch 22: loss improved from 0.00465 to 0.00457, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00457 to 0.00442, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 26: loss improved from 0.00442 to 0.00434, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00434 to 0.00414, saving model to ../result\\lstmA_gruE_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00414\n",
      "Epoch 32: early stopping\n",
      "55th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05784, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05784 to 0.01681, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01681 to 0.01321, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01321 to 0.01237, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01237 to 0.01052, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01052 to 0.00798, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00798 to 0.00683, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00683 to 0.00597, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00597 to 0.00566, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00566\n",
      "\n",
      "Epoch 11: loss improved from 0.00566 to 0.00541, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00541 to 0.00524, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00524\n",
      "\n",
      "Epoch 14: loss improved from 0.00524 to 0.00491, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00491\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00491\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00491\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00491\n",
      "\n",
      "Epoch 19: loss improved from 0.00491 to 0.00488, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 22: loss improved from 0.00488 to 0.00488, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 25: loss improved from 0.00488 to 0.00482, saving model to ../result\\lstmA_gruE_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00482\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00482\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00482\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00482\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00482\n",
      "Epoch 30: early stopping\n",
      "56th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06133, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06133 to 0.01816, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01816 to 0.01385, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01385 to 0.01207, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01207 to 0.01046, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01046 to 0.01033, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01033 to 0.00899, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00899 to 0.00787, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00787 to 0.00697, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00697 to 0.00595, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00595\n",
      "\n",
      "Epoch 12: loss improved from 0.00595 to 0.00530, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00530 to 0.00524, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00524\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00524\n",
      "\n",
      "Epoch 16: loss improved from 0.00524 to 0.00516, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00516\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00516\n",
      "\n",
      "Epoch 19: loss improved from 0.00516 to 0.00500, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00500 to 0.00481, saving model to ../result\\lstmA_gruE_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00481\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00481\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00481\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00481\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00481\n",
      "Epoch 25: early stopping\n",
      "57th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07221, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07221 to 0.02144, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02144 to 0.01386, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01386 to 0.01135, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01135 to 0.01045, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01045 to 0.00934, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00934 to 0.00807, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00807 to 0.00657, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00657 to 0.00567, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00567 to 0.00538, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00538 to 0.00530, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00530 to 0.00500, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00500 to 0.00494, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 16: loss improved from 0.00494 to 0.00487, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00487\n",
      "\n",
      "Epoch 18: loss improved from 0.00487 to 0.00475, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 22: loss improved from 0.00475 to 0.00464, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00464\n",
      "\n",
      "Epoch 24: loss improved from 0.00464 to 0.00458, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00458\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00458\n",
      "\n",
      "Epoch 27: loss improved from 0.00458 to 0.00454, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00454 to 0.00451, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00451\n",
      "\n",
      "Epoch 30: loss improved from 0.00451 to 0.00423, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00423 to 0.00416, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00416\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00416\n",
      "\n",
      "Epoch 34: loss improved from 0.00416 to 0.00414, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 36: loss improved from 0.00414 to 0.00414, saving model to ../result\\lstmA_gruE_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00414\n",
      "Epoch 41: early stopping\n",
      "58th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07689, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07689 to 0.02556, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02556 to 0.01623, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01623 to 0.01259, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01259 to 0.01157, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01157 to 0.01040, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01040 to 0.00957, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00957 to 0.00864, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00864 to 0.00790, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00790 to 0.00645, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00645 to 0.00638, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00638 to 0.00546, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00546 to 0.00531, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00531 to 0.00521, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00521 to 0.00509, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00509 to 0.00499, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 18: loss improved from 0.00499 to 0.00487, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00487\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00487\n",
      "\n",
      "Epoch 21: loss improved from 0.00487 to 0.00484, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00484 to 0.00478, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 25: loss improved from 0.00478 to 0.00469, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00469\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00469\n",
      "\n",
      "Epoch 28: loss improved from 0.00469 to 0.00465, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00465\n",
      "\n",
      "Epoch 30: loss improved from 0.00465 to 0.00460, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00460 to 0.00455, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00455 to 0.00452, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00452\n",
      "\n",
      "Epoch 34: loss improved from 0.00452 to 0.00451, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00451\n",
      "\n",
      "Epoch 36: loss improved from 0.00451 to 0.00424, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00424\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00424\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00424\n",
      "\n",
      "Epoch 40: loss improved from 0.00424 to 0.00421, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00421\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00421\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00421\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00421\n",
      "\n",
      "Epoch 45: loss improved from 0.00421 to 0.00419, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00419 to 0.00409, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00409 to 0.00401, saving model to ../result\\lstmA_gruE_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00401\n",
      "Epoch 52: early stopping\n",
      "59th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07935, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07935 to 0.02709, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02709 to 0.01824, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01824 to 0.01423, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01423 to 0.01292, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01292 to 0.01208, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01208 to 0.01110, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01110 to 0.01046, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.01046\n",
      "\n",
      "Epoch 10: loss improved from 0.01046 to 0.00985, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00985 to 0.00928, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00928 to 0.00847, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00847 to 0.00817, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00817 to 0.00617, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00617 to 0.00574, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00574 to 0.00534, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00534 to 0.00531, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00531 to 0.00517, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00517 to 0.00516, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00516 to 0.00511, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00511\n",
      "\n",
      "Epoch 22: loss improved from 0.00511 to 0.00503, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00503 to 0.00485, saving model to ../result\\lstmA_gruE_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00485\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00485\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00485\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00485\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00485\n",
      "Epoch 28: early stopping\n",
      "60th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.09496, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.09496 to 0.02960, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02960 to 0.02008, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02008 to 0.01531, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01531 to 0.01417, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01417 to 0.01318, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01318 to 0.01226, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01226 to 0.01127, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01127 to 0.01038, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01038 to 0.01028, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.01028\n",
      "\n",
      "Epoch 12: loss improved from 0.01028 to 0.01005, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01005 to 0.00946, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00946 to 0.00856, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00856 to 0.00677, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00677 to 0.00635, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00635 to 0.00595, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00595 to 0.00578, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00578 to 0.00577, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00577 to 0.00557, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00557 to 0.00545, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00545 to 0.00544, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00544 to 0.00539, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00539 to 0.00506, saving model to ../result\\lstmA_gruE_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00506\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00506\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00506\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00506\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00506\n",
      "Epoch 29: early stopping\n",
      "61th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10799, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.10799 to 0.03482, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03482 to 0.02509, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02509 to 0.01861, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01861 to 0.01489, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01489 to 0.01318, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01318 to 0.01236, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01236 to 0.01153, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01153 to 0.01088, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01088 to 0.01031, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01031 to 0.00997, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00997 to 0.00980, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00980 to 0.00943, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00943 to 0.00893, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00893 to 0.00840, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00840 to 0.00818, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00818 to 0.00703, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00703 to 0.00591, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00591 to 0.00542, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00542 to 0.00528, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00528 to 0.00515, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00515 to 0.00502, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00502 to 0.00502, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00502\n",
      "\n",
      "Epoch 25: loss improved from 0.00502 to 0.00491, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00491 to 0.00482, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00482\n",
      "\n",
      "Epoch 28: loss improved from 0.00482 to 0.00477, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00477 to 0.00475, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 32: loss improved from 0.00475 to 0.00465, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00465\n",
      "\n",
      "Epoch 34: loss improved from 0.00465 to 0.00462, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00462 to 0.00448, saving model to ../result\\lstmA_gruE_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00448\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00448\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00448\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00448\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00448\n",
      "Epoch 40: early stopping\n",
      "62th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11530, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11530 to 0.04160, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04160 to 0.02710, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02710 to 0.02065, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02065 to 0.01755, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01755 to 0.01466, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01466 to 0.01427, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01427 to 0.01330, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01330 to 0.01266, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01266 to 0.01194, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01194 to 0.01120, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01120 to 0.01088, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01088 to 0.01044, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01044 to 0.01029, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01029 to 0.00966, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00966 to 0.00937, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00937 to 0.00896, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00896 to 0.00840, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00840 to 0.00759, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00759 to 0.00736, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00736 to 0.00638, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00638 to 0.00600, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00600 to 0.00560, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00560 to 0.00532, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00532 to 0.00525, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00525 to 0.00513, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00513\n",
      "\n",
      "Epoch 28: loss improved from 0.00513 to 0.00494, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00494 to 0.00483, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00483\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00483\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00483\n",
      "\n",
      "Epoch 33: loss improved from 0.00483 to 0.00476, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00476 to 0.00464, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00464\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00464\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00464\n",
      "\n",
      "Epoch 38: loss improved from 0.00464 to 0.00461, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00461 to 0.00456, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00456 to 0.00454, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00454 to 0.00451, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00451 to 0.00440, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00440 to 0.00440, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00440 to 0.00436, saving model to ../result\\lstmA_gruE_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00436\n",
      "Epoch 49: early stopping\n",
      "63th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12015, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12015 to 0.04473, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04473 to 0.02828, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02828 to 0.02235, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02235 to 0.01868, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01868 to 0.01625, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01625 to 0.01477, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01477 to 0.01410, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01410 to 0.01352, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01352 to 0.01259, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01259 to 0.01183, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01183 to 0.01151, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01151 to 0.01121, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01121 to 0.01045, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01045 to 0.00991, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00991 to 0.00860, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00860 to 0.00749, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00749 to 0.00708, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00708 to 0.00669, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00669 to 0.00639, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00639 to 0.00623, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00623 to 0.00594, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00594 to 0.00584, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00584 to 0.00559, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00559\n",
      "\n",
      "Epoch 26: loss improved from 0.00559 to 0.00548, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00548 to 0.00532, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00532 to 0.00514, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00514\n",
      "\n",
      "Epoch 30: loss improved from 0.00514 to 0.00510, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00510 to 0.00508, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00508 to 0.00502, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00502 to 0.00486, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 38: loss improved from 0.00486 to 0.00485, saving model to ../result\\lstmA_gruE_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00485\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00485\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00485\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00485\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00485\n",
      "Epoch 43: early stopping\n",
      "64th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12272, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12272 to 0.05164, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05164 to 0.02980, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02980 to 0.02677, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02677 to 0.02189, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02189 to 0.01850, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01850 to 0.01619, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01619 to 0.01472, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01472 to 0.01337, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01337 to 0.01271, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01271 to 0.01236, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01236 to 0.01156, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01156 to 0.01117, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01117 to 0.01084, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01084 to 0.01044, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01044 to 0.01027, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01027\n",
      "\n",
      "Epoch 18: loss improved from 0.01027 to 0.01000, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01000 to 0.00883, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00883 to 0.00819, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00819 to 0.00713, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00713\n",
      "\n",
      "Epoch 23: loss improved from 0.00713 to 0.00694, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00694 to 0.00653, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00653\n",
      "\n",
      "Epoch 26: loss improved from 0.00653 to 0.00618, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00618 to 0.00598, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00598 to 0.00593, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00593\n",
      "\n",
      "Epoch 30: loss improved from 0.00593 to 0.00579, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00579 to 0.00560, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00560 to 0.00558, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00558 to 0.00550, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00550 to 0.00539, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00539 to 0.00525, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00525 to 0.00513, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00513 to 0.00511, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00511 to 0.00508, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00508\n",
      "\n",
      "Epoch 40: loss improved from 0.00508 to 0.00493, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00493\n",
      "\n",
      "Epoch 43: loss improved from 0.00493 to 0.00476, saving model to ../result\\lstmA_gruE_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00476\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00476\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00476\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00476\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00476\n",
      "Epoch 48: early stopping\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000220BA381120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000220BA851FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO: [layers, units, batch_size, dropout, look_back, is_ema]\n",
    "num_features = [1,2]\n",
    "layers = [[False, True, True]] # at this file, not effect\n",
    "units = [[64,64,32,16], [64, 128,  64, 32]]\n",
    "config = [num_features, layers, units, [1, 2, 4, 8], [0.2],[10,12,15,17], [True]] \n",
    "df = read_data('../temp_data/influA_vietnam_last_10_days.csv', num_features=1)\n",
    "hist = LSTM_HyperParameter_Tuning(config, df, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(r\"D:\\my_study\\gr3\\DATN\\result\\lstmA_gruE_ema\\35\\best_lstm_m2m_model.keras\")\n",
    "df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=2)\n",
    "trainX, trainY, testX, testY = prepare_data(df, 17, scaler, is_ema=True)\n",
    "testY_hat = forecast(testX, model)\n",
    "y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "y_inverse = inverse_transform(testY, scaler)\n",
    "plot(y_inverse, y_hat_inverse)\n",
    "# save_plot(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten(), 'abc.png')\n",
    "# model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.195743\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(np.sqrt(mean_squared_error(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
