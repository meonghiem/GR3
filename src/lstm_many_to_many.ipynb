{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "scaler = MinMaxScaler()\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN, LSTM, TimeDistributed, Input, Dropout, GRU\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from keras.saving import register_keras_serializable\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0, len(dataset)-2 *look_back+1, look_back):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back: i+ 2*look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def exponential_moving_average(data, span):\n",
    "    return data.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def read_data(file_path, num_features = 1):\n",
    "    from pandas import read_csv\n",
    "    series_influ_A_df = read_csv(file_path, index_col=0, engine='python')\n",
    "    series_influ_A_df = series_influ_A_df.rename(columns= {\"Influenza A - All types of surveillance\": \"case\"})\n",
    "    series_influ_A_df = series_influ_A_df[[\"case\", \"humidity\", \"temp\", \"dew\",\"windspeed\", \"tempmax\",][:num_features]]\n",
    "    return series_influ_A_df.dropna()\n",
    "\n",
    "def prepare_data(series, look_back, scaler, is_ema = False):\n",
    "    if is_ema:\n",
    "        span = 52  # Bạn có thể điều chỉnh độ dài span tùy ý\n",
    "        series['case'] = exponential_moving_average(series['case'], span)\n",
    "    series = series.astype('float32')\n",
    "    series = series.values\n",
    "    if scaler is not None:\n",
    "        flattened_dataset = series.flatten()\n",
    "        dataset = scaler.fit_transform(flattened_dataset.reshape(-1,1))\n",
    "        dataset = dataset.reshape(series.shape)\n",
    "\n",
    "    else: \n",
    "        dataset = series\n",
    "\n",
    "    rest = len(dataset) % look_back\n",
    "    dataset = dataset[rest:, :]\n",
    "    trainsize = len(dataset) - look_back\n",
    "    train = dataset[:trainsize, :]\n",
    "    test = dataset[trainsize - look_back:, :]\n",
    "\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "def forecast(input, model):\n",
    "    predicted = model.predict(input, verbose=0)\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def save_plot(x,y, file_path):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy import stats\n",
    "\n",
    "    # Generate some sample data\n",
    "    # x = y_inverse.flatten()\n",
    "    # y = y_hat_inverse.flatten()\n",
    "\n",
    "    # Compute the linear regression line\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    # Create the R-squared line\n",
    "    r2_line = slope * x + intercept\n",
    "    r2 = r2_score(x, y)\n",
    "    r2_pearson = r_value**2\n",
    "    squared_error = np.square(x-y)\n",
    "\n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(x, y, label='Data Points')\n",
    "    plt.plot(x, squared_error, color='red', marker=\"o\", label=f'squared Error (R²={r2:.2f})')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('actual number of infection')\n",
    "    plt.ylabel('forecast number of infection')\n",
    "    plt.title('Scatter Plot with R-squared Line')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "\n",
    "def inverse_transform(data, scaler):\n",
    "    flattened_data = data.flatten()\n",
    "    inverse_flattened_data = scaler.inverse_transform(flattened_data.reshape(-1,1))\n",
    "    return inverse_flattened_data.reshape(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class MyLSTM (Sequential):\n",
    "    def __init__(self, look_back, dense_units =[],unit=64, optimizer='adam',name='lstm'):\n",
    "        super().__init__(name=name)\n",
    "        self.look_back = look_back\n",
    "        self.add(Input(shape=(look_back,1)))\n",
    "        self.add(LSTM(units=unit, activation='relu', return_sequences=True))\n",
    "        for unit in dense_units:\n",
    "            self.add(Dense(units=unit, activation='relu'))\n",
    "        self.add(TimeDistributed(Dense(units=5, activation='sigmoid' )))\n",
    "        self.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "\n",
    "def build_model(input_shape, dropout=None, dense_units = [], unit=64, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(LSTM(units=unit, activation='relu', return_sequences=True))\n",
    "\n",
    "    # if first_additional_layer:\n",
    "    #     model.add(LSTM(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "\n",
    "    # if second_additional_layer:\n",
    "    #     model.add(LSTM(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "\n",
    "    # if third_additional_layer:\n",
    "    #     model.add(GRU(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "    for unit in dense_units:\n",
    "        model.add(Dense(units=unit, activation='relu'))\n",
    "    model.add(TimeDistributed(Dense(units=input_shape[1], activation='sigmoid' )))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat_inverse = np.expand_dims(scaler.inverse_transform(testY_hat[0]), axis=0)\n",
    "# y_inverse = np.expand_dims(scaler.inverse_transform(testY[0]), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(testY, forecasts):\n",
    "    import matplotlib.pyplot as plt\n",
    "    forecastsPlot = forecasts[:,:,0].reshape(-1)\n",
    "    testPlot = testY[:,:,0].reshape(-1)\n",
    "    plt.plot(testPlot, \"-y\", label=\"actual\", marker= '.')\n",
    "    plt.plot(forecastsPlot, color = 'green', label=\"forecast\")\n",
    "    plt.ylabel(\"Number of infections\")\n",
    "    plt.legend([\"actual\", \"forecast\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(y_inverse, y_hat_inverse)\n",
    "# print(model.predict(trainX).shape)\n",
    "# print(trainY.shape)\n",
    "# forecasts = model.predict(trainX)\n",
    "# plot(trainY, forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os, json\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def LSTM_HyperParameter_Tuning(config, df, scaler):\n",
    "    \n",
    "    n_neurons, n_batch_sizes, dropouts, look_backs, is_emas = config\n",
    "    possible_combinations = list(itertools.product(n_neurons, n_batch_sizes, dropouts, look_backs, is_emas))\n",
    "    \n",
    "    print(possible_combinations)\n",
    "    print('\\n')\n",
    "    \n",
    "    hist = []\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "        print(f'{i+1}th combination: \\n')\n",
    "        print('--------------------------------------------------------------------')\n",
    "        n_neurons, n_batch_size, dropout, look_back, is_ema = possible_combinations[i]\n",
    "\n",
    "        df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=2)\n",
    "        \n",
    "        trainX, trainY, testX, testY = prepare_data(df, look_back, scaler, is_ema=is_ema)\n",
    "        model = build_model(input_shape=(trainX.shape[1], trainX.shape[2]), dense_units=n_neurons[1:], unit=n_neurons[0])\n",
    "\n",
    "        es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "        '''''\n",
    "        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n",
    "        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n",
    "        '''''\n",
    "        a = 'ema' if is_ema else 'not_ema'\n",
    "        lstm_dir = os.path.join(\"../result\", f\"\"\"lstm_{a}\"\"\")\n",
    "        lstm_combination_dir = os.path.join(lstm_dir, str(i))\n",
    "        os.makedirs(lstm_combination_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(lstm_combination_dir, 'best_lstm_m2m_model.keras')\n",
    "\n",
    "        mc = ModelCheckpoint(file_path, monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "        '''''\n",
    "        cb = Callback(...)  # First, callbacks must be instantiated.\n",
    "        cb_list = [cb, ...]  # Then, one or more callbacks that you intend to use must be added to a Python list.\n",
    "        model.fit(..., callbacks=cb_list)  # Finally, the list of callbacks is provided to the callback argument when fitting the model.\n",
    "        '''''\n",
    "\n",
    "        model.fit(trainX, trainY,batch_size=n_batch_size, callbacks=[es, mc], verbose=0, epochs=200)\n",
    "        train_accuracy = model.evaluate(trainX, trainY, verbose=0)\n",
    "        # test_accuracy = model.evaluate(testX, testY, verbose=0)\n",
    "        # hist.append(list((n_neurons, n_batch_size, dropout,look_back,\n",
    "        #                   train_accuracy, test_accuracy)))\n",
    "        hist.append(list((n_neurons, n_batch_size, dropout,look_back,\n",
    "                          train_accuracy)))\n",
    "        \n",
    "        \n",
    "        config= {\n",
    "            \"units\": n_neurons,\n",
    "            \"n_batch_size\": n_batch_size,\n",
    "            \"dropout\": dropout,\n",
    "            \"look_back\": look_back,\n",
    "            \"is_ema\": is_ema\n",
    "        }\n",
    "        with open(os.path.join(lstm_combination_dir,'config.json'), 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "        \n",
    "\n",
    "        # print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy}')\n",
    "        \n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "\n",
    "        n_neurons, n_batch_size, dropout, look_back, is_ema = possible_combinations[i]\n",
    "        df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=2)\n",
    "        trainX, trainY, testX, testY = prepare_data(df, look_back, scaler, is_ema=is_ema)\n",
    "\n",
    "        a = 'ema' if is_ema else 'not_ema'\n",
    "        lstm_dir = os.path.join(\"../result\", f\"\"\"lstm_{a}\"\"\")\n",
    "        lstm_combination_dir = os.path.join(lstm_dir, str(i))\n",
    "        os.makedirs(lstm_combination_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(lstm_combination_dir, 'best_lstm_m2m_model.keras')\n",
    "\n",
    "\n",
    "        model = load_model(file_path)\n",
    "\n",
    "        #TODO: save r square\n",
    "        testY_hat = forecast(testX, model)\n",
    "        y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "        y_inverse = inverse_transform(testY, scaler)\n",
    "\n",
    "        r2_image_path = os.path.join(lstm_combination_dir, 'r2_image.png')\n",
    "        save_plot(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten(), r2_image_path)\n",
    "        \n",
    "    import pandas as pd\n",
    "    hist_df = pd.DataFrame(hist)\n",
    "    hist_df = hist_df.rename(columns={0: 'units', 1: 'batch_size', 2: 'dropout', 3: 'look_back', 4: 'train_loss'})\n",
    "    hist_df = hist_df.sort_values(by=['train_loss'], ascending=True)\n",
    "    hist_df.to_csv(os.path.join(lstm_dir, 'history.csv'))\n",
    "    return hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([64], 1, 0.2, 10, True), ([64], 1, 0.2, 12, True), ([64], 1, 0.2, 15, True), ([64], 1, 0.2, 17, True), ([64], 2, 0.2, 10, True), ([64], 2, 0.2, 12, True), ([64], 2, 0.2, 15, True), ([64], 2, 0.2, 17, True), ([64], 4, 0.2, 10, True), ([64], 4, 0.2, 12, True), ([64], 4, 0.2, 15, True), ([64], 4, 0.2, 17, True), ([64], 8, 0.2, 10, True), ([64], 8, 0.2, 12, True), ([64], 8, 0.2, 15, True), ([64], 8, 0.2, 17, True)]\n",
      "\n",
      "\n",
      "1th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06622, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06622 to 0.02359, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02359 to 0.01472, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01472 to 0.01069, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01069 to 0.00858, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00858 to 0.00741, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00741 to 0.00649, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00649 to 0.00589, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00589 to 0.00547, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00547 to 0.00512, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00512 to 0.00487, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00487 to 0.00471, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00471 to 0.00466, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00466 to 0.00454, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00454 to 0.00443, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00443 to 0.00431, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00431 to 0.00428, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 19: loss improved from 0.00428 to 0.00418, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00418 to 0.00411, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00411 to 0.00398, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00398\n",
      "\n",
      "Epoch 23: loss improved from 0.00398 to 0.00397, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00397 to 0.00394, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00394 to 0.00376, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00376\n",
      "Epoch 30: early stopping\n",
      "2th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08399, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08399 to 0.03047, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03047 to 0.01951, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01951 to 0.01357, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01357 to 0.01049, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01049 to 0.00882, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00882 to 0.00764, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00764 to 0.00685, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00685 to 0.00627, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00627 to 0.00584, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00584 to 0.00535, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00535 to 0.00504, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00504 to 0.00491, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00491 to 0.00478, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00478 to 0.00458, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00458 to 0.00433, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00433 to 0.00428, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00428 to 0.00425, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00425\n",
      "\n",
      "Epoch 20: loss improved from 0.00425 to 0.00414, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00414 to 0.00403, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00403 to 0.00400, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 24: loss improved from 0.00400 to 0.00399, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00399 to 0.00397, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00397 to 0.00392, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 29: loss improved from 0.00392 to 0.00384, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 32: loss improved from 0.00384 to 0.00382, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00382 to 0.00379, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00379\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00379\n",
      "\n",
      "Epoch 36: loss improved from 0.00379 to 0.00377, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00377\n",
      "\n",
      "Epoch 38: loss improved from 0.00377 to 0.00369, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00369\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00369\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00369\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00369\n",
      "\n",
      "Epoch 43: loss improved from 0.00369 to 0.00366, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00366\n",
      "Epoch 48: early stopping\n",
      "3th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07856, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07856 to 0.03155, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03155 to 0.02518, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02518 to 0.01766, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01766 to 0.01415, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01415 to 0.01165, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01165 to 0.00932, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00932 to 0.00826, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00826 to 0.00752, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00752 to 0.00709, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00709 to 0.00661, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00661 to 0.00613, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00613 to 0.00592, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00592 to 0.00561, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00561 to 0.00538, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00538 to 0.00525, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00525 to 0.00511, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00511 to 0.00495, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00495 to 0.00486, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00486 to 0.00474, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00474\n",
      "\n",
      "Epoch 22: loss improved from 0.00474 to 0.00457, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00457\n",
      "\n",
      "Epoch 24: loss improved from 0.00457 to 0.00442, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00442 to 0.00434, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00434\n",
      "\n",
      "Epoch 27: loss improved from 0.00434 to 0.00434, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00434 to 0.00428, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00428 to 0.00424, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00424 to 0.00414, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 33: loss improved from 0.00414 to 0.00407, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00407\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00407\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00407\n",
      "\n",
      "Epoch 37: loss improved from 0.00407 to 0.00405, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00405 to 0.00404, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 40: loss improved from 0.00404 to 0.00396, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 43: loss improved from 0.00396 to 0.00393, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 45: loss improved from 0.00393 to 0.00389, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 49: loss improved from 0.00389 to 0.00384, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 52: loss improved from 0.00384 to 0.00382, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.00382 to 0.00374, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00374\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00374\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00374\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00374\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00374\n",
      "Epoch 58: early stopping\n",
      "4th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06729, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06729 to 0.02398, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02398 to 0.01630, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01630 to 0.01290, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01290 to 0.01114, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01114 to 0.00973, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00973 to 0.00875, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00875 to 0.00801, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00801 to 0.00752, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00752 to 0.00705, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00705 to 0.00672, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00672 to 0.00629, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00629 to 0.00613, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00613 to 0.00571, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00571 to 0.00564, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00564 to 0.00540, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00540 to 0.00522, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00522 to 0.00513, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00513 to 0.00503, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00503\n",
      "\n",
      "Epoch 21: loss improved from 0.00503 to 0.00485, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00485\n",
      "\n",
      "Epoch 23: loss improved from 0.00485 to 0.00484, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00484 to 0.00478, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00478 to 0.00470, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00470 to 0.00470, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00470 to 0.00452, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00452\n",
      "\n",
      "Epoch 29: loss improved from 0.00452 to 0.00445, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00445 to 0.00439, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00439 to 0.00433, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00433 to 0.00428, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 37: loss improved from 0.00428 to 0.00423, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00423\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00423\n",
      "\n",
      "Epoch 40: loss improved from 0.00423 to 0.00409, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00409\n",
      "\n",
      "Epoch 42: loss improved from 0.00409 to 0.00406, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 46: loss improved from 0.00406 to 0.00403, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00403\n",
      "Epoch 51: early stopping\n",
      "5th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10076, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.10076 to 0.04038, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04038 to 0.02722, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02722 to 0.02129, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02129 to 0.01753, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01753 to 0.01378, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01378 to 0.01182, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01182 to 0.01026, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01026 to 0.00903, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00903 to 0.00815, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00815 to 0.00759, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00759 to 0.00702, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00702 to 0.00656, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00656 to 0.00604, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00604 to 0.00589, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00589 to 0.00548, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00548 to 0.00539, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00539 to 0.00512, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00512 to 0.00494, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00494 to 0.00472, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00472 to 0.00458, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00458 to 0.00454, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00454 to 0.00445, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00445 to 0.00441, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00441 to 0.00416, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00416\n",
      "\n",
      "Epoch 27: loss improved from 0.00416 to 0.00400, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00400 to 0.00399, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 30: loss improved from 0.00399 to 0.00393, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 32: loss improved from 0.00393 to 0.00391, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00391\n",
      "\n",
      "Epoch 34: loss improved from 0.00391 to 0.00389, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00389 to 0.00378, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 38: loss improved from 0.00378 to 0.00377, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00377 to 0.00376, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 43: loss improved from 0.00376 to 0.00373, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 46: loss improved from 0.00373 to 0.00368, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00368 to 0.00366, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 49: loss improved from 0.00366 to 0.00362, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00362\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00362\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00362\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00362\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00362\n",
      "Epoch 54: early stopping\n",
      "6th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12960, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12960 to 0.06974, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.06974 to 0.03521, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03521 to 0.02378, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02378 to 0.01861, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01861 to 0.01467, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01467 to 0.01231, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01231 to 0.01076, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01076 to 0.00965, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00965 to 0.00877, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00877 to 0.00815, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00815 to 0.00760, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00760 to 0.00721, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00721 to 0.00686, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00686 to 0.00639, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00639 to 0.00613, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00613 to 0.00591, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00591 to 0.00570, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00570 to 0.00558, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00558 to 0.00535, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00535 to 0.00524, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00524 to 0.00513, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00513 to 0.00504, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00504 to 0.00490, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00490 to 0.00480, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00480 to 0.00474, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00474\n",
      "\n",
      "Epoch 28: loss improved from 0.00474 to 0.00457, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00457 to 0.00450, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00450 to 0.00441, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00441 to 0.00436, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00436 to 0.00427, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00427 to 0.00418, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00418\n",
      "\n",
      "Epoch 35: loss improved from 0.00418 to 0.00417, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 37: loss improved from 0.00417 to 0.00407, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00407 to 0.00400, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 42: loss improved from 0.00400 to 0.00392, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 45: loss improved from 0.00392 to 0.00391, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00391\n",
      "\n",
      "Epoch 47: loss improved from 0.00391 to 0.00386, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00386 to 0.00383, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00383\n",
      "Epoch 53: early stopping\n",
      "7th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11525, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11525 to 0.05148, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05148 to 0.03374, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03374 to 0.02627, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02627 to 0.02131, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02131 to 0.01833, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01833 to 0.01567, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01567 to 0.01366, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01366 to 0.01228, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01228 to 0.01111, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01111 to 0.01003, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01003 to 0.00911, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00911 to 0.00837, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00837 to 0.00779, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00779 to 0.00735, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00735 to 0.00696, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00696 to 0.00660, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00660 to 0.00636, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00636 to 0.00610, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00610 to 0.00586, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00586 to 0.00571, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00571 to 0.00550, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00550 to 0.00545, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00545 to 0.00541, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00541 to 0.00527, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00527 to 0.00521, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00521 to 0.00505, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00505 to 0.00504, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00504 to 0.00493, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00493 to 0.00490, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00490 to 0.00486, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00486 to 0.00474, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00474\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00474\n",
      "\n",
      "Epoch 35: loss improved from 0.00474 to 0.00470, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00470 to 0.00470, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00470 to 0.00464, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00464 to 0.00462, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00462 to 0.00460, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00460\n",
      "\n",
      "Epoch 41: loss improved from 0.00460 to 0.00458, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00458 to 0.00452, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00452\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00452\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00452\n",
      "\n",
      "Epoch 46: loss improved from 0.00452 to 0.00445, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 48: loss improved from 0.00445 to 0.00442, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00442 to 0.00440, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00440 to 0.00437, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 54: loss improved from 0.00437 to 0.00430, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00430 to 0.00428, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 58: loss improved from 0.00428 to 0.00419, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss improved from 0.00419 to 0.00416, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss improved from 0.00416 to 0.00415, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss improved from 0.00415 to 0.00411, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 62: loss improved from 0.00411 to 0.00405, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss did not improve from 0.00405\n",
      "\n",
      "Epoch 64: loss did not improve from 0.00405\n",
      "\n",
      "Epoch 65: loss improved from 0.00405 to 0.00401, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 66: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 67: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 68: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 69: loss improved from 0.00401 to 0.00399, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 70: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 71: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 72: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 73: loss improved from 0.00399 to 0.00397, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 74: loss improved from 0.00397 to 0.00396, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss improved from 0.00396 to 0.00395, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 77: loss improved from 0.00395 to 0.00386, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 78: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 79: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 80: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 81: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 82: loss did not improve from 0.00386\n",
      "Epoch 82: early stopping\n",
      "8th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12541, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12541 to 0.06918, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.06918 to 0.03888, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03888 to 0.03405, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03405 to 0.03132, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03132 to 0.02888, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02888 to 0.02872, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02872 to 0.02728, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02728\n",
      "\n",
      "Epoch 10: loss improved from 0.02728 to 0.02705, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02705 to 0.02641, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02641 to 0.02565, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02565 to 0.02485, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02485 to 0.02402, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02402 to 0.02306, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02306 to 0.02198, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02198 to 0.02058, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02058 to 0.01841, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01841 to 0.01427, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01427 to 0.01071, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01071 to 0.00943, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00943 to 0.00820, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00820 to 0.00739, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00739 to 0.00717, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00717 to 0.00692, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00692 to 0.00657, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00657 to 0.00641, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00641 to 0.00610, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00610 to 0.00607, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00607 to 0.00583, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00583 to 0.00572, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00572 to 0.00562, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00562 to 0.00537, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00537\n",
      "\n",
      "Epoch 35: loss improved from 0.00537 to 0.00535, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00535 to 0.00519, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00519 to 0.00500, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00500 to 0.00496, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00496 to 0.00489, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00489 to 0.00477, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00477 to 0.00472, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00472 to 0.00472, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 44: loss improved from 0.00472 to 0.00456, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00456 to 0.00456, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00456\n",
      "\n",
      "Epoch 47: loss improved from 0.00456 to 0.00453, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00453 to 0.00441, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 51: loss improved from 0.00441 to 0.00440, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00440\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00440\n",
      "\n",
      "Epoch 54: loss improved from 0.00440 to 0.00438, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00438 to 0.00437, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00437 to 0.00425, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00425 to 0.00424, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.00424 to 0.00418, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00418\n",
      "\n",
      "Epoch 60: loss improved from 0.00418 to 0.00417, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 62: loss improved from 0.00417 to 0.00411, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00411 to 0.00406, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 65: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 66: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 67: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 68: loss did not improve from 0.00406\n",
      "Epoch 68: early stopping\n",
      "9th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11963, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11963 to 0.08315, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.08315 to 0.04561, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04561 to 0.03668, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03668 to 0.02913, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02913 to 0.02537, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02537 to 0.02216, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02216 to 0.01957, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01957 to 0.01736, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01736 to 0.01551, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01551 to 0.01347, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01347 to 0.01177, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01177 to 0.01065, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01065 to 0.00984, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00984 to 0.00919, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00919 to 0.00866, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00866 to 0.00808, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00808 to 0.00768, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00768 to 0.00735, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00735 to 0.00700, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00700 to 0.00666, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00666 to 0.00635, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00635 to 0.00621, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00621 to 0.00602, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00602 to 0.00586, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00586 to 0.00550, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00550 to 0.00550, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00550 to 0.00523, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00523 to 0.00512, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00512 to 0.00497, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00497 to 0.00490, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00490 to 0.00479, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00479 to 0.00464, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00464 to 0.00458, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00458 to 0.00446, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00446\n",
      "\n",
      "Epoch 37: loss improved from 0.00446 to 0.00436, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00436 to 0.00433, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00433 to 0.00432, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00432 to 0.00420, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00420 to 0.00420, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00420 to 0.00413, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00413 to 0.00412, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00412\n",
      "\n",
      "Epoch 45: loss improved from 0.00412 to 0.00403, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00403 to 0.00400, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 48: loss improved from 0.00400 to 0.00397, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00397\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00397\n",
      "\n",
      "Epoch 51: loss improved from 0.00397 to 0.00394, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00394\n",
      "\n",
      "Epoch 53: loss improved from 0.00394 to 0.00391, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.00391 to 0.00390, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00390 to 0.00385, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00385 to 0.00385, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00385\n",
      "\n",
      "Epoch 58: loss improved from 0.00385 to 0.00384, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 60: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 62: loss improved from 0.00384 to 0.00376, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 64: loss improved from 0.00376 to 0.00376, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 65: loss improved from 0.00376 to 0.00370, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 66: loss did not improve from 0.00370\n",
      "\n",
      "Epoch 67: loss did not improve from 0.00370\n",
      "\n",
      "Epoch 68: loss did not improve from 0.00370\n",
      "\n",
      "Epoch 69: loss did not improve from 0.00370\n",
      "\n",
      "Epoch 70: loss did not improve from 0.00370\n",
      "Epoch 70: early stopping\n",
      "10th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12484, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12484 to 0.08741, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.08741 to 0.04675, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04675 to 0.03821, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03821 to 0.03327, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03327 to 0.03108, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03108 to 0.02706, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02706 to 0.02396, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02396 to 0.02254, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02254 to 0.02065, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02065 to 0.01949, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01949 to 0.01838, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01838 to 0.01749, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01749 to 0.01644, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01644 to 0.01565, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01565 to 0.01528, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01528 to 0.01432, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01432 to 0.01351, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01351 to 0.01288, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01288 to 0.01221, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01221 to 0.01160, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01160 to 0.01092, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01092 to 0.00959, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00959 to 0.00840, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00840 to 0.00790, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00790 to 0.00754, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00754 to 0.00715, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00715 to 0.00691, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00691 to 0.00668, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00668 to 0.00647, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00647 to 0.00616, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00616 to 0.00593, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00593 to 0.00578, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00578 to 0.00561, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00561 to 0.00549, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00549 to 0.00528, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00528 to 0.00522, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00522 to 0.00508, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00508 to 0.00508, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00508 to 0.00500, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00500 to 0.00480, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00480 to 0.00477, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00477 to 0.00474, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00474 to 0.00463, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00463 to 0.00455, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00455 to 0.00451, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00451\n",
      "\n",
      "Epoch 48: loss improved from 0.00451 to 0.00448, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00448 to 0.00440, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00440\n",
      "\n",
      "Epoch 51: loss improved from 0.00440 to 0.00430, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00430\n",
      "\n",
      "Epoch 53: loss improved from 0.00430 to 0.00427, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.00427 to 0.00422, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00422\n",
      "\n",
      "Epoch 56: loss improved from 0.00422 to 0.00417, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00417 to 0.00414, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 59: loss improved from 0.00414 to 0.00409, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss did not improve from 0.00409\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00409\n",
      "\n",
      "Epoch 62: loss improved from 0.00409 to 0.00405, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss did not improve from 0.00405\n",
      "\n",
      "Epoch 64: loss did not improve from 0.00405\n",
      "\n",
      "Epoch 65: loss did not improve from 0.00405\n",
      "\n",
      "Epoch 66: loss improved from 0.00405 to 0.00402, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 67: loss improved from 0.00402 to 0.00399, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 68: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 69: loss improved from 0.00399 to 0.00397, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 70: loss did not improve from 0.00397\n",
      "\n",
      "Epoch 71: loss improved from 0.00397 to 0.00393, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 72: loss improved from 0.00393 to 0.00392, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss improved from 0.00392 to 0.00391, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 74: loss improved from 0.00391 to 0.00391, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss improved from 0.00391 to 0.00390, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00390\n",
      "\n",
      "Epoch 77: loss improved from 0.00390 to 0.00386, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 78: loss improved from 0.00386 to 0.00384, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 79: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 80: loss improved from 0.00384 to 0.00382, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 81: loss did not improve from 0.00382\n",
      "\n",
      "Epoch 82: loss did not improve from 0.00382\n",
      "\n",
      "Epoch 83: loss did not improve from 0.00382\n",
      "\n",
      "Epoch 84: loss did not improve from 0.00382\n",
      "\n",
      "Epoch 85: loss improved from 0.00382 to 0.00378, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 86: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 87: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 88: loss improved from 0.00378 to 0.00373, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 89: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 90: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 91: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 92: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 93: loss did not improve from 0.00373\n",
      "Epoch 93: early stopping\n",
      "11th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12063, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12063 to 0.08101, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.08101 to 0.04411, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04411 to 0.03681, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03681 to 0.03378, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03378 to 0.02964, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02964 to 0.02349, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02349 to 0.02058, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02058 to 0.01821, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01821 to 0.01652, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01652 to 0.01532, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01532 to 0.01432, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01432 to 0.01324, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01324 to 0.01247, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01247 to 0.01171, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01171 to 0.01103, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01103 to 0.01042, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01042 to 0.00995, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00995 to 0.00945, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00945 to 0.00904, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00904 to 0.00871, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00871 to 0.00841, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00841 to 0.00796, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00796 to 0.00780, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00780 to 0.00744, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00744 to 0.00726, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00726 to 0.00705, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00705 to 0.00670, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00670 to 0.00657, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00657 to 0.00637, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00637 to 0.00625, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00625 to 0.00609, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00609 to 0.00601, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00601 to 0.00584, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00584 to 0.00568, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00568 to 0.00558, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00558 to 0.00551, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00551 to 0.00549, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00549 to 0.00529, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00529 to 0.00517, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00517\n",
      "\n",
      "Epoch 42: loss improved from 0.00517 to 0.00511, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00511 to 0.00492, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00492 to 0.00488, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00488 to 0.00480, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 47: loss improved from 0.00480 to 0.00469, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00469 to 0.00463, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00463 to 0.00463, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00463\n",
      "\n",
      "Epoch 51: loss improved from 0.00463 to 0.00455, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.00455 to 0.00454, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.00454 to 0.00442, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.00442 to 0.00442, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00442 to 0.00439, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00439 to 0.00433, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00433 to 0.00423, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00423\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00423\n",
      "\n",
      "Epoch 60: loss improved from 0.00423 to 0.00419, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 62: loss improved from 0.00419 to 0.00416, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00416 to 0.00408, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 65: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 66: loss improved from 0.00408 to 0.00404, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 67: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 68: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 69: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 70: loss improved from 0.00404 to 0.00399, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 71: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 72: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 73: loss improved from 0.00399 to 0.00395, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 74: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 75: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 77: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 78: loss did not improve from 0.00395\n",
      "Epoch 78: early stopping\n",
      "12th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12737, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12737 to 0.10219, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.10219 to 0.06319, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.06319 to 0.03910, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03910 to 0.03479, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03479 to 0.03353, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03353 to 0.03202, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03202 to 0.02951, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02951 to 0.02901, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02901 to 0.02767, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02767 to 0.02474, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02474 to 0.02154, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02154 to 0.01957, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01957 to 0.01831, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01831 to 0.01739, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01739 to 0.01666, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01666 to 0.01589, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01589 to 0.01529, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01529 to 0.01465, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01465 to 0.01423, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01423 to 0.01369, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01369 to 0.01304, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01304 to 0.01220, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01220 to 0.01107, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01107 to 0.01042, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01042 to 0.00996, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00996 to 0.00954, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00954 to 0.00922, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00922 to 0.00891, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00891 to 0.00860, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00860 to 0.00820, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00820 to 0.00800, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00800 to 0.00784, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00784 to 0.00763, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00763 to 0.00727, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00727 to 0.00709, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00709 to 0.00691, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00691 to 0.00680, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00680 to 0.00660, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00660 to 0.00641, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00641\n",
      "\n",
      "Epoch 42: loss improved from 0.00641 to 0.00613, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00613 to 0.00611, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00611 to 0.00602, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00602 to 0.00582, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00582 to 0.00573, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00573 to 0.00566, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00566 to 0.00550, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00550 to 0.00538, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00538 to 0.00532, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.00532 to 0.00521, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00521\n",
      "\n",
      "Epoch 53: loss improved from 0.00521 to 0.00519, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.00519 to 0.00504, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00504 to 0.00495, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00495 to 0.00488, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00488 to 0.00479, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.00479 to 0.00475, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss improved from 0.00475 to 0.00474, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss did not improve from 0.00474\n",
      "\n",
      "Epoch 61: loss improved from 0.00474 to 0.00464, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 62: loss improved from 0.00464 to 0.00459, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00459 to 0.00457, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss improved from 0.00457 to 0.00450, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 65: loss did not improve from 0.00450\n",
      "\n",
      "Epoch 66: loss did not improve from 0.00450\n",
      "\n",
      "Epoch 67: loss did not improve from 0.00450\n",
      "\n",
      "Epoch 68: loss did not improve from 0.00450\n",
      "\n",
      "Epoch 69: loss improved from 0.00450 to 0.00442, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 70: loss improved from 0.00442 to 0.00433, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 71: loss did not improve from 0.00433\n",
      "\n",
      "Epoch 72: loss improved from 0.00433 to 0.00426, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 74: loss improved from 0.00426 to 0.00421, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss improved from 0.00421 to 0.00418, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00418\n",
      "\n",
      "Epoch 77: loss did not improve from 0.00418\n",
      "\n",
      "Epoch 78: loss improved from 0.00418 to 0.00418, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 79: loss improved from 0.00418 to 0.00410, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 80: loss did not improve from 0.00410\n",
      "\n",
      "Epoch 81: loss did not improve from 0.00410\n",
      "\n",
      "Epoch 82: loss improved from 0.00410 to 0.00409, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 83: loss did not improve from 0.00409\n",
      "\n",
      "Epoch 84: loss did not improve from 0.00409\n",
      "\n",
      "Epoch 85: loss did not improve from 0.00409\n",
      "\n",
      "Epoch 86: loss did not improve from 0.00409\n",
      "\n",
      "Epoch 87: loss improved from 0.00409 to 0.00408, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 88: loss improved from 0.00408 to 0.00402, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 89: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 90: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 91: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 92: loss improved from 0.00402 to 0.00400, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 93: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 94: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 95: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 96: loss improved from 0.00400 to 0.00396, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 97: loss improved from 0.00396 to 0.00393, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 98: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 99: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 100: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 101: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 102: loss did not improve from 0.00393\n",
      "Epoch 102: early stopping\n",
      "13th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13903, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13903 to 0.12528, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.12528 to 0.11027, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.11027 to 0.08856, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.08856 to 0.05806, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.05806 to 0.04512, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04512 to 0.04017, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.04017 to 0.03708, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03708 to 0.03425, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03425 to 0.02953, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02953 to 0.02659, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02659 to 0.02428, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02428 to 0.02276, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02276 to 0.02103, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02103 to 0.01975, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01975 to 0.01876, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01876 to 0.01783, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01783 to 0.01715, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01715 to 0.01651, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01651 to 0.01574, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01574 to 0.01510, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01510 to 0.01466, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01466 to 0.01428, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01428 to 0.01363, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01363 to 0.01324, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01324 to 0.01288, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01288 to 0.01250, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01250 to 0.01215, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01215 to 0.01183, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01183 to 0.01149, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.01149 to 0.01116, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01116 to 0.01080, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01080 to 0.00965, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00965 to 0.00873, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00873 to 0.00816, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00816 to 0.00797, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00797 to 0.00793, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00793 to 0.00769, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00769 to 0.00745, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00745 to 0.00712, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00712 to 0.00691, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00691 to 0.00678, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00678 to 0.00660, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00660 to 0.00645, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00645 to 0.00632, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00632 to 0.00613, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00613 to 0.00601, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00601 to 0.00591, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00591 to 0.00577, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00577 to 0.00564, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.00564 to 0.00558, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.00558 to 0.00550, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.00550 to 0.00541, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.00541 to 0.00531, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00531 to 0.00520, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00520 to 0.00512, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00512 to 0.00512, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.00512 to 0.00499, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss improved from 0.00499 to 0.00491, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss improved from 0.00491 to 0.00488, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss improved from 0.00488 to 0.00479, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 62: loss did not improve from 0.00479\n",
      "\n",
      "Epoch 63: loss improved from 0.00479 to 0.00479, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss improved from 0.00479 to 0.00460, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 65: loss did not improve from 0.00460\n",
      "\n",
      "Epoch 66: loss improved from 0.00460 to 0.00458, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 67: loss improved from 0.00458 to 0.00456, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 68: loss improved from 0.00456 to 0.00455, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 69: loss improved from 0.00455 to 0.00448, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 70: loss improved from 0.00448 to 0.00443, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 71: loss improved from 0.00443 to 0.00441, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 72: loss improved from 0.00441 to 0.00433, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss did not improve from 0.00433\n",
      "\n",
      "Epoch 74: loss improved from 0.00433 to 0.00426, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss improved from 0.00426 to 0.00424, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 76: loss improved from 0.00424 to 0.00421, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 77: loss improved from 0.00421 to 0.00419, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 78: loss improved from 0.00419 to 0.00417, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 79: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 80: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 81: loss improved from 0.00417 to 0.00414, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 82: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 83: loss improved from 0.00414 to 0.00413, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 84: loss improved from 0.00413 to 0.00412, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 85: loss improved from 0.00412 to 0.00406, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 86: loss improved from 0.00406 to 0.00402, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 87: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 88: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 89: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 90: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 91: loss improved from 0.00402 to 0.00396, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 92: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 93: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 94: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 95: loss improved from 0.00396 to 0.00392, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 96: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 97: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 98: loss improved from 0.00392 to 0.00392, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 99: loss improved from 0.00392 to 0.00386, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 100: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 101: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 102: loss improved from 0.00386 to 0.00386, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 103: loss improved from 0.00386 to 0.00385, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 104: loss did not improve from 0.00385\n",
      "\n",
      "Epoch 105: loss improved from 0.00385 to 0.00383, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 106: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 107: loss improved from 0.00383 to 0.00382, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 108: loss improved from 0.00382 to 0.00382, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 109: loss improved from 0.00382 to 0.00382, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 110: loss did not improve from 0.00382\n",
      "\n",
      "Epoch 111: loss improved from 0.00382 to 0.00381, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 112: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 113: loss improved from 0.00381 to 0.00379, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 114: loss improved from 0.00379 to 0.00379, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 115: loss improved from 0.00379 to 0.00377, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 116: loss improved from 0.00377 to 0.00377, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 117: loss improved from 0.00377 to 0.00376, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 118: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 119: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 120: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 121: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 122: loss did not improve from 0.00376\n",
      "Epoch 122: early stopping\n",
      "14th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12142, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12142 to 0.10642, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.10642 to 0.08885, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.08885 to 0.06650, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.06650 to 0.04533, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04533 to 0.03894, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03894 to 0.03647, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03647 to 0.03459, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03459 to 0.03174, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03174 to 0.02797, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02797 to 0.02575, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02575 to 0.02409, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02409 to 0.02237, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02237 to 0.02071, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02071 to 0.01936, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01936 to 0.01818, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01818 to 0.01715, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01715 to 0.01622, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01622 to 0.01536, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01536 to 0.01453, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01453 to 0.01381, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01381 to 0.01318, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01318 to 0.01263, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01263 to 0.01211, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01211 to 0.01171, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01171 to 0.01149, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01149 to 0.01087, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01087 to 0.01052, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01052 to 0.01008, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01008 to 0.00983, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00983 to 0.00953, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00953 to 0.00928, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00928 to 0.00906, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00906 to 0.00883, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00883 to 0.00861, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00861 to 0.00831, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00831 to 0.00812, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00812 to 0.00791, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00791 to 0.00776, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00776 to 0.00757, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00757 to 0.00741, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00741 to 0.00724, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00724 to 0.00710, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00710 to 0.00693, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00693 to 0.00680, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00680 to 0.00670, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00670 to 0.00653, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00653 to 0.00637, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00637 to 0.00628, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00628 to 0.00614, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.00614 to 0.00600, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.00600 to 0.00597, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.00597 to 0.00587, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.00587 to 0.00566, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00566 to 0.00555, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00555 to 0.00542, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00542 to 0.00538, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.00538 to 0.00531, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss improved from 0.00531 to 0.00513, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss improved from 0.00513 to 0.00509, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss improved from 0.00509 to 0.00503, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 62: loss improved from 0.00503 to 0.00500, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00500 to 0.00486, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss improved from 0.00486 to 0.00480, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 65: loss improved from 0.00480 to 0.00479, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 66: loss did not improve from 0.00479\n",
      "\n",
      "Epoch 67: loss improved from 0.00479 to 0.00469, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 68: loss improved from 0.00469 to 0.00464, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 69: loss improved from 0.00464 to 0.00458, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 70: loss improved from 0.00458 to 0.00457, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 71: loss improved from 0.00457 to 0.00452, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 72: loss improved from 0.00452 to 0.00450, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss improved from 0.00450 to 0.00446, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 74: loss improved from 0.00446 to 0.00436, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 76: loss improved from 0.00436 to 0.00433, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 77: loss improved from 0.00433 to 0.00429, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 78: loss did not improve from 0.00429\n",
      "\n",
      "Epoch 79: loss improved from 0.00429 to 0.00424, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 80: loss improved from 0.00424 to 0.00422, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 81: loss did not improve from 0.00422\n",
      "\n",
      "Epoch 82: loss did not improve from 0.00422\n",
      "\n",
      "Epoch 83: loss improved from 0.00422 to 0.00419, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 84: loss improved from 0.00419 to 0.00410, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 85: loss did not improve from 0.00410\n",
      "\n",
      "Epoch 86: loss improved from 0.00410 to 0.00410, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 87: loss did not improve from 0.00410\n",
      "\n",
      "Epoch 88: loss improved from 0.00410 to 0.00403, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 89: loss improved from 0.00403 to 0.00398, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 90: loss improved from 0.00398 to 0.00396, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 91: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 92: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 93: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 94: loss improved from 0.00396 to 0.00393, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 95: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 96: loss improved from 0.00393 to 0.00390, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 97: loss improved from 0.00390 to 0.00388, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 98: loss improved from 0.00388 to 0.00385, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 99: loss did not improve from 0.00385\n",
      "\n",
      "Epoch 100: loss improved from 0.00385 to 0.00384, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 101: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 102: loss improved from 0.00384 to 0.00381, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 103: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 104: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 105: loss improved from 0.00381 to 0.00378, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 106: loss improved from 0.00378 to 0.00378, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 107: loss improved from 0.00378 to 0.00374, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 108: loss did not improve from 0.00374\n",
      "\n",
      "Epoch 109: loss improved from 0.00374 to 0.00371, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 110: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 111: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 112: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 113: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 114: loss did not improve from 0.00371\n",
      "Epoch 114: early stopping\n",
      "15th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13561, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13561 to 0.12623, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.12623 to 0.11591, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.11591 to 0.10227, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.10227 to 0.08061, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.08061 to 0.05348, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.05348 to 0.04344, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.04344 to 0.03962, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.03962\n",
      "\n",
      "Epoch 10: loss improved from 0.03962 to 0.03414, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03414 to 0.03239, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03239 to 0.03014, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03014 to 0.02870, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02870\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02870\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02870\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02870\n",
      "\n",
      "Epoch 18: loss improved from 0.02870 to 0.02805, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02805 to 0.02692, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02692 to 0.02545, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02545 to 0.02290, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02290 to 0.02001, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02001 to 0.01877, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01877 to 0.01777, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01777 to 0.01686, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01686 to 0.01611, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01611 to 0.01540, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01540 to 0.01463, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01463 to 0.01398, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01398 to 0.01332, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.01332 to 0.01283, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01283 to 0.01241, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01241 to 0.01202, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.01202 to 0.01165, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.01165 to 0.01133, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.01133 to 0.01104, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.01104 to 0.01067, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.01067 to 0.01046, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.01046 to 0.01015, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.01015 to 0.00994, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00994 to 0.00964, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00964 to 0.00942, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00942 to 0.00928, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00928 to 0.00903, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00903 to 0.00879, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00879 to 0.00863, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00863 to 0.00847, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00847 to 0.00831, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00831 to 0.00812, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00812 to 0.00802, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.00802 to 0.00787, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.00787 to 0.00780, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.00780 to 0.00767, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.00767 to 0.00753, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00753 to 0.00739, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00739 to 0.00730, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00730 to 0.00713, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.00713 to 0.00707, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss improved from 0.00707 to 0.00690, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss improved from 0.00690 to 0.00685, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss improved from 0.00685 to 0.00675, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 62: loss improved from 0.00675 to 0.00670, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00670 to 0.00653, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss improved from 0.00653 to 0.00651, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 65: loss improved from 0.00651 to 0.00642, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 66: loss improved from 0.00642 to 0.00624, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 67: loss improved from 0.00624 to 0.00618, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 68: loss improved from 0.00618 to 0.00612, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 69: loss improved from 0.00612 to 0.00602, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 70: loss improved from 0.00602 to 0.00599, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 71: loss did not improve from 0.00599\n",
      "\n",
      "Epoch 72: loss improved from 0.00599 to 0.00593, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss improved from 0.00593 to 0.00583, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 74: loss improved from 0.00583 to 0.00573, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss improved from 0.00573 to 0.00568, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 76: loss improved from 0.00568 to 0.00564, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 77: loss improved from 0.00564 to 0.00555, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 78: loss improved from 0.00555 to 0.00550, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 79: loss improved from 0.00550 to 0.00545, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 80: loss improved from 0.00545 to 0.00540, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 81: loss improved from 0.00540 to 0.00532, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 82: loss improved from 0.00532 to 0.00528, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 83: loss improved from 0.00528 to 0.00527, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 84: loss improved from 0.00527 to 0.00519, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 85: loss did not improve from 0.00519\n",
      "\n",
      "Epoch 86: loss did not improve from 0.00519\n",
      "\n",
      "Epoch 87: loss improved from 0.00519 to 0.00511, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 88: loss did not improve from 0.00511\n",
      "\n",
      "Epoch 89: loss improved from 0.00511 to 0.00504, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 90: loss improved from 0.00504 to 0.00499, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 91: loss improved from 0.00499 to 0.00495, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 92: loss did not improve from 0.00495\n",
      "\n",
      "Epoch 93: loss improved from 0.00495 to 0.00493, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 94: loss improved from 0.00493 to 0.00489, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 95: loss improved from 0.00489 to 0.00481, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 96: loss improved from 0.00481 to 0.00479, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 97: loss improved from 0.00479 to 0.00477, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 98: loss did not improve from 0.00477\n",
      "\n",
      "Epoch 99: loss improved from 0.00477 to 0.00472, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 100: loss improved from 0.00472 to 0.00468, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 101: loss improved from 0.00468 to 0.00465, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 102: loss did not improve from 0.00465\n",
      "\n",
      "Epoch 103: loss improved from 0.00465 to 0.00458, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 104: loss improved from 0.00458 to 0.00457, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 105: loss improved from 0.00457 to 0.00455, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 106: loss improved from 0.00455 to 0.00452, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 107: loss improved from 0.00452 to 0.00452, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 108: loss improved from 0.00452 to 0.00445, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 109: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 110: loss improved from 0.00445 to 0.00444, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 111: loss did not improve from 0.00444\n",
      "\n",
      "Epoch 112: loss did not improve from 0.00444\n",
      "\n",
      "Epoch 113: loss improved from 0.00444 to 0.00439, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 114: loss did not improve from 0.00439\n",
      "\n",
      "Epoch 115: loss improved from 0.00439 to 0.00435, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 116: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 117: loss improved from 0.00435 to 0.00430, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 118: loss improved from 0.00430 to 0.00429, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 119: loss improved from 0.00429 to 0.00425, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 120: loss improved from 0.00425 to 0.00424, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 121: loss improved from 0.00424 to 0.00422, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 122: loss improved from 0.00422 to 0.00421, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 123: loss improved from 0.00421 to 0.00421, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 124: loss improved from 0.00421 to 0.00419, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 125: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 126: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 127: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 128: loss improved from 0.00419 to 0.00416, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 129: loss improved from 0.00416 to 0.00413, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 130: loss did not improve from 0.00413\n",
      "\n",
      "Epoch 131: loss did not improve from 0.00413\n",
      "\n",
      "Epoch 132: loss improved from 0.00413 to 0.00410, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 133: loss improved from 0.00410 to 0.00408, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 134: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 135: loss improved from 0.00408 to 0.00403, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 136: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 137: loss improved from 0.00403 to 0.00403, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 138: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 139: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 140: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 141: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 142: loss did not improve from 0.00403\n",
      "Epoch 142: early stopping\n",
      "16th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.14312, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.14312 to 0.13152, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.13152 to 0.12070, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.12070 to 0.10886, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.10886 to 0.09425, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.09425 to 0.07478, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.07478 to 0.05573, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.05573 to 0.04700, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.04700 to 0.04238, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.04238 to 0.03966, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03966 to 0.03756, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03756 to 0.03555, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.03555\n",
      "\n",
      "Epoch 14: loss improved from 0.03555 to 0.03386, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.03386 to 0.03329, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.03329 to 0.03258, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03258 to 0.03161, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.03161\n",
      "\n",
      "Epoch 19: loss improved from 0.03161 to 0.03119, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.03119\n",
      "\n",
      "Epoch 21: loss did not improve from 0.03119\n",
      "\n",
      "Epoch 22: loss did not improve from 0.03119\n",
      "\n",
      "Epoch 23: loss improved from 0.03119 to 0.03099, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.03099 to 0.03076, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.03076 to 0.03053, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.03053 to 0.03030, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.03030 to 0.03006, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.03006 to 0.02984, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.02984 to 0.02961, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.02961 to 0.02939, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.02939 to 0.02918, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.02918 to 0.02896, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.02896 to 0.02874, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.02874 to 0.02853, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.02853 to 0.02831, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.02831 to 0.02810, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.02810 to 0.02787, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.02787 to 0.02764, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.02764 to 0.02741, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.02741 to 0.02718, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.02718 to 0.02691, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.02691 to 0.02664, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.02664 to 0.02629, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.02629 to 0.02582, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.02582 to 0.02468, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.02468 to 0.02319, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.02319 to 0.02249, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.02249\n",
      "\n",
      "Epoch 49: loss did not improve from 0.02249\n",
      "\n",
      "Epoch 50: loss did not improve from 0.02249\n",
      "\n",
      "Epoch 51: loss did not improve from 0.02249\n",
      "\n",
      "Epoch 52: loss improved from 0.02249 to 0.02201, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.02201 to 0.02150, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.02150 to 0.02105, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss did not improve from 0.02105\n",
      "\n",
      "Epoch 56: loss did not improve from 0.02105\n",
      "\n",
      "Epoch 57: loss did not improve from 0.02105\n",
      "\n",
      "Epoch 58: loss did not improve from 0.02105\n",
      "\n",
      "Epoch 59: loss did not improve from 0.02105\n",
      "Epoch 59: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO: [units, batch_size, dropout, look_back, is_ema]\n",
    "config = [[[64]], [1, 2, 4, 8], [0.2],[10,12,15,17], [True]] \n",
    "df = read_data('../temp_data/influA_vietnam_last_10_days.csv', num_features=2)\n",
    "hist = LSTM_HyperParameter_Tuning(config, df, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>look_back</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.0035746979992836714, 0.0597887746989727]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.0036712305154651403, 0.060590680688619614]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.003672596300020814, 0.06060194969177246]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.003710880409926176, 0.060916997492313385]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[64]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0037117155734449625, 0.060923848301172256]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[64]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.0037428683135658503, 0.061178985983133316]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.0038157356902956963, 0.06177164241671562]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0038442974910140038, 0.06200239807367325]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.003847072832286358, 0.06202477216720581]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0038967549335211515, 0.06242399662733078]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0039406102150678635, 0.06277427822351456]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.003942518029361963, 0.06278947740793228]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.003995734732598066, 0.0632118210196495]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[64]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.0040192194283008575, 0.06339731067419052]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.004085062071681023, 0.06391449272632599]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[64]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.02264152280986309, 0.15047100186347961]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  batch_size  dropout  look_back  \\\n",
       "4   [64]           2      0.2         10   \n",
       "8   [64]           4      0.2         10   \n",
       "0   [64]           1      0.2         10   \n",
       "9   [64]           4      0.2         12   \n",
       "13  [64]           8      0.2         12   \n",
       "12  [64]           8      0.2         10   \n",
       "6   [64]           2      0.2         15   \n",
       "5   [64]           2      0.2         12   \n",
       "2   [64]           1      0.2         15   \n",
       "11  [64]           4      0.2         17   \n",
       "3   [64]           1      0.2         17   \n",
       "10  [64]           4      0.2         15   \n",
       "7   [64]           2      0.2         17   \n",
       "14  [64]           8      0.2         15   \n",
       "1   [64]           1      0.2         12   \n",
       "15  [64]           8      0.2         17   \n",
       "\n",
       "                                       train_loss  \n",
       "4     [0.0035746979992836714, 0.0597887746989727]  \n",
       "8   [0.0036712305154651403, 0.060590680688619614]  \n",
       "0     [0.003672596300020814, 0.06060194969177246]  \n",
       "9    [0.003710880409926176, 0.060916997492313385]  \n",
       "13  [0.0037117155734449625, 0.060923848301172256]  \n",
       "12  [0.0037428683135658503, 0.061178985983133316]  \n",
       "6    [0.0038157356902956963, 0.06177164241671562]  \n",
       "5    [0.0038442974910140038, 0.06200239807367325]  \n",
       "2     [0.003847072832286358, 0.06202477216720581]  \n",
       "11   [0.0038967549335211515, 0.06242399662733078]  \n",
       "3    [0.0039406102150678635, 0.06277427822351456]  \n",
       "10    [0.003942518029361963, 0.06278947740793228]  \n",
       "7      [0.003995734732598066, 0.0632118210196495]  \n",
       "14   [0.0040192194283008575, 0.06339731067419052]  \n",
       "1     [0.004085062071681023, 0.06391449272632599]  \n",
       "15     [0.02264152280986309, 0.15047100186347961]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# hist = pd.DataFrame(hist)\n",
    "# hist = hist.sort_values(by=[4], ascending=True)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inverse_transform(data, scaler):\n",
    "#     flattened_data = data.flatten()\n",
    "#     inverse_flattened_data = scaler.inverse_transform(flattened_data.reshape(-1,1))\n",
    "#     return inverse_flattened_data.reshape(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# model = load_model(r\"D:\\my_study\\gr3\\DATN\\result\\lstm_ema\\10\\best_lstm_m2m_model.keras\")\n",
    "# df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=2)\n",
    "# trainX, trainY, testX, testY = prepare_data(df, 15, scaler, is_ema=True)\n",
    "# testY_hat = forecast(testX, model)\n",
    "# y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "# y_inverse = inverse_transform(testY, scaler)\n",
    "# print(y_inverse, y_hat_inverse)\n",
    "\n",
    "# save_plot(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten(), 'abc.png')\n",
    "# model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist.iloc[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# testY_hat = forecast(testX, model)\n",
    "# y_hat_inverse = np.expand_dims(scaler.inverse_transform(testY_hat[0]), axis=0)\n",
    "# y_inverse = np.expand_dims(scaler.inverse_transform(testY[0]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# testY_hat = forecast(testX, model)\n",
    "# y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "# y_inverse = inverse_transform(testY, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(y_inverse, y_hat_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = read_data('../temp_data/influA_vietnam_last_10_days.csv')\n",
    "# trainX, trainY, testX, testY = prepare_data(df, hist.iloc[0][3], scaler=None, is_ema=True)\n",
    "# testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAIjCAYAAAAZajMiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAC1QElEQVR4nOzdd3gU1dfA8e+m94SWSkjovYTeey9SpUgngj8EKSoKgkgTBERRUVGkSZEOIiC9Su+d0EMNLSQhgdSd94+8u7CEkoXdnWRzPs+zj+zMnZmzO9l4cvfcezWKoigIIYQQQghhBWzUDkAIIYQQQghTkeRWCCGEEEJYDUluhRBCCCGE1ZDkVgghhBBCWA1JboUQQgghhNWQ5FYIIYQQQlgNSW6FEEIIIYTVkORWCCGEEEJYDUluhRBCCCGE1ZDkVgiVaDQaRo0apXYYQmV37tyhXbt25MiRA41Gw9SpUy127Tlz5qDRaLh69arFrmluo0aNQqPRGNX2/v37Zo7KOlnjz4+wDpLcCqvwyy+/oNFoqFSp0huf49atW4waNYpjx46ZLrBMSqPRvPDh6+urdmhmd+bMGUaNGpXu/2G/bYI0ePBgNmzYwLBhw5g3bx6NGzd+o/O8yvjx41m1apXJz5tZmPP1//PPP9SqVQtvb29cXFzIly8f7du3Z/369Wa5Xmak+4y87BEREaF2iMLK2KkdgBCmsGDBAoKDgzlw4AAXL16kQIECRp/j1q1bjB49muDgYMqUKWP6IDOZBg0a0K1bN4Ntzs7OKkVjOWfOnGH06NHUrl2b4OBgs19v69attGzZkk8//dRs1xg/fjzt2rWjVatWBtu7du1Kx44dcXR0NNu1LW3EiBEMHTrUYNvLXv/b+vbbbxkyZAi1atVi2LBhuLi4cPHiRTZv3syiRYvM8odKZvbrr7/i5uaWZruXl5flgxFWTZJbkelduXKFPXv2sGLFCj744AMWLFjAV199pXZYmV6hQoXo0qWLyc+bnJyMVqvFwcHB5OfOjO7evava/9xtbW2xtbVV5drmYmdnh52d+f/XlpyczNixY2nQoAEbN25Ms//u3btmj+FNqfUZbNeuHTlz5jTqmPj4eBwcHLCxSftFc1xcHK6urm8cj1arJTExEScnpzc+h8iYpCxBZHoLFiwgW7ZsNGvWjHbt2rFgwYIXtouKimLw4MEEBwfj6OhI7ty56datG/fv32f79u1UqFABgJ49e+q/LpszZw4AwcHB9OjRI805a9euTe3atfXPExMTGTlyJOXKlcPT0xNXV1dq1KjBtm3bjH5dd+7cwc7OjtGjR6fZFxYWhkajYdq0aQAkJSUxevRoChYsiJOTEzly5KB69eps2rTJ6Oum1927dwkNDcXHxwcnJydKly7N3LlzDdpcvXoVjUbDt99+y9SpU8mfPz+Ojo6cOXMGgHPnztGuXTuyZ8+Ok5MT5cuXZ/Xq1Wmu9ap7B8a974sWLaJcuXK4u7vj4eFByZIl+eGHH4DUGsJ3330XgDp16uh/DrZv327Ue1O7dm1KlCjBmTNnqFOnDi4uLgQEBDBp0iR9G129oqIo/Pzzz/prPfuaBw0aRGBgII6OjhQoUICJEyei1WoNrqXVavnhhx8oWbIkTk5O5MqVi8aNG3Po0CEgtcQkLi6OuXPn6q+h+1l+Wc3kL7/8QvHixXF0dMTf359+/foRFRVl9GvU+emnnyhevDguLi5ky5aN8uXLs3Dhwpe+f4qikDNnTj7++GOD1+nl5YWtra1BLBMnTsTOzo7Y2Fggbc3tq17/s+91jx498PLywtPTk549e/L48eOXxgdw//59YmJiqFat2gv3e3t7Gzy/ceMGrVq1wtXVFW9vb305yvM/X6b+XWOqz+Dp06epW7cuzs7O5M6dm3HjxqX5WXxb27dvR6PRsGjRIkaMGEFAQAAuLi7ExMTQo0cP3NzcuHTpEk2bNsXd3Z3OnTsDqUnuJ598ov+sFC5cmG+//RZFUQzOr9Fo6N+/PwsWLND/fEv5iHWSnluR6S1YsIA2bdrg4OBAp06d+PXXXzl48KA+WQWIjY2lRo0anD17ll69elG2bFnu37/P6tWruXHjBkWLFmXMmDGMHDmSPn36UKNGDQCqVq1qVCwxMTH88ccfdOrUid69e/Po0SNmzpxJo0aNOHDggFHlDj4+PtSqVYslS5ak6YlevHgxtra2+kRs1KhRTJgwgffff5+KFSsSExPDoUOHOHLkCA0aNDDqNejEx8enqSN1d3fH0dGRJ0+eULt2bS5evEj//v3JmzcvS5cupUePHkRFRTFw4ECD42bPnk18fDx9+vTB0dGR7Nmzc/r0aapVq0ZAQABDhw7F1dWVJUuW0KpVK5YvX07r1q2B19+7nDlzpvt937RpE506daJevXpMnDgRgLNnz7J7924GDhxIzZo1GTBgAD/++CNffPEFRYsWBdD/1xgPHz6kcePGtGnThvbt27Ns2TI+//xzSpYsSZMmTahZsybz5s2ja9euaUpAHj9+TK1atbh58yYffPABefLkYc+ePQwbNozbt28bDDoLDQ1lzpw5NGnShPfff5/k5GR27drFvn37KF++PPPmzdP/XPTp0weA/PnzvzTuUaNGMXr0aOrXr0/fvn0JCwvTf6Z2796Nvb19ul8jwIwZMxgwYADt2rVj4MCBxMfHc+LECfbv38977733whg0Gg3VqlVj586d+m0nTpwgOjoaGxsbdu/eTbNmzQDYtWsXISEhL/y6G0jX62/fvj158+ZlwoQJHDlyhD/++ANvb2/9z8iLeHt74+zszD///MNHH31E9uzZX9r2yZMn1KtXj2vXrjFgwAD8/f2ZN28eW7dufekxr2Ps75q3+QxGRERQp04dkpOT9e1+//13o8uUIiMj02yzs7NL883F2LFjcXBw4NNPPyUhIUHfw5ycnEyjRo2oXr063377LS4uLiiKwjvvvMO2bdsIDQ2lTJkybNiwgSFDhnDz5k2+//57g3Nv3bqVJUuW0L9/f3LmzGmR0iOhAkWITOzQoUMKoGzatElRFEXRarVK7ty5lYEDBxq0GzlypAIoK1asSHMOrVarKIqiHDx4UAGU2bNnp2kTFBSkdO/ePc32WrVqKbVq1dI/T05OVhISEgzaPHz4UPHx8VF69eplsB1Qvvrqq1e+vt9++00BlJMnTxpsL1asmFK3bl3989KlSyvNmjV75bmMAbzwoXtvpk6dqgDK/Pnz9cckJiYqVapUUdzc3JSYmBhFURTlypUrCqB4eHgod+/eNbhGvXr1lJIlSyrx8fH6bVqtVqlatapSsGBB/bb03Lv0vu8DBw5UPDw8lOTk5Je+9qVLlyqAsm3btte8S6m++uorBVDu3bun31arVi0FUP7880/9toSEBMXX11dp27atwfGA0q9fP4NtY8eOVVxdXZXz588bbB86dKhia2urXLt2TVEURdm6dasCKAMGDEgTl+69URRFcXV1feHP7+zZsxVAuXLliqIoinL37l3FwcFBadiwoZKSkqJvN23aNAVQZs2aZfRrbNmypVK8ePE0136dyZMnK7a2tvqfpR9//FEJCgpSKlasqHz++eeKoihKSkqK4uXlpQwePFh/nO5+POtlr1/X9vnPZuvWrZUcOXK8Nkbdz6arq6vSpEkT5euvv1YOHz6cpp3u87JkyRL9tri4OKVAgQJpftZM/bvGFJ/BQYMGKYCyf/9+/ba7d+8qnp6eBj8/L6N7n1/0KFy4sL7dtm3bFEDJly+f8vjxY4NzdO/eXQGUoUOHGmxftWqVAijjxo0z2N6uXTtFo9EoFy9e1G8DFBsbG+X06dOvjFdkflKWIDK1BQsW4OPjQ506dYDUHp8OHTqwaNEiUlJS9O2WL19O6dKl9T0Rz0rvtEHpYWtrq+9l0Gq1REZGkpycTPny5Tly5IjR52vTpg12dnYsXrxYv+3UqVOcOXOGDh066Ld5eXlx+vRpLly48PYv4v+1bNmSTZs2GTwaNWoEwLp16/D19aVTp0769vb29gwYMIDY2Fh27NhhcK62bduSK1cu/fPIyEi2bt1K+/btefToEffv3+f+/fs8ePCARo0aceHCBW7evAmk796l93338vIiLi7OrOUaOm5ubgY1yw4ODlSsWJHLly+/9tilS5dSo0YNsmXLpn9v7t+/T/369UlJSdH3aC5fvhyNRvPCGvM3+bnevHkziYmJDBo0yKDGsXfv3nh4eLB27VqjX6OXlxc3btzg4MGDRsVSo0YNUlJS2LNnD5DaQ1ujRg1q1KjBrl27gNTPQlRUlP6bljf1v//9L821Hzx4QExMzCuPGz16NAsXLiQkJIQNGzYwfPhwypUrR9myZTl79qy+3bp16/Dz86Ndu3b6bS4uLvqe5Ddh7O+at/kMrlu3jsqVK1OxYkX98bly5dKXBaTX8uXL0/xOmT17dpp23bt3f2mvcN++fQ2er1u3DltbWwYMGGCw/ZNPPkFRFP7991+D7bVq1aJYsWJGxS0yH0luRaaVkpLCokWLqFOnDleuXOHixYtcvHiRSpUqcefOHbZs2aJve+nSJUqUKGGRuObOnUupUqX0ta+5cuVi7dq1REdHG32unDlzUq9ePZYsWaLftnjxYuzs7GjTpo1+25gxY4iKiqJQoUKULFmSIUOGcOLEibd6Hblz56Z+/foGDz8/PwDCw8MpWLBgmkEeuq/vw8PDDbbnzZvX4PnFixdRFIUvv/ySXLlyGTx0iZpuQE5671163vcPP/yQQoUK0aRJE3Lnzk2vXr3MVnOXO3fuNAlmtmzZePjw4WuPvXDhAuvXr0/z3tSvXx8wfG/8/f1f+ZW4MXT3rXDhwgbbHRwcyJcvX5r7mp7X+Pnnn+Pm5kbFihUpWLAg/fr1Y/fu3a+NpWzZsri4uOgTWV1yW7NmTQ4dOkR8fLx+X/Xq1Y1/sc/IkydPmtcApOtederUiV27dvHw4UM2btzIe++9x9GjR2nRogXx8fFA6vtaoECBNO/V8++zsYz5XfM2n0Hd5/15xsZfs2bNNL9TqlSp8tpYdezs7MidO7fBtvDwcPz9/XF3dzfYnt7fRcI6Sc2tyLS2bt3K7du3WbRoEYsWLUqzf8GCBTRs2NAk13pZL1hKSorBaPP58+fTo0cPWrVqxZAhQ/D29sbW1pYJEyZw6dKlN7p2x44d6dmzJ8eOHaNMmTIsWbKEevXqGYw6rlmzJpcuXeLvv/9m48aN/PHHH3z//fdMnz6d999//42ua0rP98LoBqJ8+umn+t7g5xkznVt633dvb2+OHTvGhg0b+Pfff/n333+ZPXs23bp1SzMY7m29bBYC5blBLi+i1Wpp0KABn3322Qv3FypU6K1iM5X0vMaiRYsSFhbGmjVrWL9+PcuXL+eXX35h5MiRLxwsqWNvb0+lSpXYuXMnFy9eJCIigho1auDj40NSUhL79+9n165dFClSxKBH0lyv43U8PDxo0KABDRo0wN7enrlz57J//35q1aplVCzm+l1j7s+gKb2s19bR0fGFsyaY4tzCukhyKzKtBQsW4O3tzc8//5xm34oVK1i5ciXTp0/H2dmZ/Pnzc+rUqVee71Vf42bLli3NaHFI7RXIly+f/vmyZcvIly8fK1asMDjf20xN1qpVKz744AN9acL58+cZNmxYmnbZs2enZ8+e9OzZk9jYWGrWrMmoUaPMktwGBQVx4sQJtFqtwf9szp07p9//Krr3zN7eXt8b+TLpuXfGvO8ODg60aNGCFi1aoNVq+fDDD/ntt9/48ssvX9i7pob8+fMTGxubrvdmw4YNREZGvrL3Nr2vSXffwsLCDH6uExMTuXLlymvjeRlXV1c6dOhAhw4dSExMpE2bNnz99dcMGzbsldMw1ahRg4kTJ7J582Zy5sxJkSJF0Gg0FC9enF27drFr1y6aN2/+2utb+p6WL1+euXPncvv2bSD1fT116hSKohjEEhYWluZYS/2uMeYzGBQU9MKSpxfFb2lBQUFs3ryZR48eGfTepvd3kbBOUpYgMqUnT56wYsUKmjdvTrt27dI8+vfvz6NHj/RT2rRt25bjx4+zcuXKNOfS9c7o5kt80f9Y8ufPz759+0hMTNRvW7NmDdevXzdop+tZebbHZ//+/ezdu/eNX6uXlxeNGjViyZIlLFq0CAcHhzST0T948MDguZubGwUKFCAhIUG/LTo6mnPnzr1RecTzmjZtSkREhEEtcHJyMj/99BNubm6v7a3y9vamdu3a/Pbbb/oE4Fn37t3T/zs99y697/vz75ONjQ2lSpUC0L9Xr/o5sJT27duzd+9eNmzYkGZfVFQUycnJQOp7oyjKC3tAn30vXF1d0/V66tevj4ODAz/++KPB8TNnziQ6Olo/Q4Exnn/PHRwcKFasGIqikJSU9Mpja9SoQUJCAlOnTqV69er6JK5GjRrMmzePW7dupaveNr2v3xiPHz9+6edaV+ep+9q+adOm3Lp1i2XLlhkc//vvv6c51lK/a4z5DDZt2pR9+/Zx4MABg/0vm3bRkpo2bUpKSop+WkSd77//Ho1Go5+1Q2Qt0nMrMqXVq1fz6NEj3nnnnRfur1y5Mrly5WLBggV06NCBIUOGsGzZMt5991169epFuXLliIyMZPXq1UyfPp3SpUuTP39+vLy8mD59Ou7u7ri6ulKpUiXy5s3L+++/z7Jly2jcuDHt27fn0qVLzJ8/P82UQs2bN2fFihW0bt2aZs2aceXKFaZPn06xYsX083C+iQ4dOtClSxd++eUXGjVqlGbqnGLFilG7dm3KlStH9uzZOXToEMuWLaN///76NitXrqRnz57Mnj37hfNoGqNPnz789ttv9OjRg8OHDxMcHMyyZcvYvXs3U6dOTVP/9iI///wz1atXp2TJkvTu3Zt8+fJx584d9u7dy40bNzh+/DhAuu5det/3999/n8jISOrWrUvu3LkJDw/np59+okyZMvoavTJlymBra8vEiROJjo7G0dGRunXrppm31JyGDBnC6tWrad68OT169KBcuXLExcVx8uRJli1bxtWrV8mZMyd16tSha9eu/Pjjj1y4cIHGjRuj1WrZtWsXderU0d//cuXKsXnzZr777jv8/f3JmzfvC5eqzpUrF8OGDWP06NE0btyYd955h7CwMH755RcqVKjwRot6NGzYEF9fX6pVq4aPjw9nz55l2rRpNGvW7LU/J1WqVMHOzo6wsDCDwVc1a9bk119/BUhXcpve12+Mx48fU7VqVSpXrkzjxo0JDAwkKiqKVatWsWvXLlq1akVISAiQOiBv2rRpdOvWjcOHD+Pn58e8efNwcXFJc15L/q5J72fws88+0y8NPXDgQP1UYLpvcNJr2bJlL5yyrUGDBvj4+KT7PM9q0aIFderUYfjw4Vy9epXSpUuzceNG/v77bwYNGvTKae+EFbP8BA1CvL0WLVooTk5OSlxc3Evb9OjRQ7G3t1fu37+vKIqiPHjwQOnfv78SEBCgODg4KLlz51a6d++u368oivL3338rxYoVU+zs7NJMCzZlyhQlICBAcXR0VKpVq6YcOnQozfQ8Wq1WGT9+vBIUFKQ4OjoqISEhypo1a5Tu3bsrQUFBBvGRjqnAdGJiYhRnZ+c002/pjBs3TqlYsaLi5eWlODs7K0WKFFG+/vprJTExUd9GN+3Ti6Y6ex4vmJ7qeXfu3FF69uyp5MyZU3FwcFBKliyZ5ty6aYgmT578wnNcunRJ6datm+Lr66vY29srAQEBSvPmzZVly5YZtHvdvUvv+75s2TKlYcOGire3t+Lg4KDkyZNH+eCDD5Tbt28bXG/GjBlKvnz5FFtb29dOC/ayqcBeNP3Vy34OXvReP3r0SBk2bJhSoEABxcHBQcmZM6dStWpV5dtvvzW4r8nJycrkyZOVIkWKKA4ODkquXLmUJk2aGExJde7cOaVmzZr6nyHdVFPPTwWmM23aNKVIkSKKvb294uPjo/Tt21d5+PChQZv0vsbffvtNqVmzppIjRw7F0dFRyZ8/vzJkyBAlOjo6zbEvUqFChTTTUN24cUMBlMDAwDTtXzQV2Mte/4vunaK8/H15VlJSkjJjxgylVatW+p87FxcXJSQkRJk8eXKaabrCw8OVd955R3FxcVFy5sypDBw4UFm/fv0Lf75M+bvGVJ/BEydOKLVq1VKcnJyUgIAAZezYscrMmTPfeiqwZ1+/biqwpUuXpjlH9+7dFVdX1xee/9GjR8rgwYMVf39/xd7eXilYsKAyefJkg+nwFCV9v9eEddAoihEV80IIIYQwie3bt1OnTh22bdtmsPqYEOLtSM2tEEIIIYSwGpLcCiGEEEIIqyHJrRBCCCGEsBpScyuEEEIIIayG9NwKIYQQQgirIcmtEEIIIYSwGrKIA6lrbN+6dQt3d/cMsfSmEEIIIYQwpCgKjx49wt/f32Dp9+dJcgvcunWLwMBAtcMQQgghhBCvcf36dXLnzv3S/ZLcgn4JyOvXr+Ph4WH26yUlJbFx40YaNmyIvb292a8nTE/uYeYm9y/zk3uY+ck9zNzUuH8xMTEEBga+duluSW5BX4rg4eFhseTWxcUFDw8P+UBnUnIPMze5f5mf3MPMT+5h5qbm/XtdCakMKBNCCCGEEFZDklshhBBCCGE1JLkVQgghhBBWQ2pu0yklJYWkpCSTnCspKQk7Ozvi4+NJSUkxyTmFZVnrPbS3t8fW1lbtMIQQQog3JsltOsTGxnLjxg1MtVKxoij4+vpy/fp1mVc3k7LWe6jRaMidOzdubm5qhyKEEEK8EUluXyMlJYUbN27g4uJCrly5TJLIaLVaYmNjcXNze+UkxCLjssZ7qCgK9+7d48aNGxQsWFB6cIUQQmRKkty+RlJSEoqikCtXLpydnU1yTq1WS2JiIk5OTlaTGGU11noPc+XKxdWrV0lKSpLkVgghRKZkPf9XNjNr+upZiJeRn3MhhBCZnSS3QgghhBDCakhyK4QQQgghrIYkt0IVGo2GVatWqR2GEEIIIayMJLdWbu/evdja2tKsWTOjjw0ODmbq1KmmDyoDGDVqFBqNJs1j8+bNaof2xrZv345GoyEqKkrtUIQQQgjVyGwJFpKiVThwJZK7j+LJ5eZA4eyWeetnzpzJRx99xMyZM7l16xb+/v4WuW5mULx48TTJbPbs2d/oXImJiTg4OJgiLCGEEEK8Bem5tYD1p25TfeJWOs3Yx8BFx3jvjwM0/fUQ609FmPW6sbGxLF68mL59+9KsWTPmzJmTps0///xDhQoVcHJyImfOnLRu3RqA2rVrEx4ezuDBg/W9mpDa41mmTBmDc0ydOpXg4GD984MHD9KgQQNy5syJp6cntWrV4siRI+mO+/fff8ff3x+tVmuwvWXLlvTq1QuA48ePU6dOHdzd3fHw8KBcuXIcOnQo3dcAsLOzw9fX1+ChS1BPnjxJ3bp1cXZ2JkeOHPTp04fY2Fj9sT179qRz586MHz8ef39/ChcuDMD169dp3749Xl5eZM+enZYtW3L16lWD686aNYvixYvj6OiIn58f/fv31+/77rvvKFmyJK6urgQGBvLhhx8aXDc8PJwWLVqQLVs2XF1dKV68OOvWrePq1avUqVMHgGzZsqHRaOjRo4dR74cQQghhDSS5NbP1p27Td/4RbkfHG2y/+yiRfguPsv7UbbNde8mSJRQpUoTChQvTpUsXZs2aZbDK2tq1a2ndujVNmzbl6NGjbNmyhYoVKwKwYsUKcufOzZgxY7h9+za3b6c/zkePHtG9e3f+++8/9u3bR8GCBWnatCmPHj1K1/HvvvsuDx48YNu2bfptkZGRrF+/ns6dOwPQuXNncufOzcGDBzl8+DBDhw7F3t4+3TG+SlxcHI0aNSJbtmwcPHiQpUuXsnnzZoMkFGDnzp2EhYWxadMm1qxZQ1JSEo0aNcLd3Z1du3axe/du3NzcaNy4MYmJiQD8+uuv9OvXjz59+nDy5ElWr15NgQIF9Oe0sbHhxx9/5PTp08ydO5etW7fy2Wef6ff369ePhIQEdu7cycmTJ5k4cSJubm4EBgayfPlyAMLCwrh9+zY//PCDSd4PIYQQIjORsgQzStEqjP7nDC9atFcBNMDof87QoJgvtjamn1905syZdOnSBYDGjRsTHR3Njh07qF27NgBff/01HTt2ZPTo0fpjSpcuDaR+PW9ra4u7uzu+vr5GXbdu3boGz3///Xe8vLzYsWMHzZs3f+3x2bJlo0mTJixcuJB69eoBsGzZMnLmzKnvnbx27RpDhgyhSJEiABQsWNCoGCG1d/bZZWaLFSvGgQMHWLhwIfHx8fz555+4uroCMG3aNFq0aMHEiRPx8fEBwMXFhRkzZuDk5ATA/Pnz0Wq1/PHHH/qe7tmzZ+Pl5cX27dtp2LAh48aN45NPPmHgwIH661aoUEH/70GDBun/HRwczLhx4/jf//7HL7/8on/dbdu2pWTJkgDky5dP315XUuHt7Y2Xl5fR74cQQghhDaTn1owOXIlM02P7LAW4HR3PgSuRJr92WFgYBw4coFOnTkDqV/AdOnRg5syZ+jbHjh3TJ4+mdOfOHXr37k3BggXx9PTEw8OD2NhYrl27lu5zdO7cmeXLl5OQkADAggUL6Nixo341sI8//pj333+f+vXr880333Dp0iWj4yxcuDDHjh3TP3Q9n2fPnqV06dL6xBagWrVqaLVawsLC9NuKFStmUGd7/PhxLl68iLu7O25ubri5uZE9e3bi4+O5dOkSd+/e5datW698zzdv3ky9evUICAjA3d2drl278uDBAx4/fgzAgAEDGDduHNWqVeOrr77ixIkTRr9uIYR1URSF/Tf2E5sY+/rGQmQBktya0d1HL09s36SdMWbOnElycjL+/v7Y2dlhZ2fHr7/+yvLly4mOjgZ4o+WEbWxsDEobIHWJ4md1796dY8eO8cMPP7Bnzx6OHTtGjhw59F/Np0eLFi1QFIW1a9dy/fp1du3apS9JgNTa39OnT9OsWTO2bt1KsWLFWLlypVGvxcHBgQIFCugfgYGBRh3v4uJi8Dw2NpZy5coZJMzHjh3j/PnzvPfee699v69evUrz5s0pVaoUy5cv5/Dhw/z8888A+vfu/fff5/Lly3Tt2pWTJ09Svnx5fvrpJ6PiFkJYl/UX11N5ZmV6/9Nb7VCEyBAkuTUjb3cnk7ZLr+TkZP7880+mTJlikGQdP34cf39//vrrLwBKlSrFli1bXnoeBwcHUlJSDLblypWLiIgIgwT32LFjBm12797NgAEDaNq0qX7g1P379416DU5OTrRp04YFCxbw119/UbhwYcqWLWvQplChQgwePJiNGzfSpk0bZs+ebdQ1XqZo0aIcP36cuLg4g9dkY2OjHzj2ImXLluXChQt4e3sbJM0FChTA09MTd3d3goODX/qeHz58GK1Wy5QpU6hcuTKFChXi1q1badoFBgbyv//9jxUrVvDJJ58wY8YMAH0v8vP3TAhh3RJTUv/4XXZmGXdi76gcjRDqk+TWjCrmzY6fpxMvq6bVAH6eTlTM+2bTT73MmjVrePjwIaGhoZQoUcLg0bZtW31pwldffcVff/3FV199xdmzZ/UDlHSCg4PZuXMnN2/e1CentWvX5t69e0yaNIlLly7x888/8++//xpcv2DBgsybN4+zZ8+yf/9+Onfu/Ea9xJ07d2bt2rXMmjXLoNf2yZMn9O/fn+3btxMeHs7u3bs5ePAgRYsWBeDmzZsUKVKEAwcOGH1N3XWdnJzo3r07p06dYtu2bXz00Ud07dpVX2/7suNy5sxJy5Yt2bVrF1euXGH79u0MGDCAGzduAKk9zlOmTOHHH3/kwoULHDlyRN/zWqBAAZKSkvjpp5+4fPky8+bNY/r06QbXGDRoEBs2bODKlSscOXKEbdu26V93UFAQGo2GNWvWcO/ePYNZFoQQ1ivIKwiAZG0yfx7/U+VohFCfJLdmZGuj4asWxQDSJLi651+1KGbywWQzZ86kfv36eHp6ptnXtm1bDh06xIkTJ6hduzZLly5l9erVlClThrp16xokhGPGjOHq1avkz5+fXLlyAam9mr/88gs///wzpUuX5sCBA3z66adprv/w4UPKli1L165dGTBgAN7e3ka/jrp165I9e3bCwsJ477339NttbW158OAB3bp1o1ChQrRv354mTZroB8YlJSURFhamr1M1louLCxs2bCAyMpIKFSrQrl076tWrx7Rp01573M6dO8mTJw9t2rShaNGihIaGEh8fj4eHB5BasjF16lR++eUXihcvTvPmzblw4QKQOpjvu+++Y+LEiZQoUYIFCxYwYcIEg2ukpKTQr18/ihYtSuPGjSlUqJB+sFlAQACjR49m6NCh+Pj4pJndQQhhnYI8g/T/nnl0ZprSMSGyGo0inwJiYmLw9PQkOjpan4ToxMfHc+XKFfLmzasfFW+s9aduM/qfMwaDy3zcHfiqRXGalpJFFTIjrVZLTEwMHh4e+kFu1sAUP++ZQVJSEuvWraNp06Ymm0JOWJbcw6cURcHzG08eJaZOt/hfz/+olqeaylG9ntzDzE2N+/eqfO1ZMhWYBTQu4UeDYr5pVijL5pW2Z1UIIYQwhkajIcgriFN3TwGpvbeZIbkVwlysp8spg7O10VAlfw5algmgcr4cZpnXVgghRNb0bGnCktNLeJSQvkVzhLBGktwKIYQQmdyzyW1cUhyLTy9WMRoh1CXJrRBCCJHJ6WZM0Jl5dOZLWgph/SS5FUIIITI5Xc9twewFsdXYsu/GPs7cO6NyVEKoQ5JbIYQQIpPT9dzGJ8fTvFBzAGYdnaVmSEKoRpJbIYQQIpPL45kHgJuPbtK9dHcA/jz+p371MiGyEkluhRBCiEzO180XB1sHtIqWkj4l8XPz497je6w5v0bt0ISwOEluhRBCiEzORmNDoEcgADdjnvbeysAykRVJcpuF1a5dm0GDBmX4c76pq1evotFoOHbsmNqhvDGNRsOqVasA63g9Qgjz0dXdhkeH0yukFwDrL67nZsxNNcMSwuIkubVSPXr0oFWrVmqH8Uq7d+/Gzs6OMmXKGGwfNWoUGo3G4FGkSBF1gsxAAgMDuX37NiVKlFA7FCFEBqSbMSE8KpyCOQpSM6gmWkXLnGNz1A1MCAuT5FaoIioqim7dulGvXr0X7i9evDi3b9/WP/777z8LR5h+iYmWGbBha2uLr68vdnayarYQIi19chsdDkCvMqm9t7OOzUKraFWLSwhLk+T2TcXFvfwRH5/+tk+epK/tW4cbR7du3XBzc8PPz48pU6akaZOQkMCnn35KQEAArq6uVKpUie3bt+v3P3jwgE6dOhEQEICLiwslS5bkr7/+eqN4/ve///Hee+9RpUqVF+63s7PD19dX/8iZM+drz3ngwAFCQkJwcnKifPnyHD16NE2bU6dO0aRJE9zc3PDx8aFr167cv39fv//Ro0d07twZV1dX/Pz8+P7779OUWgQHBzNu3Dj+97//4eXlRZ8+fQD477//qFGjBs7OzgQGBjJgwADinrl3r3t/X+f5soTt27ej0WjYsmUL5cuXx8XFhapVqxIWFmZw3N9//03ZsmVxcnIiX758jB49muTk5HRfVwiROTxblgDQrlg73B3cufzwMjuu7lAzNCEsSpLbN+Xm9vJH27aGbb29DfbbeHjglTs3Nh4e0KSJYdvg4Bef8y0NGTKEHTt28Pfff7Nx40a2b9/OkSNHDNr079+fvXv3smjRIk6cOMG7775L48aNuXDhAgDx8fGUK1eOtWvXcurUKfr06UPXrl05cOCAUbHMnj2by5cv89VXX720zYULF/D39ydfvnx07tyZa9euvfKcsbGxNG/enGLFinH48GFGjRrFp59+atAmKiqKunXrEhISwqFDh1i/fj137tyhffv2+jYff/wxu3fvZvXq1WzatIldu3aleZ8ApkyZQokSJTh8+DBffvklly5donHjxrRt25YTJ06wePFi/vvvP/r3768/5nXv75saPnw4U6ZM4dChQ9jZ2dGrVy/9vl27dtGtWzcGDhzImTNn+O2335gzZw5ff/31W11TCJHxPFuWAODq4EqnEp0AGVgmshhFKNHR0QqgREdHp9n35MkT5cyZM8qTJ08Md8DLH02bGrZ1cXl521q1DNvmzPnidkbq3r270rJlS0VRFOXRo0eKg4ODsmTJEv3+Bw8eKM7OzsrAgQMVRVGU8PBwxdbWVrl586bBeerVq6cMGzbspddp1qyZ8sknn+if16pVS3/OFzl//rzi7e2thIWFKYqiKF999ZVSunRpgzbr1q1TlixZohw/flxZv369UqVKFSVPnjxKTEzMS8/722+/KTly5DC4T7/++qsCKEePHlUURVHGjh2rNGzY0OC469evK4ASFhamxMTEKPb29srSpUv1+6OiohQXFxeD1xQUFKS0bNlSefjwoZKSkqIoiqKEhoYqffr0MTj3rl27FBsbG+XJkydv/P4CysqVKxVFUZQrV64YvJ5t27YpgLJ582Z9+7Vr1yqA/n2oV6+eMn78eINzzps3T/Hz83vh9V76825lEhMTlVWrVimJiYlqhyLekNzDtC5FXlIYheI41lHRarWKoijK/hv7FUahOI1zUh4+eahugM+Re5i5qXH/XpWvPUuK995UbOzL99naGj6/e9fgqVarJSYmBg8PD2yer5+8etU08T3j0qVLJCYmUqlSJf227NmzU7hwYf3zkydPkpKSQqFChQyOTUhIIEeOHACkpKQwfvx4lixZws2bN0lMTCQhIQEXF5d0xZGSksJ7773H6NGj01znWU2e6c0uVaoUlSpVIigoiCVLlhAaGsr//vc/5s+fr28TGxvL2bNnKVWqFE5OTvrtz5c8HD9+nG3btuH2gp7wS5cu8eTJE5KSkqhYsaJ+u6enp8H7pFO+fPk05z5x4gQLFizQb1MUBa1Wy5UrV7h8+fJr3983VapUKf2//fz8ALh79y558uTh+PHj7N6926CnNiUlhfj4eB4/fpzueyeEyPhye+RGg4aElATuxt3Fx82HCv4VKOFdglN3T7Hw5EI+rPCh2mEKYXaS3L4pV9c3b6vVQkpK6nYbm1e3tZDY2FhsbW05fPgwts8l57pkcPLkyfzwww9MnTqVkiVL4urqyqBBg9I9oOrRo0ccOnSIo0eP6r+u12q1KIqCnZ0dGzdupG7dummO8/LyolChQly8eBGAMWPGpCk5SO9rbNGiBRMnTkyzz8/PT3/+9HB97j7FxsbywQcfMGDAgDRt8+TJw4kTJ177/r4pe3t7/b81Gg2Q+r7q4ho9ejRt2rRJc9yzfwgIITI/B1sH/N39ufnoJuHR4fi4+aDRaAgNCWXwhsHMPDpTkluRJUhymwXkz58fe3t79u/fT548qUs0Pnz4kPPnz1OrVi0AQkJCSElJ4e7du9SoUeOF59m9ezctW7akS5cuQGoCdf78eYoVK5auODw8PDh58qTBtl9++YWtW7eybNky8ubN+8LjYmNjuXTpEl27dgXA29sbb29vgzZFixZl3rx5xMfH65O2ffv2GbQpW7Ysy5cvJzg4+IUzDuTLlw97e3sOHjyof5+io6M5f/48NWvWfOVrK1u2LGfOnKFAgQIv3J+e99ccypYtS1hY2EvjEkJYlyCvoNTkNiqcigGp30J1KdWFzzZ9xpHbRzgWcYwyvmXUDVIIM5MBZVmAm5sboaGhDBkyhK1bt3Lq1Cl69OiBzTO9xoUKFaJz585069aNFStWcOXKFQ4cOMCECRNYu3YtAAULFmTTpk3s2bOHs2fP8sEHH3Dnzp10x2FjY0OJEiUMHt7e3jg5OVGiRAl9b+inn37Kjh07uHr1Knv27KF169bY2trSqVOnl577vffeQ6PR0Lt3b86cOcO6dev49ttvDdr069ePyMhIOnXqxMGDB7l06RIbNmygZ8+epKSk4O7uTvfu3RkyZAjbtm3j9OnThIaGYmNjo+8RfZnPP/+cPXv20L9/f44dO8aFCxf4+++/9T3U6Xl/zWHkyJH8+eefjB49mtOnT3P27FkWLVrEiBEjzHZNIYR68nim/mGumzEBIKdLTloVaQXAzCMysExYP0lus4jJkydTo0YNWrRoQf369alevTrlypUzaDN79my6devGJ598QuHChWnVqpVBL+aIESMoW7YsjRo1onbt2vj6+pploYgbN27QqVMnChcuTPv27cmRIwf79u0jV65cLz3Gzc2Nf/75h5MnTxISEsLw4cPTlB/4+/uze/duUlJSaNiwISVLlmTQoEF4eXnpE/3vvvuOKlWq0Lx5c+rXr0+1atUoWrToa7/CL1WqFDt27OD8+fPUqFGDkJAQRo4cib+/v77N695fc2jUqBFr1qxh48aNVKhQgcqVK/P9998TFBRktmsKIdTz/IwJOqEhoQAsOLmA+OT4NMcJYU00iqIoagehtpiYGDw9PYmOjsbDw8NgX3x8PFeuXCFv3rwmq1E0GFD2fM2tyFDi4uIICAhgypQphIaG6rdb6z00x897RpSUlMS6deto2rSpQc2yyDzkHr7Yrwd/5cN1H9KiUAtWd1qt356iTSHvD3m5HnOdhW0W0qnky78JsxS5h5mbGvfvVfnas6zn/8pCmMDRo0f566+/uHTpEkeOHKFz584AtGzZUuXIhBDi9Z5fyEHH1saWnmV6AqkrlglhzSS5FeI53377LaVLl6Z+/frExcWxa9eudK2QJoQQantZWQJAz5CeaNCw+fJmrkZdtXBkQliOJLdCPCMkJITDhw8TGxtLZGQkmzZtomTJkmqHJYQQ6aLruY1OiCY6PtpgX7BXMPXy1QNg9tHZFo9NCEuR5FYIIYSwEm4ObmR3zg6kLU2ApwPLZh+bTYo2xaKxCWEpktwKIYQQVuRVpQmtirQim1M2rsdcZ/PlzZYOTQiLkORWCCGEsCK60oRr0dfS7HOyc6JLqdSFeGYelTlvhXWS5FYIIYSwIvqe2xeUJcDT0oRV51Zx//F9i8UlhKVIciuEEEJYkdclt6V9S1POrxxJ2iTmn5hvydCEsAhJboUQQggrop/r9gU1tzq9QnoBqaUJspaTsDaS3IpMpXbt2gwaNEjtMIQQIsN6Xc8twHsl38PJzolTd09x8NZBS4UmhEVIcmul7t27R9++fcmTJw+Ojo74+vrSqFEjdu/erXZoZjVnzhw0Gk2ahzUvJSuEEM/K45kHgIjYCOKT41/YxsvJi7ZF2wIw84gMLBPWRZJbK9W2bVuOHj3K3LlzOX/+PKtXr6Z27do8ePBA7dBITEw06/k9PDy4ffu2wSM8/OU9GC+KR1EUkpOTjb72mx4nhBCmktMlJ852zgBcj77+0na6gWV/nfqLuMQ4i8QmhCVIcmskRVGIS4x7+0eS8cekty4qKiqKXbt2MXHiROrUqUNQUBAVK1Zk2LBhvPPOO/p2Fy5coGbNmjg5OVGsWDE2bdqERqNh1apVAGzfvh2NRkNUVJT+mGPHjqHRaLh69SoADx48oFOnTgQEBODi4kLJkiX566+/DOKpXbs2/fv3Z9CgQeTMmZNGjRoBcOrUKZo0aYKbmxs+Pj507dqV+/efjtyNi4ujW7duuLm54efnx5QpU9L1+jUaDb6+vgYPHx+fV8aje63//vsv5cqVw9HRkf/++4+EhAQGDBiAt7c3Tk5OVK9enYMHn36F97LjhBBCLRqN5mnd7StKE2oF1yJftnw8SnzEsjPLLBWeEGZnp3YAmc3jpMe4TXBT5dqxw2JxdXB9bTs3Nzfc3NxYtWoVlStXxtHRMU0brVZLmzZt8PHxYf/+/URHR79RLWt8fDzlypXj888/x8PDg7Vr19K1a1fy589PxYoV9e3mzp1L37599WURUVFR1K1bl/fff5/vv/+eJ0+e8Pnnn9O+fXu2bt0KwJAhQ9ixYwd///033t7efPHFFxw5coQyZcoYHefzno/n9u3bAAwdOpRvv/2WfPnykS1bNj777DOWL1/O3LlzCQoKYtKkSTRq1Ijz589jZ/f04/P8cUIIoaYgzyDO3T/3ykFlNhobepXpxYhtI5h5dCbdy3S3YIRCmI8kt1bIzs6OOXPm0Lt3b6ZPn07ZsmWpVasWHTt2pFSpUgBs3ryZc+fOsWHDBvz9/QEYP348TZo0MepaAQEBfPrpp/rnH330ERs2bGDJkiUGyW3BggWZNGmS/vm4ceMICQlh/Pjx+m2zZs0iMDCQ8+fP4+/vz8yZM5k/fz716qWuhT537lxy58792piio6NxczP8A6RGjRr8+++/L41Hl9yOGTOGBg0aAKk9x7/++itz5szRvy8zZsxg06ZNzJo1iz59+uiPf/Y4IYRQW3oGlQH0KNODkdtHsuvaLs4/OE+hHIUsEZ4QZiXJrZFc7F2IHRb7VufQarXEPIrBw90DG5v0V4a42Luku23btm1p1qwZu3btYt++ffz7779MmjSJP/74gx49enD27FkCAwP1iS1AlSpVjHodACkpKYwfP54lS5Zw8+ZNEhMTSUhIwMXFMNZy5coZPD9+/Djbtm1Lk4QCXLp0iSdPnpCYmEilSpX027Nnz07hwoVfG5O7uztHjhwx2Obs7PzKeHTKly9vEEdSUhLVqlXTb7O3t6dixYqcPXv2pccJIYTa0lOWABDgEUDjAo1Zd2Eds47O4pv631giPCHMSpJbI2k0mnSVBryKVqslxT4FVwdXo5JbYzk5OdGgQQMaNGjAl19+yfvvv89XX31Fjx490nW8LrZna32TkpIM2kyePJkffviBqVOnUrJkSVxdXRk0aFCaQVqurobvWWxsLC1atGDixIlpruvn58fFixfTFePL4i5QoMAr2zwfz+u2v86bHieEEOag77l9RVmCTmhIKOsurGPu8bmMqzsOOxtJDUTmpuqAspSUFL788kvy5s2Ls7Mz+fPnZ+zYsQbJlKIojBw5Ej8/P5ydnalfvz4XLlwwOE9kZCSdO3fGw8MDLy8vQkNDiY19u95Va1SsWDHi4lJHxBYtWpTr16/rv44H2Ldvn0H7XLlyARi0OXbsmEGb3bt307JlS7p06ULp0qXJly8f58+ff20sZcuW5fTp0wQHB1OgQAGDh6urK/nz58fe3p79+/frj3n48GG6zm0q+fPnx8HBwWD6tKSkJA4ePEixYsUsFocQQhgrvT23AM0LNSeXSy4iYiP498K/r20vREananI7ceJEfv31V6ZNm8bZs2eZOHEikyZN4qefftK3mTRpEj/++CPTp09n//79uLq60qhRI+Ljn87d17lzZ06fPs2mTZtYs2YNO3fuNKiHzGoePHhA3bp1mT9/PidOnODKlSssXbqUSZMm0bJlSwDq169PoUKF6N69O8ePH2fXrl0MHz7c4DwFChQgMDCQUaNGceHCBdauXZtmxoKCBQuyadMm9uzZw9mzZ/nggw+4c+fOa2Ps168fkZGRdOrUiYMHD3Lp0iU2bNhAz549SUlJwc3NjdDQUIYMGcLWrVs5deoUPXr0SFdPt6IoREREpHlotVoj3sXU3ti+ffsyZMgQ1q9fz5kzZ+jduzePHz+mV69eRp1LCCEsSddzeyPmBinalFe2dbB1oFvpbkDqimVCZHaqfvewZ88eWrZsSbNmzQAIDg7mr7/+4sCBA0BqkjJ16lRGjBihT8r+/PNPfHx8WLVqFR07duTs2bOsX7+egwcP6usef/rpJ5o2bcq3335rUFOaVbi5uVGpUiW+//57fd1oYGAgvXv35osvvgBSv7pfuXIloaGhVKxYkeDgYH788UcaN26sP4+9vT1//fUXffv2pVSpUlSoUIFx48bx7rvv6tuMGDGCy5cv06hRI1xcXOjTpw+tWrUiOjr6lTH6+/uze/duPv/8cxo2bEhCQgJBQUE0btxYn8BOnjxZX77g7u7OJ5988trzAsTExODn55dm++3bt/H19U3Xe6jzzTffoNVq6dq1K48ePaJ8+fJs2LCBbNmyERMTY9S5hBDCUvzd/bGzsSNZm8zt2Nvk9nj1YNzQkFCm7J3CmvNriIiNwNfNuN+VQmQkGkXFRaXHjx/P77//zsaNGylUqBDHjx+nYcOGfPfdd3Tu3JnLly+TP39+jh49ajD9U61atShTpgw//PADs2bN4pNPPuHhw4f6/cnJyTg5ObF06VJat26d5roJCQkkJCTon8fExBAYGMj9+/fx8PAwaBsfH8/169cJDg422SpXiqLw6NEj3N3d0Wg0Jjmnqdja2rJ8+XJatWqldigZWka+h28jPj6eq1evEhgYaNWruiUlJbFp0yYaNGiAvb292uGINyD38PUK/VyIq9FX2d51O1UDq762fc25Ndl3cx/j64zn0yqfvrb925J7mLmpcf9iYmLImTMn0dHRafK1Z6naczt06FBiYmIoUqQItra2pKSk8PXXX9O5c2cAIiIiAAwm4Nc91+2LiIjA29vbYL+dnR3Zs2fXt3nehAkTGD16dJrtGzduTDPK387ODl9fX2JjY02+stajR49Mej5TefLkifRKplNGvYdvKjExkSdPnrBz584ssdLapk2b1A5BvCW5hy/nmpw60PXvnX8TlS3qte3L2ZRjH/uYtmcaRSOLWuwPd7mHmZsl79/jx4/T1U7V5HbJkiUsWLCAhQsXUrx4cY4dO8agQYPw9/ene3fzTSY9bNgwPv74Y/1zXc9tw4YNX9pz6+bmliV6biF12qxX/UUkMv49fFPx8fE4OzvrV66zVtJjlPnJPXy9Zf8s4/TJ02TPm52mVZu+tn2NhBrM+XEOtxJu4VXKi2qB1V57zNuQe5i5qdVzmx6qJrdDhgxh6NChdOzYEYCSJUsSHh7OhAkT6N69u74+8s6dOwY1lHfu3NGXKfj6+nL37l2D8yYnJxMZGfnS+kpHR8cXrtplb2+f5galpKSg0WiwsbEx2bRduoFNuvNmJCpWqWQqGfkevg0bGxs0Gs0LPwvWKKu8Tmsm9/Dlgr2CAbjx6Ea63qPs9tnpULwDs47NYu7JudTOV9u8Af4/uYeZmyXvX3qvo+r/lR8/fpwmMbC1tdUnDnnz5sXX15ctW7bo98fExLB//379ggNVqlQhKiqKw4cP69ts3boVrVZrsACAEEIIkZUYMx2YTmjZUACWnF5CTIKUp4nMSdXktkWLFnz99desXbuWq1evsnLlSr777jv9IDCNRsOgQYMYN24cq1ev5uTJk3Tr1g1/f3/9gKeiRYvSuHFjevfuzYEDB9i9ezf9+/enY8eOJp0pQXo0RVYgP+dCWA9jFnLQqZK7CoVzFOZx0mMWn1psrtCEMCtVk9uffvqJdu3a8eGHH1K0aFE+/fRTPvjgA8aOHatv89lnn/HRRx/Rp08fKlSoQGxsLOvXrzeoB1ywYAFFihShXr16NG3alOrVq/P777+bJEZbW1sAkw8mEyIj0v2c637uhRCZ17M9t+n9w1Wj0RAaktp7K3PeisxK1Zpbd3d3pk6dytSpU1/aRqPRMGbMGMaMGfPSNtmzZ2fhwoVmiDB1tgQXFxfu3buHvb29SeortVotiYmJxMfHW1W9ZlZijfdQq9Vy7949XFxcsLOT5TeFyOzyeOYB4HHSYx48eUBOl5zpOq5b6W58sfUL9t/cz+m7pynuXdycYQphcvJ/sNfQaDT4+flx5coVwsPT/9XOqyiKwpMnT3B2draqkfZZibXeQxsbG/LkyWNVr0mIrMrJzgkfVx/uxN0hPCo83cmtj5sPzQs1Z9W5Vcw8OpPvGn1n5kiFMC1JbtPBwcGBggULmqw0ISkpiZ07d1KzZk0ZIZpJWes9dHBwsJqeaCFEamnCnbg7hEeHU86/XLqPCw0JZdW5Vcw7MY9v6n+Dg62DGaMUwrQkuU0nGxsbk837aWtrq19FzZoSo6xE7qEQIjMI8gziwM0DXIu+ZtRxjQs0xs/Nj9uxt1kdtpp2xdqZKUIhTE+6aIQQQggr9SYzJgDY2djRo0wPQAaWicxHklshhBDCSr3JXLc6vUJ6AbDh4gauR183aVxCmJMkt0IIIYSV0vfcvkFyWyB7AWoF1UJBYc6xOSaOTAjzkeRWCCGEsFL6nlsjyxJ0dHPezj42G62iNVlcQpiTJLdCCCGEldL13D548oC4xDijj29brC0ejh5cibrC9qvbTRydEOYhya0QQghhpTydPPFw9ADerDTBxd6F90q8B8jAMpF5SHIrhBBCWLE3nTFBJ7RsamnC8jPLefjkocniEsJcJLkVQgghrNjbzJgAUM6vHKV8SpGQksDCk+ZZ6l4IU5LkVgghhLBib9tzq9Fo9APLpDRBZAaS3AohhBBW7G2mA9PpXLIzDrYOHI04ytHbR00VmhBmIcmtEEIIYcXetiwBIIdLDloXaQ1I763I+CS5FUIIIayYruf2WvS1tzqPrjRhwckFPEl68tZxCWEuktwKIYQQVkzXc3vr0S2SUpLe+Dz18tUjj2ceouKjWHlupanCE8LkJLkVQgghrJi3qzeOto5oFS03Ym688XlsNDb0LNMTkNIEkbFJciuEEEJYMRuNDXk88wBvV3cL0LNMTzRo2HplK5cfXjZFeEKYnCS3QgghhJXTDyp7w+nAnj1P/Xz1AZh9dPZbxyWEOUhyK4QQQlg5U0wHpqMbWDbn+BxStClvfT4hTE2SWyGEEMLK6csS3rLnFqBVkVZkd87OjZgbbLy08a3PJ4SpSXIrhBBCWDlT9tw62jnSpWQXQAaWiYxJklshhBDCypliIYdnhZZNLU1YHbaae3H3THJOIUxFklshhBDCyj27kINW0b71+Ur5lKK8f3mStEnMPzH/rc8nhClJciuEEEJYudweubHR2JCYksid2DsmOaduYNnMozNRFMUk5xTCFCS5FUIIIaycva09/u7+gOlKEzqV6ISznTOn753mwM0DJjmnEKYgya0QQgiRBegHlZlgxgQATydP2hVrB8jAMpGxSHIrhBBCZAG6QWXXoq+Z7Jy60oRFpxYRlxhnsvMK8TYkuRVCCCGyAFNOB6ZTM6gmBbIX4FHiI5aeWWqy8wrxNiS5FUIIIbIAcyS3Go2GXmV6AVKaIDIOSW6FEEKILEA/162Jam51upfpjo3Ghv+u/UfY/TCTnluINyHJrRBCCJEFmKPnFsDf3Z+mBZsCMOvoLJOeW4g3IcmtEEIIkQXk8cwDQExCDFHxUSY9t25g2dzjc0lKSTLpuYUwliS3QgghRBbg6uBKDuccgOlLE5oVbIa3qzd34u6w7sI6k55bCGNJciuEEEJkEfq6WxOXJtjb2tOtVDdABpYJ9UlyK4QQQmQRpl7I4VmhZVNLE9ZdWMftR7dNfn4h0kuSWyGEECKLMNegMoAiOYtQNbAqKUoKc4/PNfn5hUgvSW6FEEKILMJcZQk6uoFls47OQlEUs1xDiNeR5FYIIYTIIsxZlgDQvnh73BzcuBB5gV3XdpnlGkK8jiS3QgghRBah67m9Fn3NLOd3c3CjQ/EOgMx5K9Qjya0QQgiRReh6bu/E3SE+Od4s19CVJiw9s5SYhBizXEOIV5HkVgghhMgisjtnx9XeFTBf723l3JUpmrMoj5Mes+jUIrNcQ4hXkeRWCCGEyCI0Gs3TQWVmqrvVaDT63luZ81aoQZJbIYQQIgsx53RgOl1Ld8XOxo4DNw9w6u4ps11HiBeR5FYIIYTIQsw9YwKAt6s37xR+B4CZR6T3VliWJLdCCCFEFmLuuW51dKUJ807MIyE5wazXEuJZktwKIYQQWUgezzyA+ZPbRvkbEeAewIMnD1gdttqs1xLiWZLcCiGEEFmIJcoSAGxtbOlRpgcgA8uEZUlyK4QQQmQhurKEGzE3SNYmm/VavUJ6AbDx0kazTT0mxPMkuRVCCCGyED83P+xs7EhRUrj16JZZr5UvWz7qBNdBQWHOsTlmvZYQOpLcCiGEEFmIrY0tgR6BgPlLE+Bp7+3sY7PRKlqzX08ISW6FEEKILEZXmmCJUoG2Rdvi6ejJ1airbL2y1ezXE0KSWyGEECKLscRCDjrO9s68V/I9QAaWCcuQ5FYIIYTIYiw1Y4KObs7blWdXEvkk0iLXFFmXJLdCCCFEFmOphRx0yvqVpbRPaRJSElhwYoFFrimyLkluhRBCiCzGkmUJABqNRt97O+vYLItcU2RdktwKIYQQWYy+5zYqHEVRLHLNzqU642jryLGIYxy5fcQi1xRZkyS3QgghRBajmwrsSfIT7j++b5FrZnfOTuuirQGYeUQGlgnzkeRWCCGEyGIc7RzxdfMFLFeaAE8Hli04uYAnSU8sdl2RtUhyK4QQQmRBlp4xAaBu3roEewUTnRDNyrCVFruuyFokuRVCCCGyIEvPmABgo7GhZ5meAMw5Psdi1xVZiyS3QgghRBakRs8tQI8yPdCgYXv4dm4n3LbotUXWIMmtEEIIkQVZejownTyeeWiYvyEAWyNlOV5hepLcCiGEEFmQrizhWvQ1i19bN7Bsa+RWUrQpFr++sG6S3AohhBBZkFo9twDvFH6HHM45eJD0gI2XN1r8+sK6SXIrhBBCZEG6ntvIJ5HEJsZa9NqOdo50LtEZgNnHZ1v02sL6SXIrhBBCZEEejh54OXkBlh9UBtCjdA8A1lxYw924uxa/vrBektwKIYQQWZSapQklvEtQ0KUgydpk5h2fZ/HrC+slya0QQgiRRennulWh5xagfvb6AMw8OhNFUVSJQVgfSW6FEEKILErNnluA6tmq42znzNn7Z9l3Y58qMQjrI8mtEEIIkUWpndy62rrStmhbILX3VghTkORWCCGEyKLyeOYB1CtLAOhZOnU53sWnF1t81gZhnSS5FUIIIbIofc2tSj23ANUDq1Mwe0FiE2NZenqpanEI6yHJrRBCCJFF6coSbj+6TWJKoioxaDQaeoX0AqQ0QZiGJLdCCCFEFuXt6o2TnRMKCtejr6sWR/fS3bHV2LL7+m7O3T+nWhzCOkhyK4QQQmRRGo3mad2tiqUJfu5+NC3YFIBZR2epFoewDpLcCiGEEFmYrjThWvQ1VeMIDQkFYO7xuSSlJKkai8jcJLkVQgghsjD9dGAqzpgA0LRgU3xcfbgbd5e1F9aqGovI3CS5FUIIIbKwjDBjAoC9rT3dS3cHZGCZeDuS3AohhBBZmNoLOTxLN2vCugvruPXolsrRiMxKklshhBAiC9P33KpclgBQOGdhquepjlbRMvfYXLXDEZmUJLdCCCFEFqbrub0ecx2tolU5mqcDy2Ydm4WiKCpHIzIjSW6FEEKILCzAIwBbjS2JKYlExEaoHQ7vFnsXdwd3LkZeZGf4TrXDEZmQ6sntzZs36dKlCzly5MDZ2ZmSJUty6NAh/X5FURg5ciR+fn44OztTv359Lly4YHCOyMhIOnfujIeHB15eXoSGhhIbK+tTCyGEEK9jZ2NHgEcAkDFKE1wdXOlYoiMgA8vEm1E1uX348CHVqlXD3t6ef//9lzNnzjBlyhSyZcumbzNp0iR+/PFHpk+fzv79+3F1daVRo0bEx8fr23Tu3JnTp0+zadMm1qxZw86dO+nTp48aL0kIIYTIdDLCQg7P0pUmLDuzjOj4aJWjEZmNqsntxIkTCQwMZPbs2VSsWJG8efPSsGFD8ufPD6T22k6dOpURI0bQsmVLSpUqxZ9//smtW7dYtWoVAGfPnmX9+vX88ccfVKpUierVq/PTTz+xaNEibt2SkZZCCCHE62SUuW51KgZUpHiu4jxJfsJfp/5SOxyRydipefHVq1fTqFEj3n33XXbs2EFAQAAffvghvXv3BuDKlStERERQv359/TGenp5UqlSJvXv30rFjR/bu3YuXlxfly5fXt6lfvz42Njbs37+f1q1bp7luQkICCQkJ+ucxMTEAJCUlkZRk/lVRdNewxLWEecg9zNzk/mV+cg9NK7d7bgCuPLxisff0dfewe6nufLblM/448gehpUMtEpNIPzU+g+m9lqrJ7eXLl/n111/5+OOP+eKLLzh48CADBgzAwcGB7t27ExGRWtju4+NjcJyPj49+X0REBN7e3gb77ezsyJ49u77N8yZMmMDo0aPTbN+4cSMuLi6meGnpsmnTJotdS5iH3MPMTe5f5if30DRi7qd28hy6eIh169ZZ9Novu4c+yT7Yaew4fPswvyz/hWDnYIvGJdLHkp/Bx48fp6udqsmtVqulfPnyjB8/HoCQkBBOnTrF9OnT6d69u9muO2zYMD7++GP985iYGAIDA2nYsCEeHh5mu65OUlISmzZtokGDBtjb25v9esL05B5mbnL/Mj+5h6Zld9mOXxf9SrxjPE2bNrXINdNzD1clrWJl2Eouul/kw4YfWiQukT5qfAZ137S/jqrJrZ+fH8WKFTPYVrRoUZYvXw6Ar68vAHfu3MHPz0/f5s6dO5QpU0bf5u7duwbnSE5OJjIyUn/88xwdHXF0dEyz3d7e3qK/JC19PWF6cg8zN7l/mZ/cQ9PInyN1rMu16GvY2dmh0Wgsdu1X3cPe5XqzMmwlC08v5NtG3+Jol/b/3UJdlvwMpvc6qg4oq1atGmFhYQbbzp8/T1BQamF73rx58fX1ZcuWLfr9MTEx7N+/nypVqgBQpUoVoqKiOHz4sL7N1q1b0Wq1VKpUyQKvQgghhMjcdLMlPEp8RFR8lLrBPKNh/obk9shN5JNI/g77W+1wRCahanI7ePBg9u3bx/jx47l48SILFy7k999/p1+/fgBoNBoGDRrEuHHjWL16NSdPnqRbt274+/vTqlUrILWnt3HjxvTu3ZsDBw6we/du+vfvT8eOHfH391fx1QkhhBCZg4u9C7lccgEZZzowAFsbW3qU7gHInLci/VRNbitUqMDKlSv566+/KFGiBGPHjmXq1Kl07txZ3+azzz7jo48+ok+fPlSoUIHY2FjWr1+Pk5OTvs2CBQsoUqQI9erVo2nTplSvXp3ff/9djZckhBBCZEpBXhlrOjCdniE9Adh0aVOGi01kTG9dc5uSksLJkycJCgoyWHwhvZo3b07z5s1ful+j0TBmzBjGjBnz0jbZs2dn4cKFRl9bCCGEEKmCPIM4dOtQhuq5BciXLR9189Zl65WtzDk2h69qf6V2SCKDM7rndtCgQcycmfrVQEpKCrVq1aJs2bIEBgayfft2U8cnhBBCCAvIaAs5PEu3YtnsY7PRKlqVoxEZndHJ7bJlyyhdujQA//zzD1euXOHcuXMMHjyY4cOHmzxAIYQQQpifviwhg/XcArQu0hovJy/Co8PZcnnL6w8QWZrRye39+/f1U2ytW7eOd999l0KFCtGrVy9Onjxp8gCFEEIIYX76ntsMmNw62zvTuWTqeBwZWCZex+jk1sfHhzNnzpCSksL69etp0KABkLpqhK2trckDFEIIIYT56aYDy4hlCfC0NGHluZU8ePxA5WhERmZ0ctuzZ0/at29PiRIl0Gg01K9fH4D9+/dTpEgRkwcohBBCCPPTlSXce3yPx0npW+bUkkL8QgjxDSExJZEFJxeoHY7IwIxObkeNGsUff/xBnz592L17t36lL1tbW4YOHWryAIUQQghhftmcsuHm4AakrlSWEel6b2cenYmiKCpHIzKqN5oKrF27dmm2de/e/a2DEUIIIYQ6NBoNQZ5BnL53mmvR1yiSM+N9G/teyff4ZOMnnLhzgsO3D1Pev7zaIYkM6I2S2y1btrBlyxbu3r2LVms4JcesWbNMEpgQQgghLCvIKzW5zah1t9mcs9G2WFsWnlzIzCMzJbkVL2R0WcLo0aNp2LAhW7Zs4f79+zx8+NDgIYQQQojMKSPPmKCjK01YeGphhqwNFuozuud2+vTpzJkzh65du5ojHiGEEEKoJDMkt7WDa5PXKy9Xoq6w/MxyupaWfEQYMrrnNjExkapVq5ojFiGEEEKoSL+QQwYtSwCw0djQs0xPQOa8FS9mdHL7/vvvs3DhQnPEIoQQQggVZYaeW4AeZXqgQcOO8B1cjLyodjgigzG6LCE+Pp7ff/+dzZs3U6pUKezt7Q32f/fddyYLTgghhBCWo+u5vRlzk2RtMnY2bzTu3OwCPQNpVKAR6y+uZ/bR2Xxd72u1QxIZiNE/tSdOnKBMmTIAnDp1ymCfRqMxSVBCCCGEsDxfN18cbB1ITEnkZsxNfbKbEYWGhLL+4nrmHJ/D6DqjM2wiLizP6J+Ebdu2mSMOIYQQQqjMRmNDoEcglx5eIjw6PEMnt+8UfoecLjm59egWGy5uoFmhZmqHJDIIo2tun3Xjxg1u3LhhqliEEEIIobI8nnmAjD2oDMDB1oGupVJnSpCBZeJZRie3Wq2WMWPG4OnpSVBQEEFBQXh5eTF27Ng0CzoIIYQQInPRz5iQwQeVwdM5b/85/w93Yu+oHI3IKIxObocPH860adP45ptvOHr0KEePHmX8+PH89NNPfPnll+aIUQghhBAWop8xIYP33AIU9y5OpYBKJGuTmXdintrhiAzC6OR27ty5/PHHH/Tt25dSpUpRqlQpPvzwQ2bMmMGcOXPMEKIQQgghLCWzTAemo+u9nXl0JoqiqByNyAiMTm4jIyMpUqRImu1FihQhMjLSJEEJIYQQQh26soRr0ddUjiR9OpTogIu9C+fun2Pvjb1qhyMyAKOT29KlSzNt2rQ026dNm0bp0qVNEpQQQggh1KHrub0WfS1T9IR6OHrQvnh7AGYekYFl4g2mAps0aRLNmjVj8+bNVKlSBYC9e/dy/fp11q1bZ/IAhRBCCGE5gZ6BaNDwJPkJ9x7fw9vVW+2QXis0JJQ5x+aw+PRipjaeiruju9ohCRUZ3XNbq1Ytzp8/T+vWrYmKiiIqKoo2bdoQFhZGjRo1zBGjEEIIISzEwdYBP3c/IHMMKgOoFliNwjkKE5cUx5LTS9QOR6jsjZbz8Pf35+uvZak7IYQQwhoFeQZx69EtwqPDqRBQQe1wXkuj0dArpBefb/6cmUdnElo2VO2QhIrSldyeOHGCEiVKYGNjw4kTJ17ZtlSpUiYJTAghhBDqCPIKYu+NvZmm5xagW+lufLHlC/be2MvZe2cpmquo2iEJlaQruS1TpgwRERF4e3tTpkwZNBrNC4vMNRoNKSkpJg9SCCGEEJaT2aYDA/B186V5oeb8HfY3M4/O5NuG36odklBJupLbK1eukCtXLv2/hRBCCGG9MmNyC6kDy/4O+5s/j//J+HrjcbB1UDskoYJ0DSgLCgpCo9EAEB4eTkBAgH7pXd0jICCA8PDM9SEQQgghRFr6JXgzUVkCQJOCTfB18+Xe43usOb9G7XCESoyeLaFOnTovXKwhOjqaOnXqmCQoIYQQQqgnj2ceIPP13NrZ2NG9dHcAZh2dpXI0Qi1GJ7eKouh7cZ/14MEDXF1dTRKUEEIIIdSjK0uIio8iJiFG5WiM0yukFwD/XvyXmzE3VY5GqCHdU4G1adMGSB001qNHDxwdHfX7UlJSOHHiBFWrVjV9hEIIIYSwKHdHd7I5ZeNh/EPCo8Ip6VNS7ZDSrVCOQtTIU4Nd13Yx9/hcvqjxhdohCQtLd8+tp6cnnp6eKIqCu7u7/rmnpye+vr706dOH+fPnmzNWIYQQQliIru72WvQ1lSMxXmhI6jy3s47OQqtoVY5GWFq6e25nz54NQHBwMEOGDMHFxcVsQQkhhBBCXUGeQRyLOJbp6m4B2hVrx0f/fsSlh5fYGb6T2sG11Q5JWJDRNbfdunXj5s20NSwXLlzg6tWrpohJCCGEECrTTweWyWZMAHB1cKVTiU4AzDw6U+VohKUZndz26NGDPXv2pNm+f/9+evToYYqYhBBCCKEy/XRgmbDnFtAvwbvszDKi4qPUDUZYlNHJ7dGjR6lWrVqa7ZUrV+bYsWOmiEkIIYQQKsusCznoVPCvQAnvEsQnx/PXyb/UDkdYkNHJrUaj4dGjR2m2R0dHy9K7QgghhJXIrAs56Gg0Gv3AMilNyFqMTm5r1qzJhAkTDBLZlJQUJkyYQPXq1U0anBBCCCHUoeu5vR17m4TkBJWjeTNdSnXB3saew7cPczziuNrhCAtJ92wJOhMnTqRmzZoULlyYGjVqALBr1y5iYmLYunWryQMUQgghhOXldMmJs50zT5KfcD3mOgWyF1A7JKPldMlJqyKtWHpmKTOPzuTHJj+qHZKwAKN7bosVK8aJEydo3749d+/e5dGjR3Tr1o1z585RokQJc8QohBBCCAvTaDSZvjQBns55O//EfOKT41WORliC0T23AP7+/owfP97UsQghhBAiAwnyDOLc/XOZdlAZQP189Qn0COR6zHVWnVtFxxId1Q5JmJnRPbeQWobQpUsXqlatqp/zdt68efz3338mDU4IIYQQ6snjmQfI3D23tja29CzTE5CBZVmF0cnt8uXLadSoEc7Ozhw5coSEhNQi8+joaOnNFUIIIaxIZp8OTKdnSE80aNh8eTNXo66qHY4wM6OT23HjxjF9+nRmzJiBvb29fnu1atU4cuSISYMTQgghhHp0NbfXoq+pHMnbCfYKpl6+egDMPjpb5WiEuRmd3IaFhVGzZs002z09PYmKijJFTEIIIYTIAKyl5xagV5leAMw+NpsUrczLb82MTm59fX25ePFimu3//fcf+fLlM0lQQgghhFCfruf2evR1tIpW5WjeTuuircnmlI3rMdfZcmWL2uEIMzI6ue3duzcDBw5k//79aDQabt26xYIFC/j000/p27evOWIUQgghhAr83f2x1diSpE3i9qPbaofzVpzsnOhcsjMgA8usndFTgQ0dOhStVku9evV4/PgxNWvWxNHRkU8//ZSPPvrIHDEKIYQQQgV2Nnbk9shNeHQ44dHhBHgEqB3SWwktG8q0g9NYdW4VDx4/IIdLDrVDEmaQrp7bEydOoNWmfh2h0WgYPnw4kZGRnDp1in379nHv3j3Gjh1r1kCFEEIIYXnWsJCDThnfMpT1K0tiSiLzT8xXOxxhJulKbkNCQrh//z4A+fLl48GDBzg4OFCsWDEqVqyIm5ubWYMUQgghhDqsaVAZPF2xbObRmSiKonI0whzSldx6eXlx5coVAK5evarvxRVCCCGEddMnt1bQcwvwXsn3cLJz4uTdkxy6dUjtcIQZpKvmtm3bttSqVQs/Pz80Gg3ly5fH1tb2hW0vX75s0gCFEEIIoR59WYKV9Nx6OXnRtmhbFpxcwMyjM6kQUEHtkISJpSu5/f3332nTpg0XL15kwIAB9O7dG3d3d3PHJoQQQgiVWVtZAqSWJiw4uYC/Tv3Fd42+w8XeRe2QhAmle7aExo0bA3D48GEGDhwoya0QQgiRBTw7oExRFDQajcoRvb1awbXIly0flx9eZtmZZXQr3U3tkIQJGT3P7ezZsyWxFUIIIbKIQI9AAOKS4oh8EqlyNKZho7HRr1gmc95aH6OT27i4OL788kuqVq1KgQIFyJcvn8FDCCGEENbD2d4Zb1dvwLpKE3qU6YGNxoad4Tu58OCC2uEIEzJ6EYf333+fHTt20LVrV/0AMyGEEEJYryDPIO7G3eVa9DXK+pVVOxyTCPAIoHGBxqy7sI5ZR2cxof4EtUMSJmJ0cvvvv/+ydu1aqlWrZo54hBBCCJHBBHkFcfDWQauZDkwnNCSUdRfWMff4XMbWHYudjdFpkciAjC5LyJYtG9mzZzdHLEIIIYTIgKxxxgSA5oWak8slF7djb/PvhX/VDkeYiNHJ7dixYxk5ciSPHz82RzxCCCGEyGCsNbl1sHXQz5QgA8ush9H971OmTOHSpUv4+PgQHByMvb29wf4jR46YLDghhBBCqO/Z6cCsTWhIKFP2TmHN+TVExEbg6+ardkjiLRmd3LZq1coMYQghhBAio7LWnluAormKUiV3Ffbe2Mu84/MYUm2I2iGJt2R0cvvVV1+ZIw4hhBBCZFC6ntv7j+8TlxiHq4OryhGZVq+QXuy9sZeZR2fyadVPZSaoTM7omlshhBBCZC1eTl54OHoAcC36msrRmF6H4h1wtXcl7EEYe67vUTsc8ZbSndzqZkl43UMIIYQQ1seaSxPcHd1pX7w9IAPLrEG6yxKmTp1qxjCEEEIIkZEFeQVx8u5JqxxUBqkDy2Yfm82S00v4ofEPuDu6qx2SeEPpTm67d+9uzjiEEEIIkYHl8cgDWGfPLUDVwKoUzlGYsAdhLD69mPfLvq92SOINSc2tEEIIIV5LPx2YlSa3Go2G0JBQQEoTMjtJboUQQgjxWrqaW2scUKbTrXQ37Gzs2HdjH2funVE7HPGGJLkVQgghxGtZ80IOOj5uPjQv1ByAmUek9zazkuRWCCGEEK+l67m9+egmSSlJKkdjPrrShD9P/EliSqLK0Yg3YXRyO2bMGB4/fpxm+5MnTxgzZoxJghJCCCFExuLj5oODrQNaRcvNRzfVDsdsGhdojJ+bH/cf3+efsH/UDke8AaOT29GjRxMbG5tm++PHjxk9erRJghJCCCFExmKjsSGP5//PmGDFpQl2Nnb0KNMDkIFlmZXRya2iKC9clu748eOyiIMQQghhxax5IYdn9QrpBcCGSxu4EXND5WiEsYxeoUyj0VCoUCGDVck8PT1p0KAB7du3N2esQgghhFCRPrm14p5bgALZC1ArqBZaRcucY3PUDkcYyagVyhRFoVevXowePRpPT0/9PgcHB4KDg6lSpYpZghRCCCGE+qx9rttnhYaEsiN8B7OOzuKLGl9go5Ex+JmF0SuU5c2bl2rVqmFnl+5DhRBCCGEFskpZAkDbYm3p/29/rkRdYfvV7dTNW1ftkEQ6Gf1niLu7O2fPntU///vvv2nVqhVffPEFiYkyZYYQQghhrbLCXLc6LvYuvFfiPUAGlmU2Rie3H3zwAefPnwfg8uXLdOjQARcXF5YuXcpnn31m8gCFEEIIkTE8u0qZVtGqHI35hZZNnfN2+ZnlPHzyUOVoRHoZndyeP3+eMmXKALB06VJq1arFwoULmTNnDsuXLzd1fEIIIYTIIAI8AtCgISElgbtxd9UOx+zK+ZWjlE8pElIS+OvUX2qHI9LpjaYC02pT/1rbvHkzTZs2BSAwMJD79++bNjohhBBCZBgOtg74u/sDqb231k6j0dCrTOq0YFKakHkYndyWL1+ecePGMW/ePHbs2EGzZs0AuHLlCj4+PiYPUAghhBAZR1aquwXoUqoLDrYOHLl9hGMRx9QOR6SD0cnt1KlTOXLkCP3792f48OEUKFAAgGXLllG1atU3DuSbb75Bo9EwaNAg/bb4+Hj69etHjhw5cHNzo23btty5c8fguGvXrtGsWTNcXFzw9vZmyJAhJCcnv3EcQgghhHi5rDRjAkAOlxy0KtIKgJlHpPc2MzB6Pq9SpUpx8uTJNNsnT56Mra3tGwVx8OBBfvvtN0qVKmWwffDgwaxdu5alS5fi6elJ//79adOmDbt37wYgJSWFZs2a4evry549e7h9+zbdunXD3t6e8ePHv1EsQgghhHi5rLKQw7NCQ0JZcnoJC04uYHLDyTjZOakdkngFk81I7OTkhL29vdHHxcbG0rlzZ2bMmEG2bNn026Ojo5k5cybfffcddevWpVy5csyePZs9e/awb98+ADZu3MiZM2eYP38+ZcqUoUmTJowdO5aff/5ZpiUTQryUoiiEP8k6/2MWwpSy0kIOOvXz1SePZx4exj9k5dmVaocjXsPontuUlBS+//57lixZwrVr19IkkZGRkUadr1+/fjRr1oz69eszbtw4/fbDhw+TlJRE/fr19duKFClCnjx52Lt3L5UrV2bv3r2ULFnSoNa3UaNG9O3bl9OnTxMSEvLCayYkJJCQkKB/HhMTA0BSUhJJSUlGxf8mdNewxLWEecg9zLwSkhPo9U8vVp1fRZlrZaiSR1ZWzIzkM6ieALcAAK5GXX2r9z+z3cNuJbsx7r9x/H74d9oVaad2OKpT4/6l91pGJ7ejR4/mjz/+4JNPPmHEiBEMHz6cq1evsmrVKkaOHGnUuRYtWsSRI0c4ePBgmn0RERE4ODjg5eVlsN3Hx4eIiAh9m+cHseme69q8yIQJExg9enSa7Rs3bsTFxcWo1/A2Nm3aZLFrCfOQe5j5aBUt4TfDSVKSaLO4Dd8W+pZs9tlef6DIkOQzaHnX468DcOn+JdatW/fW58ss9zAoMQgbbNgevp0flv1AQZeCaoeUIVjy/j1+/Dhd7YxObhcsWMCMGTNo1qwZo0aNolOnTuTPn59SpUqxb98+BgwYkK7zXL9+nYEDB7Jp0yacnCxbuzJs2DA+/vhj/fOYmBgCAwNp2LAhHh4eZr9+UlISmzZtokGDBm9UyiHUJ/cwc6sSW4UKv1XgRsINZkTPYGPnjTjYOqgdljCCfAbVE5cYx0fnPuKx9jHV6lbD08nzjc6TGe/hTtudzDs5j53sZGDTgWqHoyo17p/um/bXMTq5jYiIoGTJkgC4ubkRHR0NQPPmzfnyyy/TfZ7Dhw9z9+5dypYtq9+WkpLCzp07mTZtGhs2bCAxMZGoqCiD3ts7d+7g6+sLgK+vLwcOHDA4r242BV2bF3F0dMTR0THNdnt7e4t+wCx9PWF6cg8zpxxuORiWdxhfXPmCPTf28MnmT5jefLraYYk3IJ9By/Oy9yKHcw4ePHnArce3yOme863Ol5nu4fCaw5l/cj7/nP+Hc5HnKOlTUu2QVGfJ+5fe6xg9oCx37tzcvn0bgPz587Nx40YgdcaDFyWML1OvXj1OnjzJsWPH9I/y5cvTuXNn/b/t7e3ZsmWL/piwsDCuXbtGlSqpNXJVqlTh5MmT3L37dJWUTZs24eHhQbFixYx9aUKILCTAKYA/W/6JBg2/Hf6N3w79pnZIQmQaWW2uW53COQvzbvF3ARj/n8zKlFEZndy2bt1an3B+9NFHfPnllxQsWJBu3brRq1evdJ/H3d2dEiVKGDxcXV3JkSMHJUqUwNPTk9DQUD7++GO2bdvG4cOH6dmzJ1WqVKFy5coANGzYkGLFitG1a1eOHz/Ohg0bGDFiBP369TMq0RZCZE1NCjTh67pfA/DRvx+x+9pulSMSInPIanPdPmt4jeEALD61mPMPzqscjXgRo8sSvvnmG/2/O3ToQFBQEHv27KFgwYK0aNHCpMF9//332NjY0LZtWxISEmjUqBG//PKLfr+trS1r1qyhb9++VKlSBVdXV7p3786YMWNMGocQwnoNrT6UIxFHWHZmGW2XtOVwn8MEeASoHZYQGVpWnOtWp5RPKd4p/A6rw1bzzX/fMKvlLLVDEs8xOrl9XuXKlfU9qW9r+/btBs+dnJz4+eef+fnnn196TFBQkElGawohsiaNRsPslrMJux/GybsnabOkDTt67JBJ2oV4hTyeeQC4FnNN5UjUMbzGcFaHrWbeiXmMrDWSYK9gtUMSzzC6LGHChAnMmpX2r5RZs2YxceJEkwQlhBCW5ObgxqqOq8jmlI0DNw/Qd21fFEVROywhMqysWnOrUzGgIg3yNSBZm8yk3ZPUDkc8x+jk9rfffqNIkSJpthcvXpzp02W0sRAic8qXLR9L3l2CjcaGOcfm8PPBl39jJERWl5VrbnVG1BwBwKyjs7j16JbK0YhnGZ3cRkRE4Ofnl2Z7rly59LMoCCFEZlQ/X30mN5gMwKD1g9h+dbu6AQmRQel6biNiI4hPjlc5GnXUDKpJ9TzVSUhJYMqeKWqHI55hdHIbGBjI7t1pRxTv3r0bf39/kwQlhBBqGVx5MJ1LdiZFSeHdpe9m2a9dhXiVHM45cLFPXdHzevR1laNRz4gaqb230w9P5/7j+ypHI3SMTm579+7NoEGDmD17NuHh4YSHhzNr1iwGDx5M7969zRGjEEJYjEajYUaLGZT1K8v9x/dpvbg1j5PSt+SjEFmFRqOR0gSgYf6GlPcvz+Okx0zdN1XtcMT/Mzq5HTJkCKGhoXz44Yfky5ePfPny8dFHHzFgwACGDRtmjhiFEMKinO2dWdlhJblccnE04ii9/+ktA8yEeE5WH1QGqUm+bt7bnw78RFR8lLoBCeANkluNRsPEiRO5d+8e+/bt4/jx40RGRjJy5EhzxCeEEKrI45mHpe8uxVZjy8KTC/lu73dqhyREhiI9t6neKfwOJbxLEJMQw7QD09QOR/AGya1OREQEkZGR5M+fH0dHR+nVEEJYnVrBtZjaeCoAn23+jE2XNqkbkBAZiCS3qWw0Nvre2+/3fU9sYqzKEQmjk9sHDx5Qr149ChUqRNOmTfUzJISGhvLJJ5+YPEAhhFBTvwr96FmmJ1pFS4dlHbj88LLaIQmRIUhZwlPvFnuXgtkLEvkkkt8O/aZ2OFme0cnt4MGDsbe359q1a7i4uOi3d+jQgfXr15s0OCGEUJtGo+GXZr9QKaASD+Mf0mpRK+mZEQLpuX2WrY0tw6qnjjv6du+3PEl6onJEWZvRye3GjRuZOHEiuXPnNthesGBBwsPlB1wIYX2c7JxY3n45vm6+nLx7kp5/95RSLJHl6Xpub8TcIEWbonI06utSqgt5PPMQERvBrKNpV3IVlmN0chsXF2fQY6sTGRmJo6OjSYISQoiMJsAjgOXtl2NvY8+yM8uY8N8EtUMSQlV+bn7Y2diRrE2WFboAe1t7Pq/2OQCT9kwiMSVR5YiyLqOT2xo1avDnn3/qn2s0GrRaLZMmTaJOnTomDU4IITKSqoFV+blp6rK8I7aOYO35tSpHJIR6bG1sye2R+i3utehrKkeTMfQK6YWvmy/Xoq8x/8R8tcPJsoxObidNmsTvv/9OkyZNSExM5LPPPqNEiRLs3LmTiRMnmiNGIYTIMHqX683/yv0PBYX3VrxH2P0wtUMSQjVSd2vIyc6JIVWHADDhvwkka5NVjihrMjq5LVGiBOfPn6d69eq0bNmSuLg42rRpw9GjR8mfP785YhRCiAzlhyY/UC2wGjEJMbRa3IqYhBi1QxJCFTJjQloflPuAHM45uBh5kaWnl6odTpZkVHKblJREvXr1uHv3LsOHD2fJkiWsW7eOcePG4efnZ64YhRAiQ3GwdWBZ+2UEuAdw7v45uq7silbRqh2WEBYnPbdpuTq4MrjyYAC+3vW1/G5QgVHJrb29PSdOnDBXLEIIkWn4uvmyssNKHG0dWR22mjE7xqgdkhAWJ8nti/Wv2B9PR09O3zvN3+f+VjucLMfosoQuXbowc+ZMc8QihBCZSoWACvze4ncARu8Yzapzq9QNSAgLk7KEF/N08qR/xf5Aau+tTB1oWXbGHpCcnMysWbPYvHkz5cqVw9XV1WD/d9/J+utCiKyjW+luHLl9hB/2/0DXlV3ZF7qP4t7F1Q5LCIt4tudWURQ0Go3KEWUcgyoP4vt933P49mE2XNpA4wKN1Q4pyzC65/bUqVOULVsWd3d3zp8/z9GjR/WPY8eOmSFEIYTI2CY3mEyd4DrEJsbSanErHj55qHZIQlhEoGcgAI+THvPgyQOVo8lYcrrkpG/5vgCM2zlOem8tyOie223btpkjDiGEyLTsbe1Z3G4xFWZU4GLkRd5b8R5rOq3B1sZW7dCEMCsnOyd83XyJiI0gPCqcnC451Q4pQ/mkyidMOzCN3dd3szN8J7WCa6kdUpZgdM/ts27cuMGNGzdMFYsQQmRauVxzsbLDSpztnFl/cT0jto5QOyQhLEIGlb2cn7sfoSGhAIzbNU7laLIOo5NbrVbLmDFj8PT0JCgoiKCgILy8vBg7dixarUx3IYTIukL8Qpj5TuqA2292f8OS00tUjkgI85NBZa/2WbXPsLOxY/Plzey/sV/tcLIEo5Pb4cOHM23aNL755ht9re348eP56aef+PLLL80RoxBCZBqdSnbSr1DU8++eHI84rnJEQpiX9Ny+WpBXEF1LdQVSZ04Q5md0cjt37lz++OMP+vbtS6lSpShVqhQffvghM2bMYM6cOWYIUQghMpcJ9SbQMH9DHic9ptXiVjx4LANthPXK45kHgGvR11SOJOMaWn0oNhob/jn/D8cijqkdjtUzOrmNjIykSJEiabYXKVKEyMhIkwQlhBCZma2NLX+1/Yv82fJzNeoqHZZ1kDXmhdWSntvXK5SjEB2KdwBg/K7xKkdj/YxObkuXLs20adPSbJ82bRqlS5c2SVBCCJHZZXfOzqqOq3C1d2XLlS18tukztUMSwiyk5jZ9vqjxBQDLzizj7L2zKkdj3YxObidNmsSsWbMoVqwYoaGhhIaGUqxYMebMmcPkyZPNEaMQQmRKJbxL8GfrPwH4ft/3zDs+T+WIhDA9Xc/tgycPiEuMUzmajKuEdwlaFWmFgsI3u79ROxyrZnRyW6tWLc6fP0/r1q2JiooiKiqKNm3aEBYWRo0aNcwRoxBCZFptirZhRI3UacF6/9ObQ7cOqRyREKbl6eSJp6MnIKUJrzO8xnAAFpxYwOWHl1WOxnqlO7m9fPmyfnUNf39/vv76a5YvX87y5csZN24c/v7+ZgtSCCEys9F1RtO8UHMSUhJovbg1d2LvqB2SECYlpQnpU96/PI3yNyJFSWHifxPVDsdqpTu5LViwIPfu3dM/79ChA3fuyC9oIYR4HRuNDfNbz6dwjsLciLnBu0vfJSklSe2whDAZGVSWfiNqpn6TM+f4HG7EyEJY5pDu5Pb5NZHXrVtHXJzU1gghRHp4OnmyquMqPBw92HVtF4M3DFY7JCFMRp/cSs/ta1XPU51aQbVITEnk2z3fqh2OVXqr5XeFEEKkX5GcRVjQZgEaNPx88GdmHpmpdkhCmIS+LEF6btNFV3v7++HfuRt3V+VorE+6k1uNRoNGo0mzTQghRPo1L9ScMXXGAPDhug/Zd2OfyhEJ8fakLME49fPVp2JARZ4kP+H7vd+rHY7VsUtvQ0VR6NGjB46OjgDEx8fzv//9D1dXV4N2K1asMG2EQghhZb6o8QVHI46y4uwK2ixuw6E+h/B3l0G5IvOSAWXG0Wg0jKgxgncWvcO0g9MYUm0I2Z2zqx2W1Uh3z2337t3x9vbG09MTT09PunTpgr+/v/657iGEEOLVbDQ2zGk5h+K5inM79jZtl7QlITlB7bCEeGO6nttbj26RmJKocjSZQ/NCzSnlU4rYxFh+2v+T2uFYlXT33M6ePduccQghRJbi7ujOqo6rqDCjAvtu7KPfun7MaDFDyr1EpuTt6o2jrSMJKQncjLlJ3mx51Q4pw9NoNAyvMZwOyzrww/4f+LjKx7g7uqsdllWQAWVCCKGSAtkLsKjtImw0Nsw8OpPph6arHZIQb0Sj0ZDHMw8gdbfGaFu0LYVzFOZh/EN+PfSr2uFYDUluhRBCRY0KNGJCvQkADFg/gF3hu1SOSIg3I3W3xrO1sWVY9WEATNk7hSdJT1SOyDpIciuEECobUnUIHUt0JFmbTLul7bgefV3tkIQwmsyY8GbeK/kewV7B3I27yx9H/lA7HKsgya0QQqhMo9Ew852ZlPEtw924u7Re3Fp6cESmIws5vBl7W3uGVhsKwKQ9k2RwqQlIciuEEBmAi70LKzusJIdzDg7fPswHaz5IszKkEBmZLOTw5nqU6YG/uz83Ym7w5/E/1Q4n05PkVgghMohgr2CWvLsEW40t807M44f9P6gdkhDpJmUJb87RzpEhVYcA8M3ub0jWJqscUeYmya0QQmQgdfPWZUrDKQB8uvFTtlzeonJEQqSPruf2WvQ1tIpW5Wgyn95le5PLJReXH15m0alFaoeTqUlyK4QQGcyASgPoVrobKUoKHZZ14MrDK2qHJMRrBbgHYKOxITElkTuxd9QOJ9NxdXDl4yofA/D1rq/lD4S3IMmtEEJkMBqNhunNplPevzwPnjyg9eLWxCXGqR2WEK9kb2tPgHsAIKUJb+rDCh/i5eTFufvnWHF2hdrhZFqS3AohRAbkbO/MivYr8Hb15vid44SuDpUBZiLDk7lu346HowcDKg4AUntv5TP/ZiS5FUKIDCrQM5Dl7ZdjZ2PH4tOLmbxnstohCfFKMqjs7Q2oNAA3BzeORRxj3YV1aoeTKUlyK4QQGVj1PNX5qclPAAzdPJT1F9erHJEQLydz3b69HC456Fu+LwDjdo2T3ts3IMmtEEJkcB+U+4DeZXujoNBpeScuRl5UOyQhXkg/Y0LMNZUjydw+rvIxTnZO7Luxj21Xt6kdTqYjya0QQmRwGo2Gn5r8RJXcVYiKj6LlopY8SnikdlhCpJHHMw8gPbdvy9fNl95lewMwbuc4laPJfCS5FUKITMDRzpHl7Zfj5+bHmXtn6Laqm0wVJDIcqbk1nSFVh2BvY8+2q9vYc32P2uFkKpLcCiFEJuHn7seKDitwsHVg1blVfL3za7VDEsKAruc2JiGGqPgodYPJ5AI9A+leujuQOnOCSD9JboUQIhOpnLsyvzb7FYCR20eyOmy1yhEJ8ZSrgys5XXICUppgCkOrD8VGY8O6C+s4cvuI2uHopWgVDlyJBODAlUhStBlr0Jskt0IIkcn0CulFvwr9AOiyogvn7p9TOSIhnpLSBNPJnz0/nUp0AjJO7+36U7epPnErveYeBKDX3INUn7iV9aduqxzZU5LcCiFEJvR9o++pGVSTR4mPaLmoJdHx0WqHJAQgCzmY2hc1vgBgxdkVnL57WtVY1p+6Td/5R7gdHW+wPSI6nr7zj2SYBFeSWyGEyITsbe1Z+u5SAj0COf/gPJ1XdCZFm6J2WEJIz62JFctVjLZF2wIw4b8JqsWRolUY/c8ZXlSAoNs2+p8zGaJEQZJbIYTIpLxdvVnZYSVOdk6svbCWr7Z/pXZIQkhyawbDawwH4K9Tf6k2z/WBK5FpemyfpQC3o+P1tbhqkuRWCCEysXL+5ZjRYgaQWpO37MwylSMSWZ2UJZheiF8ITQs2RatomfjfRFViuPvo5Yntm7QzJ0luhRAik+tSqgsfV/4YgB6renDyzkmVIxJZmfTcmseIGiMAmHt8LteiLb8CnLe7k0nbmZMkt0IIYQUmNphIvbz1iEuKo9XiVkQ+Uf+rQZE16Xpu78bd5UnSE5WjsR5VAqtQJ7gOSdokJu+ebPHrV8ybHT9PJzQv2a8B/DydqJg3uyXDeiFJboUQwgrY2dixuN1igr2CufzwMh2XdSRZm6x2WCILyuaUDTcHNwCux1xXORrrMqJmau/tjCMziIiNsOi1bW00fNWiGECaBFf3/KsWxbC1eVn6azmS3AohhJXI4ZKDvzv+jYu9C5sub+KLLV+oHZLIgjQazdPSBKm7Nak6wXWokrsKCSkJfLf3O4tfv3EJP37tUpZgZ4WVMwcSsGsXAL6eTvzapSyNS/hZPKYXkeRWCCGsSCmfUsxpOQeAyXsm89fJv9QNSGRJumV4ranuNkWrsPfSA/4+dpO9lx6oMuWVRqPRz5zwy8FfePD4gXkupNVCWBjMnw8DB0LVqtA2dTqyxiX82PxlM/LzhGxhYczqXoH/Pq+bYRJbADu1AxBCCGFa7xZ/l2ERw5jw3wRCV4dSJGcRQvxC1A5LZCHW1nO7/tRtRv9zxmAqLD9PJ75qUcziSV3Tgk0p41uGYxHH+GH/D4ypM8Z0Jx83DrZtg0OHICbGcF/OnKAooNFga6NBWbaEixcuUDdv9gxRivAs6bkVQggrNLbOWJoUaMKT5Ce0WtyKe3H31A5JZCH66cCsoOc2o63KpdFo9DMn/HTgJ+NXJ7x3D9atg9GjoU8fw32bN8PWramJrbNzao/twIGpPbi7dxs0VSpVIj67+oPHXkR6boUQwgrZ2tiysO1CKs6oyIXIC7Rf1p6NXTZib2uvdmgiC7CW6cBetyqXhtRVuRoU87Vo72Xroq0pmrMoZ++f5ZeDvzCsxrCXNz54MLU39uDB1Ef4c/dk0iTw8kr990cfQZcuUKECFC8OdpkzTZSeWyGEsFJeTl6s6rgKNwc3tl/dzqcbP1U7JJFFWMtCDhl1VS4bjQ1f1EgdMPrdvu+IS4yDJ09g71748UdITHzaePp0+PxzWLYsNbHVaKBIEejaNbWt5pmkvG1beP99KF060ya2ID23Qghh1YrlKsa81vNovbg1Px74kRC/EHqU6aF2WMLK6Xpub8TcIFmbjJ1N5kw3MuyqXElJdEwqzFe2Obn8+D4zOhVi0N93ICUldX/16lC2bOq/GzRILTOoUCH1Ua4ceHhYNl4Lk55bIYSwcq2KtOKrWl8B8L81/+PAzQMqRySsnZ+7H/Y29qQoKdx6dEvtcN5YhliVSzdzQfQztbVTpmBXviJDV94HYHLwLeI1KeDtDc2apQ780unYEZYuhc8+gzp1rD6xBUluhRAiSxhZayQtC7ckISWBNovbWHwCeJG12GhsCPQMBDJ3aYLFV+VSlNTSgWXLUksJ6taFbNlSywg2bHjarnx58PCgW7ba5Na6c8sD5qz9GiIiYM2a1N7ZLEySWyGEyAJsNDb82fpPiuYsys1HN2m3pB2JKYmvP1CIN2QNg8rMviqXVvv037t2ga8vBAfDu++mDvTati21pMDJCe7cedq2Th14+BDHzdv4rOnXAEw8O4MkWZUQkORWCCGyDA9HD1Z1XIWnoye7r+9mwL8D1A5JWDFrGVSmW5XL19Ow9MDoVbmio1On2Zo4Edq1S01iJ058uj93brh7F2xtoUwZ6N0bfv8djh5NTXA/+uhpW1tbsElN4d4v+z7ert5cjbrKwpML3+7FWonMWeEthBDijRTKUYiFbRfSfGFzfjv8GyG+IXxQ/gO1wxJWSNdzey36msqRvL3GJfxoUMyXA1ciufsoHm/31FKE1/bYPngAgwalTsEVFpZ2/8GDT/8dHJw620Hp0qlzzKaTs70zn1T5hM83f874/8bTpVQXbG1s0328NZKeWyGEyGKaFmzK13VTv8r86N+P2H1t92uOEMJ41lCW8CxbGw1V8uegZZkAquTP8TSxTUqCY8dgxozURRHGjXt6kLs7LFnyNLHNkyd1uq1vvoEtW2D27KdtNRqoXNmoxFanb/m+ZHPKxvkH51l+dvmbv0grIT23QgiRBQ2tPpQjEUdYdmYZbZe05XCfwwR4BKgdlrAieTzzANaT3OopCixcCAcOpPa8Hj0K8c9MBVaqFIxIXUEMBwf46ScICEidhsvb2ywhuTu6M7DSQEbtGMW4neNoV6wdNpqs238pya0QQmRBGo2G2S1nE3Y/jJN3T9JmSRt29NiBk50ZpzQSWcqzNbeKoqDRWG4FL5NQFLh+PTWBvX8fPvj/8h2NJnXp2gsXnrb18EidoaBChdTe12c9v8StmXxU6SOm7J3CybsnWXN+De8Ufsci182IJLkVQogsys3BjVUdV1FhRgUO3DxA37V9mfXOrMyXhGRxKVrF+FpQCwj0SJ0K7EnyE+4/vk8u11wqR/Qa9+49XaJW97h7N3Wfm1vqyl22/1/L2qVLasKrWxihUCH9AC+1ZHfOTr8K/fhm9zd8vetrWhRqkWU/y5LcCiFEFpYvWz4Wt1tMo/mNmHNsDuX8ytG/Yn+1wxLptP7UbUb/c8ZgiVg/Tye+alEs/aP4zcTRzhE/Nz9ux94mPDo8YyW3MTFw/DjUqPF0W7dusH69YTtbWyhRIjWBjYt7ugDCyJGWi9UIg6sM5of9P3Dg5gE2X95Mg/wN1A5JFVm3IEMIIQQA9fPVZ3KDyQAMWj+I7Ve3qxuQSJf1p27Td/4Rg8QWICI6nr7zj7D+1G2VInsqQ0wHFh8P+/al1r526wZFi4KXF9SsmbrogU6lSlC4cGqv7NSpsHt3ahKsGyyWCVb28nb1pk+51DKIcbvGvaa19ZLkVgghBIMrD6Zzyc6kKCm8u/TdTD83qbVL0SqM/ucMygv26baN/ucMKdoXtbAci8+YkJwMKSlPn3/zTeqMBVWqwIABMG8enDuXWk+bJw/cuPG07Vdfpe6bNw8GDoSqVcHFxTJxm9CnVT/FwdaBneE72RW+S+1wVCHJrRBCCDQaDTNazKCsX1nuP75P68WteZz0WO2wxEscuBKZpsf2WQpwOzqeA1ciLRfUC+iTW3P8saTVwvnzsGBB6lyy1aql9q7u3fu0jZ9fasLr7Q3NmsGoUbB2bepqX+HhqcvY6lhJfWpuj9z0KN0DgK93fa1uMCpRNbmdMGECFSpUwN3dHW9vb1q1akXYc5Mcx8fH069fP3LkyIGbmxtt27blzrNL0AHXrl2jWbNmuLi44O3tzZAhQ0hOliXohBDCGM72zqzssJJcLrk4GnGU3v/0RlHU7fkTL3b30csT2zdpZy76sgRT9tzu3g3160P27E/LCH74AfbsgSdP4PDhp21btUpNYiMiYM2a1N7Zpk3NNiVXRvF59c+x1diy4dIGDt48+PoDrIyqye2OHTvo168f+/btY9OmTSQlJdGwYUPi4uL0bQYPHsw///zD0qVL2bFjB7du3aJNmzb6/SkpKTRr1ozExET27NnD3LlzmTNnDiMzaLG3EEJkZHk887D03aXYamxZeHIh3+39Tu2QxAt4u6dvyrb0tjOXNy5LuH8f/v0XxoyBFi1g+XMLE2zZkrqcrZOTYcnB2bOGy9R6eqaWH1hJr2x65cuWj86lOgNZs/dW1dkS1j83KnHOnDl4e3tz+PBhatasSXR0NDNnzmThwoXUrVsXgNmzZ1O0aFH27dtH5cqV2bhxI2fOnGHz5s34+PhQpkwZxo4dy+eff86oUaNwcHBQ46UJIUSmVSu4FlMbT+Wjfz/is82fUcqnVJYddZ1RVcybHT9PJyKi419Yd6sBfD1TpwVTU7oHlD14ALNmPZ2C6+rV504UlLqyF0BICPz+e+oMBsWLg7296QO3AsOqD2Pe8Xn8HfY3J++cpKRPSbVDspgMNRVYdHQ0ANmzp34YDx8+TFJSEvXr19e3KVKkCHny5GHv3r1UrlyZvXv3UrJkSXx8fPRtGjVqRN++fTl9+jQhISFprpOQkEBCQoL+eUxMDABJSUkkJSWZ5bU9S3cNS1xLmIfcw8xN7t/r9SnTh0M3DzH3xFw6LOvA3p57yZctn9ph6ck9hJHNCjN48TEAgwRX88x+bUoy2pTnj7Qcfxd/AB7GPyQyNhJ3xR7NiRNoDh1C6+MDzs6p9/DxY+w/+8zgWKVQIZRy5VDKl0dbq1bqMreQmsz26PG0YRb+GXiV/J75aVOkDcvPLWfcznHMbzXfpOdX4zOY3mtlmORWq9UyaNAgqlWrRokSJQCIiIjAwcEBLy8vg7Y+Pj5E/P/0HREREQaJrW6/bt+LTJgwgdGjR6fZvnHjRlwsODJy06ZNFruWMA+5h5mb3L9Xa0Yz9rrs5fzj8zSa3YhvCn6Ds63x696bU1a/hxMrvnxf4pXDrLtiuVjS0GrxuHYND60jMTYJhNUsTaWTEdj8/5iY+2XLwsiR+ntYukED4vz8iCpQgKj8+Ul2dX16rhs3DGc2EOlSXanOcpaz9MxSamlrEeBk+iW2LfkZfPw4fYNcM0xy269fP06dOsV///1n9msNGzaMjz/+WP88JiaGwMBAGjZsiIcF5rFLSkpi06ZNNGjQAHv5OiVTknuYucn9S78KjypQZVYVwuPCWZq0lL+a/5UhVj2Se/hUilbhcPhD7scmkNPNkXJB2Sy/QpmiwMWLaO7fR6lSJXWbVotdrlzkey+BY37wMPYGNsmQkC0HR7zz81/2EhQCvjxkQzY3Z4Z+O4v6RX1eeRlhvE1LNrHu4joOOBxgRtMZJjuvGp9B3Tftr5Mhktv+/fuzZs0adu7cSe7cufXbfX19SUxMJCoqyqD39s6dO/j6+urbHDhwwOB8utkUdG2e5+joiKOjY5rt9vb2Fv0laenrCdOTe5i5yf17veDswSzvsJzac2qz4twKvt3/LV/U+ELtsPTkHoI9UK2QBZNCRYGbNw2XqT10CKKioEABuHDhadu6dcljv5tj3Cf80/fZHtyHnlvuoGg0ONoqTCKFBK2Gaw8T+HDhcX7tUlb1ldWszZe1vmTdxXUsOLWAUXVGEewVbNLzW/IzmN7rqDpbgqIo9O/fn5UrV7J161by5s1rsL9cuXLY29uzZcsW/bawsDCuXbtGlf//y7BKlSqcPHmSu7r1n0ntIvfw8KBYsWKWeSFCCGHFqgZW5eemPwMwYusI1p5fq3JEwqKe7y1r0AACA6FNG5gwATZvTk1sHR0hVy5ITHzadtUqgpp2AuBK3uwMOxyD8oKe/4y08IS1qZy7MvXz1SdZm8yk3ZPUDsciVE1u+/Xrx/z581m4cCHu7u5EREQQERHBkydPAPD09CQ0NJSPP/6Ybdu2cfjwYXr27EmVKlWoXLkyAA0bNqRYsWJ07dqV48ePs2HDBkaMGEG/fv1e2DsrhBDCeL3L9eZ/5f6HgsJ7K94j7H7Y6w8Smc+jR7BjB3z7LXToAPnypc4J+2zCGhwMtrZQujS8/z789hscOZJ67J498NwsRbrpwI7evJApFp6wRsNrDAdg1tFZ3Hp0S+VozE/VsoRff/0VgNq1axtsnz17Nj3+fyTk999/j42NDW3btiUhIYFGjRrxyy+/6Nva2tqyZs0a+vbtS5UqVXB1daV79+6MGTPGUi9DCCGyhB+a/MDJuyfZfX03rRa3Yv/7+/FwNP84BWEB06bBr7+mzhP7ooU7wsKg5P9PJTV+PPz4Y7qXptVNB3Y95lq62qu98IQ1qhVUi2qB1dh9fTdT9kxhSqMpaodkVqomt+lZ+cbJyYmff/6Zn3/++aVtgoKCWLdunSlDE0II8RwHWweWtV9G+d/Lc+7+Obqu7MrKDiux0chK7hle8v+1d+dxUVb7H8A/MyM7AiJ7Km6oKa4sRq4p7pmauWU3XLI0vZZbZZmm994s08TMtH65VV63m3vqzX0LFXBLURIyVxBF2URZhvP749yZYQQVdZhnZvi8X695Nc9zzjzzHY5DX4/f55xCmbgWr5NduxbQlQNmZwMJCfJ59epyDVndIyQEKL5q0WPu7qWbuU2/dxUuj+gLKL/xhC1SqVSY0nYKuq3ohkXxizC5zWR4OXspHVa5sYgbyoiIyDr4ufph/YD1aLO0DTYlbsKMfTPwSftPlA6LSnP8uNy1KzZWlg3cv4xSbKwhue3XT87MhoUBvqa9OU03c5t+9zpqu2mQlqW16I0nbFWXOl0Q4h+C+JR4RB+Oxj87/FPpkMoN/7pNRESPJeyZMHzX8zsAwPR907Hh3AZlA6rorl4FNmwAPvoIiI83nE9KAubOBQ4elIlt5cpA+/bApEnAmjXyuU7dusCLL5o8sQUAb2dvOFVygoDAWx3cARg2mtDRHU/r2dD8y5hVECqVSl97O//ofGTcy1A2oHLEmVsiInpsrzd9HcdSjmHekXn42/q/4fDww2jk00jpsGzfnTsyWS1eXpCSYmh3cZFlBAAQEQGMGWMoL6hfH1Cbf05LpVKhhnsNJKYnoqbvXSx8rQWmb07ArZy7+j5+7o6Y1rMhlwErZ70a9EIj70Y4c+MMvj76Naa0naJ0SOWCyS0RET2RLzp9gVPXT2HPX3vQe3VvHH3jKKo4VVE6LNuRkyPLCdzd5coEgLyxq2tX434aDdCokUxgQ0MN56tVA+bPN1+8DxHoEYjE9ERczLiIoc07oFNDPxxOSsPNs4exJCoMz9X14YytGahVanzU5iO8uu5VRB+OxrvPvQtXe1elwzI5liUQEdETsdPYYfUrqxHoHoikW0l4dd2r0BZplQ7LOuXlyVnYb74Bhg4FgoNlUtuunVyZQKdxY9n26quGkoOsLODkSeD774HOnZX7DA+hu6nsYuZFAIBGrdLX1obX8mRia0b9G/VHXc+6SL+bjm/jvlU6nHLBmVsiInpi3i7eWD9gPVotaYXtSdsxZfcUzIycqXRYlk2rBdLTDasO3LkDVK0qE9z7VatmvFKBnR3w++9mCdOUdMntpcyyLQdG5Uej1mBy68kYvmk4ZsfMxtthb8PJzknpsEyKM7dERPRUmvs3x+KXFgMAPjv0GdacWaNwRBZECCA5GVi1CpgwAWjbVs7I9utn6OPiAtSoIRPcrl2Bjz8GNm2StbSXLwNzrH9NUt2KCbqZW1LWa01eQw33GkjNScWS40uUDsfkOHNLRERPbVDjQTieehxf/PYFhm4civpV66OpX9NyeS9tkdDvYnX0wi3LrdccPBjYvh24VcqOW+fPy8RXtxVtTAzg6Wk4tjH6soQMJreWwF5jj/eefw9jto3BrN9mYUTICNhr7B/9QivBmVsiIjKJmR1nonOdzsgtyEXv1b2Rnptu8vfYfjoFrT/fjWHLYwEAw5bHovXnu7H9dMojXlkObt0Cfv0V+Ne/gN69gfBw4/bbt2Ufe3vZNno0sGwZcOaMnJEtnshWrWqziS0A1HCvAQC4nHUZRaJI4WgIAIY1HwY/Vz9cyryEn079pHQ4JsXkloiITEKj1mBl35WoU6UO/sr4C/3/0x+FRYUmu/720ykY9dMxpGQab8+amnkPo346Zp4Ed/VqYNAgoE4dmZB26QJMmQJs3FhyWa4ZM4C4OLn715EjcovbqCigYUO5wkEF8ozbM9CoNMjX5iM1J1XpcAiAk50TJkZMBADMPDjTpN9VpTG5JSIik/F08sSGgRvgYueC3Rd2470d75nkutoigembE0rd2Up3bvrmBGiLHr2t+yPl5cmkdOFCYNgwecOXzsGDsn72zz/lcd26Mtn98kvgwAGZ8OqEhso1Z+1t5597n1QldSU84/YMAJYmWJK3Qt+Cp5Mnkm4lYe2ZtUqHYzJMbomIyKSCfYLxQ58fAABzD8/Fjyd/fOprHr1wq8SMbXECQErmPX0t7mO5eBFYuhR4+225Vqybm/zv22/L88ePG/r27SvLEH79VZYcnD8P/PvfwLhxQOvWTGQf4v7lwEh5rvauGPfcOADAvw78y2ZKRpjcEhGRyb387MuY0kbufjRi8wjEXYt7quulZT84sS1zPyHkjOvq1XLLWp0NG+QM7cKFcsY2P1/e3KUrOfDzM/Rt3x748EOgUyegCjeseBz6FRM4c2tRxoSPgZuDG87cOION5zYqHY5JMLklIqJyMf2F6Xix3ovI0+ahz+o+uJ5z/Ymv5VPZ8fH7Xbsma2GnTJGJqpeXrJUdOBDYscPQLyJCLtE1YYIsOUhOBm7elCsd/OMfsvSAnhpnbi2Th6MHxoSNASBnb4UwQWmPwrgUGBERlQu1So2f+vyElt+3RGJ6Ivqt7Yddr++Cncbusa8VXssT/u6OSM28V2rdrcfdbPi72ul3vcJ//1tym1pAlg00bQo4FVu0Pjwc2LfvsWOix8Pk1nK9+9y7iD4SjfiUePw3+b/oWreU744V4cwtERGVG3dHd2wYuAFuDm44cOkAxv133BNdR6NWYVrPhgAAl/y7CL10GnU2bMCX62dh37dv4MRXgzD/5kHDerfNmgFqtdyqduhQua1tbKxcueDoUWDAABN9QiorliVYLm8Xb4wMGQkA+Of+f1r97C1nbomIqFw18GqAFS+vwEsrX8KC2AVo7tccw1sML9uLi2100NVbjVM/T4Bz8nlo/nfjS3CxrnXzMwwHvr5AVpbc/YssQvGZW2tPnmzRhOcn4OvYr3Ho8iHsv7gf7Wq2UzqkJ8aZWyIiKncv1nsRM16YAQB4e+vbOHzlcMlOWi1w+rTxygVDhxravb1R+fo1aEQR8nz8kBIejovvfgDttu1Aerp8XXFMbC2KbiOHnPwcZNzLUDYYKiGgcgCGN5d/6fzngX8qHM3T4cwtERGZxYdtPsTx1ONYd3YdXl79MuLejEOAqz8weTLw22/AsWPGa8oCQEaG4blaDWzdCtSuDbW3N45u3Yru3btDY/f4Nbxkfk52TvBx8UHanTRczLyIRlUbKR0S3ee9Vu/h/479H3b+uRNHrhxBy2otlQ7piXDmloiIyt+1a1Bv2oxlp2qjUaEnUnJS0HdNX+Rp8+WqBAcOyMTWxQVo0wYYPx5YuVK2Fde6NRAQoMxnoKemL01g3a1FqulRE681eQ2AXDnBWnHmloiITO/gQbkCQWysfFy7BgCoDGCDrx3Cxnng8JXDGL11NP5v4kSoCgpkGcKzz1a4rWkrkkCPQMRei+WKCRZscuvJWH5iOTb/sRknUk+gmV8zpUN6bJy5JSKiJ3fnjpx1nT9f3vylM3euXF9240aZ2KrVQKNGwJAhqDs1GqteXAa1So3FxxdjUf1sWVsbHMzE1sbVcJN1t5y5tVz1qtbDgGC5msinBz5VOJonw5lbIiIqm/x84NQpw2xsbCyQkAAU/W/Lzh49gNq15fNu3QA7OzkbGxYGtGgBuLrqL9UFwMyMmXh/5/sYu30sgn2C0Sawjfk/E5mVfjkwztxatA9bf4hVp1fhPwn/wbmb59DAq4HSIT0WztwSEVFJWi1w5gyQm2s4N3WqTFTffluuTHD6tExs/f2Bl14C7hXb+vaNN+RuXxMmyN2/iiW2OpOen4SBwQNRWFSIV9a+gsuZl83wwUhJ3MjBOjT2bYxe9XtBQGDmwZlKh/PYmNwSEVV0QgB//gmsXg1MnAi0awd4eMgygYMHDf1CQ4EqVYDOnYGPPgI2bACuXjVsc9uw4WO9rUqlwuKXFqOZXzOk3UlDn9V9cLfgrkk/GlkWbuRgPT5q8xEAYMWpFfjz9p8KR/N4WJZARFTRFBXJGlhALq31+utyndj7OTsDKSmG4969gb599ZsqmIKznTPWD1iP0O9CEZ8Sj7e2vIXlvZdDZcL3IMuhm7m9kXsDuQW5j+hNSgp7Jgyd63TGr8m/4vODn+Pbnt8qHVKZceaWiCoUbZHA0Qu3AABHL9yCtsjGd0q6fRvYsQP49FOgTx+gWjXg22L/k/L3l4mtnZ2cmR01CliyBPj9dyAzE4iKMvStVMmkia1OTY+aWNNvDTQqDX489SPmHZln8vcgy+Dh6IHK9pUBAJcyLykcDT3KlDZTAADLTi7DlawrCkdTdkxuiajC2H46Ba0/341hy2MBAMOWx6L157ux/XTKI15pZa5cAV59FQgKAjw9S5YRxMYa+gYHA0ePAtnZ8vw33xhWLqhkvn/c61CrA+Z0ngMAmPjrROz6c5fZ3pvMR6VS6UsTLmUxubV0bQLboG1gW+Rr8zH7t9lKh1NmTG6JqELYfjoFo346hpTMe0bnUzPvYdRPx6wvwc3PB+LjgUWLgOHD5dJbOq6ucgOEpCR5XKcOMHAgMGcOsH8/8NVXhr66FQ0cHMwbfynGthyL15u+Dq3QYsB/BuDC7QtKh0TlQFeawJlb66Crvf0u/juk3UlTOJqyYc0tEdk8bZHA9M0JKK0AQQBQAZi+OQGdGvpBo7bQWk+tFvjpJ8MSXCdPAnl5hvY2bYBx4+RzDw/g66/lzG1oqJy9tQIqlQqLeixCwo0ExF2LQ5/VfXBo2CG42LsoHRqZUPHkNgDcbc7SdardCWEBYYi9Fou5MXMxM9LyV0/gzC0R2byjF26VmLEtTgBIybynr8VVlBDAhQvAmjXAsmWG82o1MGkSsGCBLCPIyzNeuWDyZOPrjB4t26wksdVxsnPCuv7r4OPig5PXT2L4puEQwsbroisYliVYF5VKhSltZe3t17Ff49ZdC/g9+QicuSUim5eW/eDE9kn6mVRqqvGmCHFxwM2bsi0gABgyRD5XqYBhwwDdNrVhYXLDBBtcVaC6e3X83P9nvLD8Baw+sxot/FvgvVbvKR0WmYhRWUJVhYOhMnmx3oto7NMYv6f9jvlH5mNa+2lKh/RQnLklIpvnU9nRpP2eWEYG8NtvxudefllugPCPfwDbt8vEVrdyQa9esrZW57PPZN3swIGyjtYGE1ud1jVaY363+QCAD3Z+gO1J2xWOiExFP3PLmluroVap9bW3847MQ3ZetsIRPRyTWyKyeeG1POHv7ogHpYIqAP7ujgivZcJ/ws/NBQ4dAqKjgcGDgXr1ZBlBmzbAnTuGfs89BzRqJGdodSUHxVcusLc3XUxW5q2QtzCixQgICAz6eRCSbiUpHRKZQA33GgCAq9lXoRVahaOhsnql4SuoV7Uebt+7jYVxC5UO56GY3BKRzdOoVZjWU+6edX+Cqzue1rPhk99MVlAgN0bQ+fBDwM0NaN1a3uT1738D58/Ltpo1gcvFtpmdM0duY7t0qdzW1kJWLrAEKpUK87vNR0S1CGTcy0CvVb0sfsaIHs3P1Q/2GntohRbpBaVsHkIWSaPWYHJrWds/J2aORe8myOSWiCqErsH+WPhaC/i5G5ce+Lk7YuFrLdA12L9sFyoqAs6eBX74Afj73+XMa+XKQEJCsYv6ydUN/P1LlhwkJwMNGhj62nBpgSk4VHLAz/1/hr+rPxJuJOD1Da+jSBQ9+oVksdQqNaq7VQcA3Mi/oXA09DgGNx6MQPdApN1Jw5ITS5QO54F4QxkRVRhdg/3RqaEfDiel4ebZw1gSFYbn6vqUbcZWt8tXfLwsG7hffLzc+ACQZQh9+wLPPGPaD1BB+Vf2x7oB69BuWTtsOLcB/9r/L3zw/AdKh0VPIdAjEMm3k5GWbx3rppJkp7HDB60/wKhfRmHO4TmYW2vuo1+kAM7cElGFolGr9LW14bU8jRPb69eBLVuAadOA7t2BX381tBUUAHv3ysTW2blkycHrrxv6Vq3KxNbEnqv2HBb2kHV+U/dOxeY/NiscET0N3YoJnLm1PkOaDYG/qz+uZF/Bntt7lA6nVJy5JaKKKyVFJqe6ZbiK18ICQIsWcq1YAIiIABYvljWxzz5r1q1pSRrWfBiOpRzDgtgFGLJpCGbWtvzF5Kl0TG6tl2MlR0x6fhLG/zoeP1//GbOLZsMOdkqHZYS/nYnI9uXmAidOyAS2Xj0gMlKez8oy3vxApZKJq24d2Q4dDG1Vqsh1ZklRc7vMxe9pv2P/xf0Yc24M3pn5jtIh0RPQ1U2nFbAswRq9GfImPj3wKa7fvY7VCasxpPkQpUMywuSWiGyLVgucOmW8McLp0/I8INeI1SW3QUHA3/4GNGkik9kWLeTNYWSx7DR2WNtvLV5Y9gISbiZwKSkrV8upltIh0BNwsXfB2PCxmLpvKmKvxjK5JSIymaIi4I8/5AxseLg8l58vnxcWGvf185MJbNu2hnNqtVz1gKyKj4sP4t+Ix8rNK9GxY0fYVbKsfxKlsinSFiFuX5zSYdATGhUyCs4pzhjbZazSoZTA5JaIrIMQwKVLxjOy8fEysQ0NlccA4OQkN0rQaAzlBWFh8gYv3bJbBQXKfQ4yCY1aA087T/i7+sPOjsmtNSrg99CquTu6o65zXaXDKBWTWyKyTFlZciMEnbAwmczez8lJ9hPCkLzu3m2eGImIyOIwuSUi5WVmysS1+KxsTo7c9ECXsNaqBZw8aaiP1T0aNuTKBUREpMf/IxCRcj7/XG47m5hYsk2lkktz1ZD70OPrr4EffwQcHUv2JSIi+h8mt0RUfgoK5EoFcXGGGdmdO+UmBwBw+7Yhsa1Z03hGtkUL47IEX1+zh09ERNaHyS0Rmdbhw4aNEU6cAO7dM26PjzdsjPD660C7dvKGMG9vs4dKRES2h8ktET0+3coFuhnZqCi5+QEA/P47MH++oa+7u0xedTOyoaGGtoYN5YOIiMhEmNwS0aNlZQEHDhhKC+LigLRiOwvVqGFIbtu1A955x5DM1q0r15MlIiIyAya3RGQsMxM4dkxueqBLWOPjgRdfNO5XqRLQuLFMYIODDefr1QOio80WLhERUXFMbokqsrt3ZV1s8SW4dDd4jR8PzJkjn4eEyES3eHlB06ZyjVkiIiILwuSWqKIoLJSrE+hu3EpNBapXL7lNLQAEBgKVKxuO3dyAhATzxElERPQUmNwS2aKiIuD8eeMZ2ePH5SoFGzfKPr6+gKenfF58Ca7QUMDHR7nYiYiIngKTWyJbIgTw0kvy5q/MzJLtf/xheK5SydlYT0/DLmBERERWjsktkbVJSzOekb17F9i9W7apVMCtWzKxdXQEmjc3npUNCjK+lm4zBSIiIhvB5JbIGixdCvzyi0xmL10yblOrgZwcwNVVHs+eLW/0atQIsLMzf6xEREQKYnJLZCmKr1xw/Djw/feARiPb9uwBfv7Z0Ld+feMZWUdHQ1tEhFnDJiIisiRMbomUkpwsywl05QWnTxuvXDBhgmH92EGD5ExsWJhclsvdXZmYiYiILByTW6LyVnzlgq5dAS8veX7FCmDaNOO+3t6G2djiCWy3bvJBRERED8XklsiUhAAuXza+4Ss+3rBywfr1QO/e8nnr1sALLxiXF9SowZULiIiIngKTW6KnceOGrHfVrRe7di0wYEDJfo6OQLNmcstanQ4d5IOIiIhMhsktUVllZclZ2NhYaI4cQacDB2B344ZcnWDCBNmnWTN5E1hwsPGMbHAwVy4gIiIyAya3RKURwlAe8OefQI8eQGKiPA9ADcBZ1/fyZcPrgoJkEuzsDCIiIjI/JrdEhYXAmTPGdbJt2gDz5sn2gAAgKUkmttWrA2Fh0IaE4LBWi/BRo2Cnu0EMkAkxE1siIiLFMLmlikmrlaUEujVl7941btetLwvIetmdO4EGDQBfXwBAUUEBbm7dyiW5iIiILAyTW7JdQgBXrhhmY4UAPvtMtmk0wMaNwF9/yePKlYHQUOM62eLatTNr6ERERPRkmNySbdm9Gzh40JDQXr9uaKtSBZg501BL+/HH8iavsDCgXj25jS0RERFZNSa3ZJ2ys+XKBefOASNHGs5/+imwa5fhWKMBGjc2zMYWFhpWLRg2zLwxExERUbljckuW79494ORJ4xu+zp3Tr1yAfv2AqlXl8549AX9/QzLbrBng5KRY6ERERGReTG7JshQWAgkJ8uYte3t5btw4YNGikn1r1JAJbHa2Ibl95x3zxUpEREQWh8ktKUcIucRW8RnZ48eB3FzgyBEgPFz2Cw0FvL2Nb/YKDdWvXEBERESkw+SWzEMI+dDdtLVmDfDWW0BGRsm+lSsDV68ajqOiZH2s7kYwIiIiogdgckvlIz3deEY2Nhb48ktg0CDZ7uMjE1sHB6B5c+NZ2ftXLqjEP6ZERERUNswayHSSkoCPPpKJ7IULJdtjYw3JbcuWwLFjQHCwYfUCIiIioqfE5JYeT16e8coFrVoBI0bINgcHWW6gU6+e8Yxss2aGNicnOWNLREREZEJMbunh8vKAFSsMyeypU0BBgaH91i1Dclutmiw9aNIECAkBPDwUCZmIiIgqLia3JAkBJCfLBBYwlA9oNMCYMcDdu4a+Xl6G2di2bQ3nVSq5bBcRERGRQpjcVlRXrxrf7BUXB9y+LdsaNjQkt5UqAW+8ATg6GhLawECuXEBEREQWicltRZCeLm/2atnScK5TJ+DsWeN+Dg6yLva55+RMri6B/eors4VKRERE9DSY3NqanBy5CkHxWdk//wScnYHMTMOyWhERcpWC4jd8BQcbdgUjIiIiskJMbq1ZXp5MRnUzrKNHy21qi4pK9n3mGSA1Vd70BQDff8/SAiIiIrI5TG6thVYrywiKz8iePClnZXUJq6+vTGyrVTOekQ0JAapUMb4eE1siIiKyQTaT3C5YsABffPEFUlNT0bRpU8yfPx/h4eFKh/X0Nm4E5syRpQZ37pRsj483JLcjRwJvvgn4+Zk3RiIiIiILYRPJ7erVqzF+/HgsWrQILVu2RHR0NLp06YLExET4+PgoHd6jXbtmPCP7ySeyJhaQCe2BA/K5q6uchS0+K1uzpuE61vBZiYiIiMqRTSS3X375JUaMGIGhQ4cCABYtWoRffvkFS5YswQcffKBwdKW4eBH11q6FZvFiOfN67Zpxe6dOhuT2hReAZctkIlu/vlx3loiIiIhKZfXJbX5+PuLj4zF58mT9ObVajcjISMTExJT6mry8POTl5emPs7KyAAAFBQUoKL77VjnRXr2KZ1es0B8LtRpo2BAiNBQiNBRFHToYdgHz8gJefVU+Lyoq/WYxMjvdnxNz/Hkh0+P4WT+OofXjGFo3JcavrO9l9cntzZs3odVq4evra3Te19cX586dK/U1M2fOxPTp00uc//XXX+Hs7FwucRanzs9Hs7ZtkVG3LjLq1kVm7drQOjoaOvzxh3yQxduxY4fSIdBT4PhZP46h9eMYWjdzjl9ubm6Z+ll9cvskJk+ejPHjx+uPs7KyUL16dXTu3Blubm7l/v4FBQXYYW+PTp06wc7Ortzfj0yvoKAAO3bs4BhaKY6f9eMYWj+OoXVTYvx0/9L+KFaf3Hp5eUGj0eD69etG569fvw6/B6wa4ODgAAcHhxLn7ezszPoFM/f7kelxDK0bx8/6cQytH8fQuplz/Mr6PupyjqPc2dvbIyQkBLt27dKfKyoqwq5duxChuymLiIiIiCoEq5+5BYDx48cjKioKoaGhCA8PR3R0NO7cuaNfPYGIiIiIKgabSG4HDBiAGzduYOrUqUhNTUWzZs2wffv2EjeZEREREZFts4nkFgDGjBmDMWPGKB0GERERESnI6mtuiYiIiIh0mNwSERERkc1gcktERERENoPJLRERERHZDCa3RERERGQzmNwSERERkc1gcktERERENoPJLRERERHZDCa3RERERGQzmNwSERERkc1gcktERERENoPJLRERERHZDCa3RERERGQzKikdgCUQQgAAsrKyzPJ+BQUFyM3NRVZWFuzs7MzynmRaHEPrxvGzfhxD68cxtG5KjJ8uT9PlbQ/C5BZAdnY2AKB69eoKR0JERERED5OdnQ13d/cHtqvEo9LfCqCoqAjXrl1D5cqVoVKpyv39srKyUL16dVy+fBlubm7l/n5kehxD68bxs34cQ+vHMbRuSoyfEALZ2dkICAiAWv3gylrO3AJQq9WoVq2a2d/Xzc2NX2grxzG0bhw/68cxtH4cQ+tm7vF72IytDm8oIyIiIiKbweSWiIiIiGwGk1sFODg4YNq0aXBwcFA6FHpCHEPrxvGzfhxD68cxtG6WPH68oYyIiIiIbAZnbomIiIjIZjC5JSIiIiKbweSWiIiIiGwGk1siIiIishlMbs1swYIFqFmzJhwdHdGyZUscPXpU6ZDoAT755BOoVCqjR4MGDfTt9+7dw+jRo1G1alW4urqib9++uH79uoIR0/79+9GzZ08EBARApVJhw4YNRu1CCEydOhX+/v5wcnJCZGQkzp8/b9Tn1q1bGDx4MNzc3ODh4YHhw4cjJyfHjJ+i4nrU+A0ZMqTEd7Jr165GfTh+ypo5cybCwsJQuXJl+Pj4oHfv3khMTDTqU5bfnZcuXUKPHj3g7OwMHx8fTJo0CYWFheb8KBVSWcavffv2Jb6HI0eONOqj9PgxuTWj1atXY/z48Zg2bRqOHTuGpk2bokuXLkhLS1M6NHqARo0aISUlRf84ePCgvm3cuHHYvHkz1q5di3379uHatWt4+eWXFYyW7ty5g6ZNm2LBggWlts+aNQtfffUVFi1ahCNHjsDFxQVdunTBvXv39H0GDx6MM2fOYMeOHdiyZQv279+PN99801wfoUJ71PgBQNeuXY2+kytXrjRq5/gpa9++fRg9ejQOHz6MHTt2oKCgAJ07d8adO3f0fR71u1Or1aJHjx7Iz8/Hb7/9huXLl2PZsmWYOnWqEh+pQinL+AHAiBEjjL6Hs2bN0rdZxPgJMpvw8HAxevRo/bFWqxUBAQFi5syZCkZFDzJt2jTRtGnTUtsyMjKEnZ2dWLt2rf7c2bNnBQARExNjpgjpYQCI9evX64+LioqEn5+f+OKLL/TnMjIyhIODg1i5cqUQQoiEhAQBQMTGxur7bNu2TahUKnH16lWzxU4lx08IIaKiokSvXr0e+BqOn+VJS0sTAMS+ffuEEGX73bl161ahVqtFamqqvs/ChQuFm5ubyMvLM+8HqODuHz8hhGjXrp145513HvgaSxg/ztyaSX5+PuLj4xEZGak/p1arERkZiZiYGAUjo4c5f/48AgICULt2bQwePBiXLl0CAMTHx6OgoMBoPBs0aIAaNWpwPC3UhQsXkJqaajRm7u7uaNmypX7MYmJi4OHhgdDQUH2fyMhIqNVqHDlyxOwxU0l79+6Fj48P6tevj1GjRiE9PV3fxvGzPJmZmQAAT09PAGX73RkTE4PGjRvD19dX36dLly7IysrCmTNnzBg93T9+OitWrICXlxeCg4MxefJk5Obm6tssYfwqmeVdCDdv3oRWqzUabADw9fXFuXPnFIqKHqZly5ZYtmwZ6tevj5SUFEyfPh1t2rTB6dOnkZqaCnt7e3h4eBi9xtfXF6mpqcoETA+lG5fSvoO6ttTUVPj4+Bi1V6pUCZ6enhxXC9C1a1e8/PLLqFWrFpKTk/Hhhx+iW7duiImJgUaj4fhZmKKiIrz77rto1aoVgoODAaBMvztTU1NL/Z7q2sg8Shs/AHj11VcRGBiIgIAAnDp1Cu+//z4SExOxbt06AJYxfkxuiR6gW7du+udNmjRBy5YtERgYiDVr1sDJyUnByIgqpoEDB+qfN27cGE2aNEGdOnWwd+9edOzYUcHIqDSjR4/G6dOnje5VIOvxoPErXsPeuHFj+Pv7o2PHjkhOTkadOnXMHWapWJZgJl5eXtBoNCXuCL1+/Tr8/PwUiooeh4eHB+rVq4ekpCT4+fkhPz8fGRkZRn04npZLNy4P+w76+fmVuMGzsLAQt27d4rhaoNq1a8PLywtJSUkAOH6WZMyYMdiyZQv27NmDatWq6c+X5Xenn59fqd9TXRuVvweNX2latmwJAEbfQ6XHj8mtmdjb2yMkJAS7du3SnysqKsKuXbsQERGhYGRUVjk5OUhOToa/vz9CQkJgZ2dnNJ6JiYm4dOkSx9NC1apVC35+fkZjlpWVhSNHjujHLCIiAhkZGYiPj9f32b17N4qKivS/wMlyXLlyBenp6fD39wfA8bMEQgiMGTMG69evx+7du1GrVi2j9rL87oyIiMDvv/9u9BeVHTt2wM3NDQ0bNjTPB6mgHjV+pTlx4gQAGH0PFR8/s9y2RkIIIVatWiUcHBzEsmXLREJCgnjzzTeFh4eH0R2FZDkmTJgg9u7dKy5cuCAOHTokIiMjhZeXl0hLSxNCCDFy5EhRo0YNsXv3bhEXFyciIiJERESEwlFXbNnZ2eL48ePi+PHjAoD48ssvxfHjx8XFixeFEEJ89tlnwsPDQ2zcuFGcOnVK9OrVS9SqVUvcvXtXf42uXbuK5s2biyNHjoiDBw+KoKAgMWjQIKU+UoXysPHLzs4WEydOFDExMeLChQti586dokWLFiIoKEjcu3dPfw2On7JGjRol3N3dxd69e0VKSor+kZubq+/zqN+dhYWFIjg4WHTu3FmcOHFCbN++XXh7e4vJkycr8ZEqlEeNX1JSkpgxY4aIi4sTFy5cEBs3bhS1a9cWbdu21V/DEsaPya2ZzZ8/X9SoUUPY29uL8PBwcfjwYaVDogcYMGCA8Pf3F/b29uKZZ54RAwYMEElJSfr2u3fvirfffltUqVJFODs7iz59+oiUlBQFI6Y9e/YIACUeUVFRQgi5HNjHH38sfH19hYODg+jYsaNITEw0ukZ6eroYNGiQcHV1FW5ubmLo0KEiOztbgU9T8Txs/HJzc0Xnzp2Ft7e3sLOzE4GBgWLEiBElJgc4fsoqbfwAiKVLl+r7lOV3519//SW6desmnJychJeXl5gwYYIoKCgw86epeB41fpcuXRJt27YVnp6ewsHBQdStW1dMmjRJZGZmGl1H6fFT/e/DEBERERFZPdbcEhEREZHNYHJLRERERDaDyS0RERER2Qwmt0RERERkM5jcEhEREZHNYHJLRERERDaDyS0RERER2Qwmt0RERERkM5jcEhFZIJVKhQ0bNpj0mqmpqejUqRNcXFzg4eFh0msXt2zZsnK9PhHRwzC5JaIKLSYmBhqNBj169Hjs19asWRPR0dGmD6oMhgwZgt69ez/Wa+bOnYuUlBScOHECf/zxh0niKO1nMGDAAJNdn4jocTG5JaIKbfHixfj73/+O/fv349q1a0qHU66Sk5MREhKCoKAg+Pj4lNv7ODk5lev1iYgehsktEVVYOTk5WL16NUaNGoUePXpg2bJlJfps3rwZYWFhcHR0hJeXF/r06QMAaN++PS5evIhx48ZBpVJBpVIBAD755BM0a9bM6BrR0dGoWbOm/jg2NhadOnWCl5cX3N3d0a5dOxw7duypPkv79u0xduxYvPfee/D09ISfnx8++eQTfXvNmjXx888/44cffoBKpcKQIUMAABkZGXjjjTfg7e0NNzc3dOjQASdPnnyqn0FpZQkLFy5EnTp1YG9vj/r16+PHH380alepVPj+++/Rp08fODs7IygoCJs2bdK33759G4MHD4a3tzecnJwQFBSEpUuXPtXPjIhsE5NbIqqw1qxZgwYNGqB+/fp47bXXsGTJEggh9O2//PIL+vTpg+7du+P48ePYtWsXwsPDAQDr1q1DtWrVMGPGDKSkpCAlJaXM75udnY2oqCgcPHgQhw8fRlBQELp3747s7Oyn+jzLly+Hi4sLjhw5glmzZmHGjBnYsWMHAJlQd+3aFf3790dKSgrmzZsHAOjXrx/S0tKwbds2xMfHo0WLFujYsSNu3bplsp/B+vXr8c4772DChAk4ffo03nrrLQwdOhR79uwx6jd9+nT0798fp06dQvfu3TF48GB9HB9//DESEhKwbds2nD17FgsXLoSXl9dT/byIyEYJIqIK6vnnnxfR0dFCCCEKCgqEl5eX2LNnj749IiJCDB48+IGvDwwMFHPnzjU6N23aNNG0aVOjc3PnzhWBgYEPvI5WqxWVK1cWmzdv1p8DINavX//A10RFRYlevXrpj9u1aydat25t1CcsLEy8//77+uNevXqJqKgo/fGBAweEm5ubuHfvntHr6tSpI7799lshxJP9DJYuXSrc3d31x88//7wYMWKEUZ9+/fqJ7t27648BiClTpuiPc3JyBACxbds2IYQQPXv2FEOHDn1gHEREOpy5JaIKKTExEUePHsWgQYMAAJUqVcKAAQOwePFifZ8TJ06gY8eOJn/v69evY8SIEQgKCoK7uzvc3NyQk5ODS5cuPdV1mzRpYnTs7++PtLS0B/Y/efIkcnJyULVqVbi6uuofFy5cQHJyMgDT/AzOnj2LVq1aGZ1r1aoVzp49+8D4XVxc4Obmpo9/1KhRWLVqFZo1a4b33nsPv/3221PFRES2q5LSARARKWHx4sUoLCxEQECA/pwQAg4ODvj666/h7u4OJyenx76uWq02Km0AgIKCAqPjqKgopKenY968eQgMDISDgwMiIiKQn5//ZB/mf+zs7IyOVSoVioqKHtg/JycH/v7+2Lt3b4k2Xc3sk/wMntTD4u/WrRsuXryIrVu3YseOHejYsSNGjx6N2bNnmy0+IrIOnLklogqnsLAQP/zwA+bMmYMTJ07oHydPnkRAQABWrlwJQM4k7tq164HXsbe3h1arNTrn7e2N1NRUowT3xIkTRn0OHTqEsWPHonv37mjUqBEcHBxw8+ZN033AMmrRogVSU1NRqVIl1K1b1+ihq2d9kp/B/Z599lkcOnTI6NyhQ4fQsGHDx4rX29sbUVFR+OmnnxAdHY3vvvvusV5PRBUDZ26JqMLZsmULbt++jeHDh8Pd3d2orW/fvli8eDFGjhyJadOmoWPHjqhTpw4GDhyIwsJCbN26Fe+//z4AuQLB/v37MXDgQDg4OMDLywvt27fHjRs3MGvWLLzyyivYvn07tm3bBjc3N/17BAUF4ccff0RoaCiysrIwadIks86Q6kRGRiIiIgK9e/fGrFmzUK9ePVy7dk1/E1loaOgT/QzuN2nSJPTv3x/NmzdHZGQkNm/ejHXr1mHnzp1ljnXq1KkICQlBo0aNkJeXhy1btuDZZ5812c+CiGwHZ26JqMJZvHgxIiMjSyS2gExu4+LicOrUKbRv3x5r167Fpk2b0KxZM3To0AFHjx7V950xYwb++usv1KlTB97e3gDkLOU333yDBQsWoGnTpjh69CgmTpxY4v1v376NFi1a4G9/+xvGjh2ryLqwKpUKW7duRdu2bTF06FDUq1cPAwcOxMWLF+Hr6wsAT/QzuF/v3r0xb948zJ49G40aNcK3336LpUuXon379mWO1d7eHpMnT0aTJk3Qtm1baDQarFq16qk+PxHZJpW4vziMiIiIiMhKceaWiIiIiGwGk1siIiIishlMbomIiIjIZjC5JSIiIiKbweSWiIiIiGwGk1siIiIishlMbomIiIjIZjC5JSIiIiKbweSWiIiIiGwGk1siIiIishlMbomIiIjIZvw/ROen7yio4u4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "actual_infections = np.array([100, 150, 200, 180, 220, 250])\n",
    "forecast_infections = np.array([120, 160, 190, 210, 240, 260])\n",
    "\n",
    "# Calculate squared error\n",
    "squared_error = np.square(actual_infections - forecast_infections)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(actual_infections, forecast_infections, label='Actual vs. Forecast')\n",
    "plt.plot([0, max(actual_infections)], [0, max(actual_infections)], 'r--', label='Ideal 45-degree line')\n",
    "plt.plot(actual_infections, squared_error, 'g-', label='Squared Error')\n",
    "\n",
    "plt.xlabel('Actual Infections')\n",
    "plt.ylabel('Forecast Infections')\n",
    "plt.title('Actual vs. Forecast Infections with Squared Error')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
