{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "scaler = MinMaxScaler()\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN, LSTM, TimeDistributed, Input, Dropout, GRU\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from keras.saving import register_keras_serializable\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0, len(dataset)-2 *look_back+1, look_back):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back: i+ 2*look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def exponential_moving_average(data, span):\n",
    "    return data.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def read_data(file_path, num_features = 1):\n",
    "    from pandas import read_csv\n",
    "    series_influ_A_df = read_csv(file_path, index_col=0, engine='python')\n",
    "    series_influ_A_df = series_influ_A_df.rename(columns= {\"Influenza A - All types of surveillance\": \"case\"})\n",
    "    series_influ_A_df = series_influ_A_df[[\"case\", \"humidity\", \"temp\", \"dew\",\"windspeed\", \"tempmax\",][:num_features]]\n",
    "    return series_influ_A_df.dropna()\n",
    "\n",
    "def prepare_data(series, look_back, scaler, is_ema = False):\n",
    "    if is_ema:\n",
    "        span = 52  # Bạn có thể điều chỉnh độ dài span tùy ý\n",
    "        series['case'] = exponential_moving_average(series['case'], span)\n",
    "    series = series.astype('float32')\n",
    "    series = series.values\n",
    "    if scaler is not None:\n",
    "        flattened_dataset = series.flatten()\n",
    "        dataset = scaler.fit_transform(flattened_dataset.reshape(-1,1))\n",
    "        dataset = dataset.reshape(series.shape)\n",
    "\n",
    "    else: \n",
    "        dataset = series\n",
    "\n",
    "    rest = len(dataset) % look_back\n",
    "    dataset = dataset[rest:, :]\n",
    "    trainsize = len(dataset) - look_back\n",
    "    train = dataset[:trainsize, :]\n",
    "    test = dataset[trainsize - look_back:, :]\n",
    "\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "def forecast(input, model):\n",
    "    predicted = model.predict(input, verbose=0)\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def save_plot(x,y, file_path):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy import stats\n",
    "\n",
    "    # Generate some sample data\n",
    "    # x = y_inverse.flatten()\n",
    "    # y = y_hat_inverse.flatten()\n",
    "\n",
    "    # Compute the linear regression line\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    # Create the R-squared line\n",
    "    r2_line = slope * x + intercept\n",
    "    r2 = r2_score(x, y)\n",
    "    r2_pearson = r_value**2\n",
    "\n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(x, y, label='Data Points')\n",
    "    plt.plot(x, r2_line, color='red', label=f'R-squared line (R²={r2:.2f})')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('actual number of infection')\n",
    "    plt.ylabel('forecast number of infection')\n",
    "    plt.title('Scatter Plot with R-squared Line')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "\n",
    "def inverse_transform(data, scaler):\n",
    "    flattened_data = data.flatten()\n",
    "    inverse_flattened_data = scaler.inverse_transform(flattened_data.reshape(-1,1))\n",
    "    return inverse_flattened_data.reshape(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class MyLSTM (Sequential):\n",
    "    def __init__(self, look_back, dense_units =[],unit=64, optimizer='adam',name='lstm'):\n",
    "        super().__init__(name=name)\n",
    "        self.look_back = look_back\n",
    "        self.add(Input(shape=(look_back,1)))\n",
    "        self.add(LSTM(units=unit, activation='relu', return_sequences=True))\n",
    "        for unit in dense_units:\n",
    "            self.add(Dense(units=unit, activation='relu'))\n",
    "        self.add(TimeDistributed(Dense(units=5, activation='sigmoid' )))\n",
    "        self.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "\n",
    "def build_model(input_shape, dropout=None, dense_units = [], unit=64, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    model.add(LSTM(units=unit, activation='relu', return_sequences=True))\n",
    "\n",
    "    # if first_additional_layer:\n",
    "    #     model.add(LSTM(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "\n",
    "    # if second_additional_layer:\n",
    "    #     model.add(LSTM(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "\n",
    "    # if third_additional_layer:\n",
    "    #     model.add(GRU(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "    for unit in dense_units:\n",
    "        model.add(Dense(units=unit, activation='relu'))\n",
    "    model.add(TimeDistributed(Dense(units=input_shape[1], activation='sigmoid' )))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat_inverse = np.expand_dims(scaler.inverse_transform(testY_hat[0]), axis=0)\n",
    "# y_inverse = np.expand_dims(scaler.inverse_transform(testY[0]), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(testY, forecasts):\n",
    "    import matplotlib.pyplot as plt\n",
    "    forecastsPlot = forecasts[:,:,0].reshape(-1)\n",
    "    testPlot = testY[:,:,0].reshape(-1)\n",
    "    plt.plot(testPlot, \"-y\", label=\"actual\", marker= '.')\n",
    "    plt.plot(forecastsPlot, color = 'green', label=\"forecast\")\n",
    "    plt.ylabel(\"Number of infections\")\n",
    "    plt.legend([\"actual\", \"forecast\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(y_inverse, y_hat_inverse)\n",
    "# print(model.predict(trainX).shape)\n",
    "# print(trainY.shape)\n",
    "# forecasts = model.predict(trainX)\n",
    "# plot(trainY, forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os, json\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def LSTM_HyperParameter_Tuning(config, df, scaler):\n",
    "    \n",
    "    n_neurons, n_batch_sizes, dropouts, look_backs, is_emas = config\n",
    "    possible_combinations = list(itertools.product(n_neurons, n_batch_sizes, dropouts, look_backs, is_emas))\n",
    "    \n",
    "    print(possible_combinations)\n",
    "    print('\\n')\n",
    "    \n",
    "    hist = []\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "        print(f'{i+1}th combination: \\n')\n",
    "        print('--------------------------------------------------------------------')\n",
    "        n_neurons, n_batch_size, dropout, look_back, is_ema = possible_combinations[i]\n",
    "\n",
    "        df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=2)\n",
    "        \n",
    "        trainX, trainY, testX, testY = prepare_data(df, look_back, scaler, is_ema=is_ema)\n",
    "        model = build_model(input_shape=(trainX.shape[1], trainX.shape[2]), dense_units=n_neurons[1:], unit=n_neurons[0])\n",
    "\n",
    "        es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "        '''''\n",
    "        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n",
    "        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n",
    "        '''''\n",
    "        a = 'ema' if is_ema else 'not_ema'\n",
    "        lstm_dir = os.path.join(\"../result\", f\"\"\"lstm_{a}\"\"\")\n",
    "        lstm_combination_dir = os.path.join(lstm_dir, str(i))\n",
    "        os.makedirs(lstm_combination_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(lstm_combination_dir, 'best_lstm_m2m_model.keras')\n",
    "\n",
    "        mc = ModelCheckpoint(file_path, monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "        '''''\n",
    "        cb = Callback(...)  # First, callbacks must be instantiated.\n",
    "        cb_list = [cb, ...]  # Then, one or more callbacks that you intend to use must be added to a Python list.\n",
    "        model.fit(..., callbacks=cb_list)  # Finally, the list of callbacks is provided to the callback argument when fitting the model.\n",
    "        '''''\n",
    "\n",
    "        model.fit(trainX, trainY,batch_size=n_batch_size, callbacks=[es, mc], verbose=0, epochs=200)\n",
    "        train_accuracy = model.evaluate(trainX, trainY, verbose=0)\n",
    "        # test_accuracy = model.evaluate(testX, testY, verbose=0)\n",
    "        # hist.append(list((n_neurons, n_batch_size, dropout,look_back,\n",
    "        #                   train_accuracy, test_accuracy)))\n",
    "        hist.append(list((n_neurons, n_batch_size, dropout,look_back,\n",
    "                          train_accuracy)))\n",
    "        \n",
    "        \n",
    "        config= {\n",
    "            \"units\": n_neurons,\n",
    "            \"n_batch_size\": n_batch_size,\n",
    "            \"dropout\": dropout,\n",
    "            \"look_back\": look_back,\n",
    "            \"is_ema\": is_ema\n",
    "        }\n",
    "        with open(os.path.join(lstm_combination_dir,'config.json'), 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "        \n",
    "\n",
    "        # print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy}')\n",
    "        \n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "\n",
    "        n_neurons, n_batch_size, dropout, look_back, is_ema = possible_combinations[i]\n",
    "        df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=2)\n",
    "        trainX, trainY, testX, testY = prepare_data(df, look_back, scaler, is_ema=is_ema)\n",
    "\n",
    "        a = 'ema' if is_ema else 'not_ema'\n",
    "        lstm_dir = os.path.join(\"../result\", f\"\"\"lstm_{a}\"\"\")\n",
    "        lstm_combination_dir = os.path.join(lstm_dir, str(i))\n",
    "        os.makedirs(lstm_combination_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(lstm_combination_dir, 'best_lstm_m2m_model.keras')\n",
    "\n",
    "\n",
    "        model = load_model(file_path)\n",
    "\n",
    "        #TODO: save r square\n",
    "        testY_hat = forecast(testX, model)\n",
    "        y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "        y_inverse = inverse_transform(testY, scaler)\n",
    "\n",
    "        r2_image_path = os.path.join(lstm_combination_dir, 'r2_image.png')\n",
    "        save_plot(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten(), r2_image_path)\n",
    "        \n",
    "    import pandas as pd\n",
    "    hist_df = pd.DataFrame(hist)\n",
    "    hist_df = hist_df.rename(columns={0: 'units', 1: 'batch_size', 2: 'dropout', 3: 'look_back', 4: 'train_loss'})\n",
    "    hist_df = hist_df.sort_values(by=['train_loss'], ascending=True)\n",
    "    hist_df.to_csv(os.path.join(lstm_dir, 'history.csv'))\n",
    "    return hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([64], 1, 0.2, 10, True), ([64], 1, 0.2, 12, True), ([64], 1, 0.2, 15, True), ([64], 1, 0.2, 17, True), ([64], 2, 0.2, 10, True), ([64], 2, 0.2, 12, True), ([64], 2, 0.2, 15, True), ([64], 2, 0.2, 17, True), ([64], 4, 0.2, 10, True), ([64], 4, 0.2, 12, True), ([64], 4, 0.2, 15, True), ([64], 4, 0.2, 17, True), ([64], 8, 0.2, 10, True), ([64], 8, 0.2, 12, True), ([64], 8, 0.2, 15, True), ([64], 8, 0.2, 17, True)]\n",
      "\n",
      "\n",
      "1th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07744, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07744 to 0.02754, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02754 to 0.01701, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01701 to 0.01224, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01224 to 0.00981, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00981 to 0.00812, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00812 to 0.00716, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00716 to 0.00647, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00647 to 0.00585, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00585 to 0.00554, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00554 to 0.00516, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00516 to 0.00497, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00497\n",
      "\n",
      "Epoch 14: loss improved from 0.00497 to 0.00473, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00473 to 0.00468, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00468 to 0.00456, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00456 to 0.00454, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00454 to 0.00437, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 21: loss improved from 0.00437 to 0.00434, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00434 to 0.00421, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00421 to 0.00414, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00414 to 0.00408, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00408 to 0.00390, saving model to ../result\\lstm_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00390\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00390\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00390\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00390\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00390\n",
      "Epoch 30: early stopping\n",
      "2th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08834, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08834 to 0.03281, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03281 to 0.02369, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02369 to 0.01789, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01789 to 0.01449, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01449 to 0.01170, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01170 to 0.00941, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00941 to 0.00821, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00821 to 0.00764, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00764 to 0.00690, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00690 to 0.00633, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00633 to 0.00606, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00606 to 0.00580, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00580 to 0.00553, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00553 to 0.00530, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00530 to 0.00513, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00513 to 0.00492, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00492 to 0.00482, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00482 to 0.00465, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00465 to 0.00448, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00448 to 0.00444, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00444 to 0.00430, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00430 to 0.00416, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00416 to 0.00414, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 27: loss improved from 0.00414 to 0.00400, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 29: loss improved from 0.00400 to 0.00395, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 32: loss improved from 0.00395 to 0.00395, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00395 to 0.00389, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00389 to 0.00388, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00388 to 0.00378, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 40: loss improved from 0.00378 to 0.00377, saving model to ../result\\lstm_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00377\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00377\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00377\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00377\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00377\n",
      "Epoch 45: early stopping\n",
      "3th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08970, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08970 to 0.03015, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03015 to 0.01836, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01836 to 0.01324, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01324 to 0.01095, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01095 to 0.00956, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00956 to 0.00875, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00875 to 0.00766, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00766 to 0.00716, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00716 to 0.00685, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00685 to 0.00631, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00631 to 0.00590, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00590 to 0.00559, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00559 to 0.00551, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00551 to 0.00497, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00497\n",
      "\n",
      "Epoch 17: loss improved from 0.00497 to 0.00478, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00478 to 0.00477, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00477 to 0.00459, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00459\n",
      "\n",
      "Epoch 21: loss improved from 0.00459 to 0.00436, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00436 to 0.00432, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00432 to 0.00426, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 26: loss improved from 0.00426 to 0.00415, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00415\n",
      "\n",
      "Epoch 28: loss improved from 0.00415 to 0.00410, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00410 to 0.00408, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00408 to 0.00399, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 34: loss improved from 0.00399 to 0.00398, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00398\n",
      "\n",
      "Epoch 36: loss improved from 0.00398 to 0.00397, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00397\n",
      "\n",
      "Epoch 38: loss improved from 0.00397 to 0.00394, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00394\n",
      "\n",
      "Epoch 40: loss improved from 0.00394 to 0.00394, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00394 to 0.00387, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00387 to 0.00385, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00385\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00385\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00385\n",
      "\n",
      "Epoch 46: loss improved from 0.00385 to 0.00381, saving model to ../result\\lstm_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00381\n",
      "Epoch 51: early stopping\n",
      "4th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08985, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08985 to 0.03712, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03712 to 0.03208, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03208 to 0.02815, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02815 to 0.01864, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01864 to 0.01459, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01459 to 0.01175, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01175 to 0.01036, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01036 to 0.00935, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00935 to 0.00851, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00851 to 0.00776, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00776 to 0.00723, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00723 to 0.00692, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00692 to 0.00650, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00650 to 0.00614, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00614 to 0.00584, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00584 to 0.00561, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00561 to 0.00535, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00535\n",
      "\n",
      "Epoch 20: loss improved from 0.00535 to 0.00509, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00509 to 0.00490, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00490 to 0.00478, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00478 to 0.00476, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00476 to 0.00459, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00459\n",
      "\n",
      "Epoch 26: loss improved from 0.00459 to 0.00455, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00455 to 0.00441, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00441 to 0.00435, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00435 to 0.00434, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00434 to 0.00431, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 33: loss improved from 0.00431 to 0.00430, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00430 to 0.00412, saving model to ../result\\lstm_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00412\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00412\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00412\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00412\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00412\n",
      "Epoch 39: early stopping\n",
      "5th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11645, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11645 to 0.05078, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05078 to 0.03038, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03038 to 0.02311, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02311 to 0.01809, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01809 to 0.01446, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01446 to 0.01208, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01208 to 0.01056, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01056 to 0.00941, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00941 to 0.00861, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00861 to 0.00780, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00780 to 0.00720, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00720 to 0.00672, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00672 to 0.00635, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00635 to 0.00602, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00602 to 0.00576, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00576 to 0.00547, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00547 to 0.00521, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00521 to 0.00505, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00505 to 0.00489, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00489 to 0.00474, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00474 to 0.00458, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00458 to 0.00451, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00451 to 0.00441, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00441 to 0.00438, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00438\n",
      "\n",
      "Epoch 27: loss improved from 0.00438 to 0.00416, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00416\n",
      "\n",
      "Epoch 29: loss improved from 0.00416 to 0.00407, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00407 to 0.00400, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00400 to 0.00398, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00398\n",
      "\n",
      "Epoch 33: loss improved from 0.00398 to 0.00387, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 37: loss improved from 0.00387 to 0.00385, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00385\n",
      "\n",
      "Epoch 39: loss improved from 0.00385 to 0.00378, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00378 to 0.00378, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 42: loss improved from 0.00378 to 0.00377, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00377 to 0.00374, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00374\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00374\n",
      "\n",
      "Epoch 46: loss improved from 0.00374 to 0.00371, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 48: loss improved from 0.00371 to 0.00367, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00367\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00367\n",
      "\n",
      "Epoch 51: loss improved from 0.00367 to 0.00367, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00367\n",
      "\n",
      "Epoch 53: loss improved from 0.00367 to 0.00366, saving model to ../result\\lstm_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00366\n",
      "Epoch 58: early stopping\n",
      "6th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11620, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11620 to 0.04852, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04852 to 0.03377, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03377 to 0.03119, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03119 to 0.02655, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02655 to 0.02075, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02075 to 0.01804, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01804 to 0.01636, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01636 to 0.01445, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01445 to 0.01316, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01316 to 0.01199, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01199 to 0.00982, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00982 to 0.00892, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00892 to 0.00819, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00819 to 0.00766, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00766 to 0.00748, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00748 to 0.00692, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00692 to 0.00665, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00665 to 0.00632, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00632 to 0.00600, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00600 to 0.00583, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00583 to 0.00564, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00564 to 0.00534, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00534 to 0.00524, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00524 to 0.00496, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00496\n",
      "\n",
      "Epoch 27: loss improved from 0.00496 to 0.00467, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00467 to 0.00462, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00462 to 0.00447, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 32: loss improved from 0.00447 to 0.00427, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00427 to 0.00419, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00419 to 0.00419, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00419 to 0.00409, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00409 to 0.00406, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 38: loss improved from 0.00406 to 0.00401, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00401 to 0.00393, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 43: loss improved from 0.00393 to 0.00390, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00390 to 0.00389, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00389 to 0.00388, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00388\n",
      "\n",
      "Epoch 47: loss improved from 0.00388 to 0.00387, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 49: loss improved from 0.00387 to 0.00382, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00382 to 0.00381, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.00381 to 0.00380, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.00380 to 0.00371, saving model to ../result\\lstm_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00371\n",
      "Epoch 57: early stopping\n",
      "7th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08400, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08400 to 0.03517, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03517 to 0.02449, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02449 to 0.01827, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01827 to 0.01535, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01535 to 0.01341, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01341 to 0.01214, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01214 to 0.01105, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01105 to 0.01049, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01049 to 0.00939, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00939 to 0.00875, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00875 to 0.00831, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00831 to 0.00785, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00785 to 0.00752, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00752 to 0.00723, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00723 to 0.00695, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00695 to 0.00671, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00671 to 0.00636, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00636 to 0.00619, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00619 to 0.00608, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00608 to 0.00592, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00592 to 0.00561, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00561 to 0.00547, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00547 to 0.00539, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00539 to 0.00526, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00526 to 0.00505, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00505 to 0.00496, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00496 to 0.00487, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00487 to 0.00469, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00469\n",
      "\n",
      "Epoch 31: loss improved from 0.00469 to 0.00464, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00464 to 0.00458, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00458 to 0.00456, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00456 to 0.00437, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00437 to 0.00437, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 37: loss improved from 0.00437 to 0.00416, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00416\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00416\n",
      "\n",
      "Epoch 40: loss improved from 0.00416 to 0.00410, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00410\n",
      "\n",
      "Epoch 42: loss improved from 0.00410 to 0.00406, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 44: loss improved from 0.00406 to 0.00404, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00404 to 0.00400, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 48: loss improved from 0.00400 to 0.00396, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 50: loss improved from 0.00396 to 0.00393, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 55: loss improved from 0.00393 to 0.00389, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 58: loss improved from 0.00389 to 0.00388, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00388\n",
      "\n",
      "Epoch 60: loss improved from 0.00388 to 0.00381, saving model to ../result\\lstm_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 62: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 63: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 64: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 65: loss did not improve from 0.00381\n",
      "Epoch 65: early stopping\n",
      "8th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12947, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12947 to 0.07720, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.07720 to 0.04027, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04027 to 0.03423, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03423 to 0.03144, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03144 to 0.02967, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02967 to 0.02856, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02856 to 0.02741, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02741 to 0.02610, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02610 to 0.02371, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02371 to 0.02341, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02341 to 0.02226, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02226 to 0.01721, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01721 to 0.01378, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01378 to 0.01250, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01250 to 0.01090, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01090 to 0.01014, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01014 to 0.00961, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00961 to 0.00919, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00919 to 0.00885, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00885 to 0.00849, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00849 to 0.00818, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00818 to 0.00812, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00812 to 0.00766, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00766 to 0.00743, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00743 to 0.00721, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00721 to 0.00713, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00713 to 0.00697, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00697 to 0.00671, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00671 to 0.00653, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00653 to 0.00640, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00640 to 0.00624, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00624 to 0.00611, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00611 to 0.00605, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00605 to 0.00596, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00596 to 0.00583, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00583 to 0.00577, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00577 to 0.00558, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00558 to 0.00555, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00555 to 0.00538, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00538 to 0.00524, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00524 to 0.00517, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00517 to 0.00512, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00512 to 0.00504, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00504 to 0.00493, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00493 to 0.00484, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00484 to 0.00475, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 49: loss improved from 0.00475 to 0.00466, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00466 to 0.00460, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.00460 to 0.00457, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.00457 to 0.00456, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00456\n",
      "\n",
      "Epoch 54: loss improved from 0.00456 to 0.00451, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00451 to 0.00446, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00446 to 0.00442, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00442 to 0.00432, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00432\n",
      "\n",
      "Epoch 59: loss improved from 0.00432 to 0.00431, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss improved from 0.00431 to 0.00431, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss improved from 0.00431 to 0.00429, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 62: loss improved from 0.00429 to 0.00423, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00423 to 0.00420, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss improved from 0.00420 to 0.00419, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 65: loss improved from 0.00419 to 0.00419, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 66: loss improved from 0.00419 to 0.00417, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 67: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 68: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 69: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 70: loss improved from 0.00417 to 0.00407, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 71: loss did not improve from 0.00407\n",
      "\n",
      "Epoch 72: loss improved from 0.00407 to 0.00403, saving model to ../result\\lstm_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 74: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 75: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 77: loss did not improve from 0.00403\n",
      "Epoch 77: early stopping\n",
      "9th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12203, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12203 to 0.08257, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.08257 to 0.04365, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04365 to 0.03602, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03602 to 0.02885, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02885 to 0.02194, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02194 to 0.01779, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01779 to 0.01544, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01544 to 0.01370, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01370 to 0.01226, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01226 to 0.01119, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01119 to 0.01035, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01035 to 0.00958, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00958 to 0.00898, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00898 to 0.00859, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00859 to 0.00807, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00807 to 0.00760, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00760 to 0.00723, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00723 to 0.00688, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00688 to 0.00656, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00656 to 0.00631, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00631 to 0.00603, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00603 to 0.00581, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00581 to 0.00554, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00554 to 0.00547, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00547 to 0.00519, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00519 to 0.00502, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00502 to 0.00484, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00484 to 0.00477, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00477 to 0.00471, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00471 to 0.00448, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00448\n",
      "\n",
      "Epoch 33: loss improved from 0.00448 to 0.00437, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 35: loss improved from 0.00437 to 0.00428, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00428 to 0.00422, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00422\n",
      "\n",
      "Epoch 38: loss improved from 0.00422 to 0.00420, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00420 to 0.00415, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00415 to 0.00408, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 42: loss improved from 0.00408 to 0.00398, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00398\n",
      "\n",
      "Epoch 44: loss improved from 0.00398 to 0.00396, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 46: loss improved from 0.00396 to 0.00393, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00393 to 0.00388, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00388\n",
      "\n",
      "Epoch 49: loss improved from 0.00388 to 0.00386, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00386 to 0.00384, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 54: loss improved from 0.00384 to 0.00381, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00381 to 0.00379, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00379\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00379\n",
      "\n",
      "Epoch 58: loss improved from 0.00379 to 0.00376, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 60: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 62: loss improved from 0.00376 to 0.00376, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00376 to 0.00374, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss did not improve from 0.00374\n",
      "\n",
      "Epoch 65: loss did not improve from 0.00374\n",
      "\n",
      "Epoch 66: loss improved from 0.00374 to 0.00373, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 67: loss improved from 0.00373 to 0.00370, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 68: loss improved from 0.00370 to 0.00367, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 69: loss did not improve from 0.00367\n",
      "\n",
      "Epoch 70: loss did not improve from 0.00367\n",
      "\n",
      "Epoch 71: loss improved from 0.00367 to 0.00364, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 72: loss did not improve from 0.00364\n",
      "\n",
      "Epoch 73: loss improved from 0.00364 to 0.00363, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 74: loss improved from 0.00363 to 0.00363, saving model to ../result\\lstm_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss did not improve from 0.00363\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00363\n",
      "\n",
      "Epoch 77: loss did not improve from 0.00363\n",
      "\n",
      "Epoch 78: loss did not improve from 0.00363\n",
      "\n",
      "Epoch 79: loss did not improve from 0.00363\n",
      "Epoch 79: early stopping\n",
      "10th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12253, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12253 to 0.08517, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.08517 to 0.04500, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04500 to 0.03556, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03556 to 0.02965, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02965 to 0.02466, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02466 to 0.02198, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02198 to 0.01904, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01904 to 0.01707, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01707 to 0.01545, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01545 to 0.01416, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01416 to 0.01323, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01323 to 0.01222, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01222 to 0.01126, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01126 to 0.01067, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01067 to 0.01005, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01005 to 0.00953, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00953 to 0.00910, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00910 to 0.00857, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00857 to 0.00818, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00818 to 0.00788, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00788 to 0.00757, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00757 to 0.00711, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00711 to 0.00692, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00692 to 0.00655, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00655 to 0.00631, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00631 to 0.00609, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00609 to 0.00591, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00591 to 0.00572, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00572 to 0.00557, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00557 to 0.00538, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00538 to 0.00527, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00527 to 0.00525, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00525 to 0.00503, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00503 to 0.00498, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00498 to 0.00496, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00496 to 0.00487, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00487 to 0.00481, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00481 to 0.00468, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00468 to 0.00462, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00462 to 0.00457, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00457 to 0.00451, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00451 to 0.00446, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00446 to 0.00443, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00443 to 0.00436, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 47: loss improved from 0.00436 to 0.00433, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00433\n",
      "\n",
      "Epoch 49: loss improved from 0.00433 to 0.00426, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00426 to 0.00416, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.00416 to 0.00415, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.00415 to 0.00405, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00405\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00405\n",
      "\n",
      "Epoch 55: loss improved from 0.00405 to 0.00394, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00394\n",
      "\n",
      "Epoch 57: loss improved from 0.00394 to 0.00393, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 60: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 62: loss improved from 0.00393 to 0.00388, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00388 to 0.00384, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 65: loss improved from 0.00384 to 0.00381, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 66: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 67: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 68: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 69: loss improved from 0.00381 to 0.00378, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 70: loss improved from 0.00378 to 0.00376, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 71: loss improved from 0.00376 to 0.00375, saving model to ../result\\lstm_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 72: loss did not improve from 0.00375\n",
      "\n",
      "Epoch 73: loss did not improve from 0.00375\n",
      "\n",
      "Epoch 74: loss did not improve from 0.00375\n",
      "\n",
      "Epoch 75: loss did not improve from 0.00375\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00375\n",
      "Epoch 76: early stopping\n",
      "11th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12401, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12401 to 0.09816, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.09816 to 0.05573, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.05573 to 0.04114, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04114 to 0.03659, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03659 to 0.03418, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03418 to 0.03178, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03178 to 0.03024, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03024 to 0.02840, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02840 to 0.02494, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02494 to 0.02229, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02229 to 0.01970, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01970 to 0.01732, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01732 to 0.01601, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01601 to 0.01502, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01502 to 0.01423, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01423 to 0.01360, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01360 to 0.01303, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01303 to 0.01248, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01248 to 0.01182, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01182 to 0.01109, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01109 to 0.00996, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00996 to 0.00923, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00923 to 0.00889, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00889 to 0.00853, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00853 to 0.00828, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00828 to 0.00795, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00795 to 0.00772, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00772 to 0.00758, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00758 to 0.00735, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00735 to 0.00709, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00709 to 0.00694, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00694 to 0.00680, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00680 to 0.00661, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00661 to 0.00647, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00647 to 0.00637, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00637 to 0.00625, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00625 to 0.00612, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00612 to 0.00605, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00605 to 0.00590, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00590 to 0.00584, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00584 to 0.00567, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00567 to 0.00564, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00564 to 0.00542, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00542 to 0.00539, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00539 to 0.00529, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00529 to 0.00526, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00526 to 0.00518, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00518 to 0.00509, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00509\n",
      "\n",
      "Epoch 51: loss improved from 0.00509 to 0.00502, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00502\n",
      "\n",
      "Epoch 53: loss improved from 0.00502 to 0.00497, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00497\n",
      "\n",
      "Epoch 55: loss improved from 0.00497 to 0.00477, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00477 to 0.00471, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00471 to 0.00465, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.00465 to 0.00457, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss improved from 0.00457 to 0.00452, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss improved from 0.00452 to 0.00450, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00450\n",
      "\n",
      "Epoch 62: loss improved from 0.00450 to 0.00446, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00446 to 0.00437, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 65: loss improved from 0.00437 to 0.00431, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 66: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 67: loss improved from 0.00431 to 0.00426, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 68: loss improved from 0.00426 to 0.00419, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 69: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 70: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 71: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 72: loss improved from 0.00419 to 0.00409, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss did not improve from 0.00409\n",
      "\n",
      "Epoch 74: loss improved from 0.00409 to 0.00408, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss improved from 0.00408 to 0.00402, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 77: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 78: loss improved from 0.00402 to 0.00398, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 79: loss improved from 0.00398 to 0.00396, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 80: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 81: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 82: loss improved from 0.00396 to 0.00395, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 83: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 84: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 85: loss improved from 0.00395 to 0.00394, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 86: loss improved from 0.00394 to 0.00388, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 87: loss did not improve from 0.00388\n",
      "\n",
      "Epoch 88: loss improved from 0.00388 to 0.00386, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 89: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 90: loss did not improve from 0.00386\n",
      "\n",
      "Epoch 91: loss improved from 0.00386 to 0.00385, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 92: loss improved from 0.00385 to 0.00383, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 93: loss improved from 0.00383 to 0.00383, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 94: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 95: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 96: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 97: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 98: loss improved from 0.00383 to 0.00378, saving model to ../result\\lstm_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 99: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 100: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 101: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 102: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 103: loss did not improve from 0.00378\n",
      "Epoch 103: early stopping\n",
      "12th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11659, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11659 to 0.08219, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.08219 to 0.04343, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04343 to 0.03691, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03691 to 0.03365, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.03365\n",
      "\n",
      "Epoch 7: loss improved from 0.03365 to 0.03021, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03021 to 0.02989, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02989 to 0.02913, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02913 to 0.02828, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02828 to 0.02736, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02736 to 0.02631, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02631 to 0.02503, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02503 to 0.02296, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02296 to 0.01939, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01939 to 0.01621, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01621 to 0.01503, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01503 to 0.01402, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01402 to 0.01290, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01290 to 0.01168, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01168 to 0.01099, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01099 to 0.01035, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01035 to 0.01002, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01002 to 0.00961, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00961 to 0.00925, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00925 to 0.00895, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00895 to 0.00865, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00865 to 0.00841, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00841 to 0.00816, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00816 to 0.00793, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00793 to 0.00773, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00773 to 0.00760, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00760 to 0.00738, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00738 to 0.00723, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00723 to 0.00706, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00706 to 0.00696, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00696 to 0.00689, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00689 to 0.00661, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00661 to 0.00654, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00654 to 0.00637, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00637 to 0.00626, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00626 to 0.00614, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00614 to 0.00605, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00605 to 0.00591, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00591 to 0.00585, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00585 to 0.00576, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00576 to 0.00561, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00561\n",
      "\n",
      "Epoch 49: loss improved from 0.00561 to 0.00553, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00553\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00553\n",
      "\n",
      "Epoch 52: loss improved from 0.00553 to 0.00532, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.00532 to 0.00526, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.00526 to 0.00516, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00516 to 0.00511, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00511 to 0.00503, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00503 to 0.00498, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00498\n",
      "\n",
      "Epoch 59: loss improved from 0.00498 to 0.00490, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss improved from 0.00490 to 0.00485, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss improved from 0.00485 to 0.00481, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 62: loss improved from 0.00481 to 0.00480, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00480 to 0.00471, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss did not improve from 0.00471\n",
      "\n",
      "Epoch 65: loss improved from 0.00471 to 0.00466, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 66: loss did not improve from 0.00466\n",
      "\n",
      "Epoch 67: loss improved from 0.00466 to 0.00455, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 68: loss improved from 0.00455 to 0.00454, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 69: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 70: loss improved from 0.00454 to 0.00450, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 71: loss improved from 0.00450 to 0.00450, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 72: loss improved from 0.00450 to 0.00443, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss improved from 0.00443 to 0.00439, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 74: loss improved from 0.00439 to 0.00438, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss improved from 0.00438 to 0.00433, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 76: loss improved from 0.00433 to 0.00431, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 77: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 78: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 79: loss improved from 0.00431 to 0.00430, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 80: loss improved from 0.00430 to 0.00429, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 81: loss improved from 0.00429 to 0.00422, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 82: loss did not improve from 0.00422\n",
      "\n",
      "Epoch 83: loss improved from 0.00422 to 0.00420, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 84: loss improved from 0.00420 to 0.00413, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 85: loss improved from 0.00413 to 0.00412, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 86: loss did not improve from 0.00412\n",
      "\n",
      "Epoch 87: loss improved from 0.00412 to 0.00409, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 88: loss improved from 0.00409 to 0.00406, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 89: loss improved from 0.00406 to 0.00406, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 90: loss improved from 0.00406 to 0.00402, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 91: loss improved from 0.00402 to 0.00399, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 92: loss improved from 0.00399 to 0.00398, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 93: loss did not improve from 0.00398\n",
      "\n",
      "Epoch 94: loss did not improve from 0.00398\n",
      "\n",
      "Epoch 95: loss improved from 0.00398 to 0.00396, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 96: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 97: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 98: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 99: loss improved from 0.00396 to 0.00391, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 100: loss did not improve from 0.00391\n",
      "\n",
      "Epoch 101: loss did not improve from 0.00391\n",
      "\n",
      "Epoch 102: loss improved from 0.00391 to 0.00390, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 103: loss did not improve from 0.00390\n",
      "\n",
      "Epoch 104: loss improved from 0.00390 to 0.00384, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 105: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 106: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 107: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 108: loss improved from 0.00384 to 0.00380, saving model to ../result\\lstm_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 109: loss did not improve from 0.00380\n",
      "\n",
      "Epoch 110: loss did not improve from 0.00380\n",
      "\n",
      "Epoch 111: loss did not improve from 0.00380\n",
      "\n",
      "Epoch 112: loss did not improve from 0.00380\n",
      "\n",
      "Epoch 113: loss did not improve from 0.00380\n",
      "Epoch 113: early stopping\n",
      "13th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13586, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13586 to 0.12156, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.12156 to 0.10700, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.10700 to 0.08761, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.08761 to 0.05932, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.05932 to 0.04333, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04333 to 0.03888, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03888 to 0.03583, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03583 to 0.03177, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03177 to 0.02662, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02662 to 0.02438, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02438 to 0.02267, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02267 to 0.02093, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02093 to 0.01949, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01949 to 0.01809, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01809 to 0.01647, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01647 to 0.01533, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01533 to 0.01428, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01428 to 0.01345, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01345 to 0.01259, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01259 to 0.01196, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01196 to 0.01138, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01138 to 0.01093, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01093 to 0.01046, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01046 to 0.01005, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01005 to 0.00970, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00970 to 0.00929, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00929 to 0.00903, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00903 to 0.00866, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00866 to 0.00845, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00845 to 0.00816, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00816 to 0.00801, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00801 to 0.00776, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00776 to 0.00748, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00748 to 0.00733, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00733 to 0.00714, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00714 to 0.00693, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00693 to 0.00680, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00680 to 0.00662, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00662 to 0.00645, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00645 to 0.00636, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00636 to 0.00620, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00620 to 0.00605, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00605 to 0.00597, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00597 to 0.00576, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00576 to 0.00566, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00566 to 0.00565, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00565 to 0.00543, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00543 to 0.00526, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00526 to 0.00518, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.00518 to 0.00506, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.00506 to 0.00502, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00502\n",
      "\n",
      "Epoch 54: loss improved from 0.00502 to 0.00495, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.00495 to 0.00473, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00473 to 0.00472, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00472 to 0.00470, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.00470 to 0.00459, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss improved from 0.00459 to 0.00452, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss improved from 0.00452 to 0.00452, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00452\n",
      "\n",
      "Epoch 62: loss improved from 0.00452 to 0.00442, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.00442 to 0.00435, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss improved from 0.00435 to 0.00431, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 65: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 66: loss improved from 0.00431 to 0.00426, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 67: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 68: loss improved from 0.00426 to 0.00420, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 69: loss improved from 0.00420 to 0.00416, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 70: loss did not improve from 0.00416\n",
      "\n",
      "Epoch 71: loss improved from 0.00416 to 0.00412, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 72: loss improved from 0.00412 to 0.00407, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss did not improve from 0.00407\n",
      "\n",
      "Epoch 74: loss improved from 0.00407 to 0.00406, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 76: loss improved from 0.00406 to 0.00404, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 77: loss improved from 0.00404 to 0.00401, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 78: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 79: loss improved from 0.00401 to 0.00398, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 80: loss improved from 0.00398 to 0.00392, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 81: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 82: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 83: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 84: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 85: loss improved from 0.00392 to 0.00389, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 86: loss improved from 0.00389 to 0.00387, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 87: loss improved from 0.00387 to 0.00383, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 88: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 89: loss improved from 0.00383 to 0.00381, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 90: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 91: loss did not improve from 0.00381\n",
      "\n",
      "Epoch 92: loss improved from 0.00381 to 0.00380, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 93: loss improved from 0.00380 to 0.00378, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 94: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 95: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 96: loss improved from 0.00378 to 0.00376, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 97: loss did not improve from 0.00376\n",
      "\n",
      "Epoch 98: loss improved from 0.00376 to 0.00375, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 99: loss improved from 0.00375 to 0.00373, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 100: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 101: loss improved from 0.00373 to 0.00372, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 102: loss did not improve from 0.00372\n",
      "\n",
      "Epoch 103: loss improved from 0.00372 to 0.00371, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 104: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 105: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 106: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 107: loss did not improve from 0.00371\n",
      "\n",
      "Epoch 108: loss improved from 0.00371 to 0.00369, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 109: loss did not improve from 0.00369\n",
      "\n",
      "Epoch 110: loss did not improve from 0.00369\n",
      "\n",
      "Epoch 111: loss improved from 0.00369 to 0.00366, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 112: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 113: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 114: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 115: loss improved from 0.00366 to 0.00366, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 116: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 117: loss did not improve from 0.00366\n",
      "\n",
      "Epoch 118: loss improved from 0.00366 to 0.00364, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 119: loss did not improve from 0.00364\n",
      "\n",
      "Epoch 120: loss did not improve from 0.00364\n",
      "\n",
      "Epoch 121: loss did not improve from 0.00364\n",
      "\n",
      "Epoch 122: loss did not improve from 0.00364\n",
      "\n",
      "Epoch 123: loss improved from 0.00364 to 0.00363, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 124: loss improved from 0.00363 to 0.00361, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 125: loss improved from 0.00361 to 0.00361, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 126: loss did not improve from 0.00361\n",
      "\n",
      "Epoch 127: loss improved from 0.00361 to 0.00360, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 128: loss did not improve from 0.00360\n",
      "\n",
      "Epoch 129: loss did not improve from 0.00360\n",
      "\n",
      "Epoch 130: loss did not improve from 0.00360\n",
      "\n",
      "Epoch 131: loss improved from 0.00360 to 0.00358, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 132: loss did not improve from 0.00358\n",
      "\n",
      "Epoch 133: loss did not improve from 0.00358\n",
      "\n",
      "Epoch 134: loss did not improve from 0.00358\n",
      "\n",
      "Epoch 135: loss improved from 0.00358 to 0.00358, saving model to ../result\\lstm_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 136: loss did not improve from 0.00358\n",
      "\n",
      "Epoch 137: loss did not improve from 0.00358\n",
      "\n",
      "Epoch 138: loss did not improve from 0.00358\n",
      "\n",
      "Epoch 139: loss did not improve from 0.00358\n",
      "\n",
      "Epoch 140: loss did not improve from 0.00358\n",
      "Epoch 140: early stopping\n",
      "14th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12826, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12826 to 0.11424, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.11424 to 0.09926, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.09926 to 0.08101, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.08101 to 0.06022, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.06022 to 0.04808, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04808 to 0.04237, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.04237 to 0.03864, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03864 to 0.03432, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03432 to 0.02962, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02962 to 0.02769, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02769 to 0.02591, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02591 to 0.02432, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02432 to 0.02358, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02358 to 0.02203, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02203 to 0.02098, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02098 to 0.01999, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01999 to 0.01914, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01914 to 0.01847, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01847 to 0.01783, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01783 to 0.01716, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01716 to 0.01655, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01655 to 0.01548, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01548 to 0.01487, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01487 to 0.01413, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01413 to 0.01367, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01367 to 0.01304, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01304 to 0.01257, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01257 to 0.01210, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01210 to 0.01172, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.01172 to 0.01133, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01133 to 0.01101, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01101 to 0.01068, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.01068 to 0.01039, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.01039 to 0.01009, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.01009 to 0.00985, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00985 to 0.00959, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00959 to 0.00941, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00941 to 0.00911, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00911 to 0.00899, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00899 to 0.00881, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00881 to 0.00859, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00859 to 0.00836, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00836 to 0.00826, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00826 to 0.00810, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00810 to 0.00785, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00785 to 0.00776, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00776 to 0.00763, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.00763 to 0.00749, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00749 to 0.00733, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.00733 to 0.00727, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.00727 to 0.00726, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.00726 to 0.00704, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00704\n",
      "\n",
      "Epoch 55: loss improved from 0.00704 to 0.00681, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.00681 to 0.00674, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.00674 to 0.00662, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.00662 to 0.00649, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00649\n",
      "\n",
      "Epoch 60: loss improved from 0.00649 to 0.00628, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss improved from 0.00628 to 0.00619, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 62: loss improved from 0.00619 to 0.00615, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss did not improve from 0.00615\n",
      "\n",
      "Epoch 64: loss improved from 0.00615 to 0.00601, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 65: loss improved from 0.00601 to 0.00596, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 66: loss improved from 0.00596 to 0.00591, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 67: loss improved from 0.00591 to 0.00578, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 68: loss improved from 0.00578 to 0.00572, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 69: loss improved from 0.00572 to 0.00565, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 70: loss improved from 0.00565 to 0.00555, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 71: loss improved from 0.00555 to 0.00549, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 72: loss improved from 0.00549 to 0.00543, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss improved from 0.00543 to 0.00537, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 74: loss improved from 0.00537 to 0.00533, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss did not improve from 0.00533\n",
      "\n",
      "Epoch 76: loss did not improve from 0.00533\n",
      "\n",
      "Epoch 77: loss improved from 0.00533 to 0.00521, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 78: loss improved from 0.00521 to 0.00513, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 79: loss improved from 0.00513 to 0.00506, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 80: loss improved from 0.00506 to 0.00504, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 81: loss improved from 0.00504 to 0.00500, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 82: loss improved from 0.00500 to 0.00491, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 83: loss did not improve from 0.00491\n",
      "\n",
      "Epoch 84: loss did not improve from 0.00491\n",
      "\n",
      "Epoch 85: loss improved from 0.00491 to 0.00480, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 86: loss improved from 0.00480 to 0.00475, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 87: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 88: loss improved from 0.00475 to 0.00474, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 89: loss improved from 0.00474 to 0.00473, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 90: loss did not improve from 0.00473\n",
      "\n",
      "Epoch 91: loss did not improve from 0.00473\n",
      "\n",
      "Epoch 92: loss improved from 0.00473 to 0.00463, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 93: loss improved from 0.00463 to 0.00459, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 94: loss improved from 0.00459 to 0.00454, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 95: loss improved from 0.00454 to 0.00448, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 96: loss did not improve from 0.00448\n",
      "\n",
      "Epoch 97: loss improved from 0.00448 to 0.00442, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 98: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 99: loss improved from 0.00442 to 0.00438, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 100: loss improved from 0.00438 to 0.00434, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 101: loss did not improve from 0.00434\n",
      "\n",
      "Epoch 102: loss improved from 0.00434 to 0.00433, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 103: loss did not improve from 0.00433\n",
      "\n",
      "Epoch 104: loss improved from 0.00433 to 0.00426, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 105: loss improved from 0.00426 to 0.00423, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 106: loss improved from 0.00423 to 0.00420, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 107: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 108: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 109: loss improved from 0.00420 to 0.00418, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 110: loss improved from 0.00418 to 0.00415, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 111: loss improved from 0.00415 to 0.00412, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 112: loss improved from 0.00412 to 0.00410, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 113: loss did not improve from 0.00410\n",
      "\n",
      "Epoch 114: loss improved from 0.00410 to 0.00408, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 115: loss improved from 0.00408 to 0.00404, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 116: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 117: loss improved from 0.00404 to 0.00402, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 118: loss improved from 0.00402 to 0.00399, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 119: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 120: loss did not improve from 0.00399\n",
      "\n",
      "Epoch 121: loss improved from 0.00399 to 0.00396, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 122: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 123: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 124: loss improved from 0.00396 to 0.00395, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 125: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 126: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 127: loss improved from 0.00395 to 0.00395, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 128: loss improved from 0.00395 to 0.00387, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 129: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 130: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 131: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 132: loss improved from 0.00387 to 0.00387, saving model to ../result\\lstm_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 133: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 134: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 135: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 136: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 137: loss did not improve from 0.00387\n",
      "Epoch 137: early stopping\n",
      "15th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13911, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13911 to 0.12583, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.12583 to 0.11283, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.11283 to 0.09645, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.09645 to 0.07275, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.07275 to 0.04967, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04967 to 0.04327, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.04327 to 0.04002, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.04002 to 0.03796, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03796 to 0.03645, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03645 to 0.03515, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03515 to 0.03357, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.03357\n",
      "\n",
      "Epoch 14: loss improved from 0.03357 to 0.03241, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.03241 to 0.03207, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.03207 to 0.03163, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03163 to 0.03118, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.03118 to 0.03071, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.03071 to 0.03023, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.03023 to 0.02974, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02974 to 0.02922, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02922 to 0.02864, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02864 to 0.02792, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02792 to 0.02678, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.02678 to 0.02481, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02481 to 0.02306, saving model to ../result\\lstm_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02306\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02306\n",
      "\n",
      "Epoch 29: loss did not improve from 0.02306\n",
      "\n",
      "Epoch 30: loss did not improve from 0.02306\n",
      "\n",
      "Epoch 31: loss did not improve from 0.02306\n",
      "Epoch 31: early stopping\n",
      "16th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13201, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13201 to 0.11640, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.11640 to 0.09817, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.09817 to 0.07459, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.07459 to 0.04947, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04947 to 0.04252, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04252 to 0.03926, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03926 to 0.03679, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.03679\n",
      "\n",
      "Epoch 10: loss improved from 0.03679 to 0.03290, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.03290\n",
      "\n",
      "Epoch 12: loss improved from 0.03290 to 0.03269, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.03269\n",
      "\n",
      "Epoch 14: loss did not improve from 0.03269\n",
      "\n",
      "Epoch 15: loss improved from 0.03269 to 0.03234, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.03234 to 0.03189, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03189 to 0.03143, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.03143 to 0.03098, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.03098 to 0.03051, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.03051 to 0.03005, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.03005 to 0.02960, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02960 to 0.02912, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02912 to 0.02863, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02863 to 0.02810, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.02810 to 0.02750, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02750 to 0.02680, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.02680 to 0.02583, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.02583 to 0.02441, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.02441 to 0.02285, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.02285 to 0.02152, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.02152 to 0.01972, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01972 to 0.01877, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01877 to 0.01812, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.01812 to 0.01760, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.01760 to 0.01715, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.01715 to 0.01709, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.01709 to 0.01657, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.01657 to 0.01642, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.01642 to 0.01585, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.01585 to 0.01560, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.01560 to 0.01518, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.01518 to 0.01490, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.01490 to 0.01470, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.01470 to 0.01439, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.01439 to 0.01415, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.01415 to 0.01394, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.01394 to 0.01372, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.01372 to 0.01353, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.01353 to 0.01333, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.01333 to 0.01312, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.01312 to 0.01309, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.01309 to 0.01284, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.01284 to 0.01262, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.01262 to 0.01248, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.01248 to 0.01232, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.01232 to 0.01218, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.01218 to 0.01210, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.01210 to 0.01185, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss improved from 0.01185 to 0.01181, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 60: loss improved from 0.01181 to 0.01165, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss improved from 0.01165 to 0.01143, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 62: loss improved from 0.01143 to 0.01125, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 63: loss improved from 0.01125 to 0.01105, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 64: loss improved from 0.01105 to 0.01059, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 65: loss improved from 0.01059 to 0.00959, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 66: loss improved from 0.00959 to 0.00941, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 67: loss improved from 0.00941 to 0.00901, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 68: loss improved from 0.00901 to 0.00891, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 69: loss improved from 0.00891 to 0.00858, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 70: loss improved from 0.00858 to 0.00841, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 71: loss improved from 0.00841 to 0.00819, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 72: loss improved from 0.00819 to 0.00803, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 73: loss improved from 0.00803 to 0.00784, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 74: loss improved from 0.00784 to 0.00772, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 75: loss improved from 0.00772 to 0.00761, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 76: loss improved from 0.00761 to 0.00745, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 77: loss improved from 0.00745 to 0.00733, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 78: loss improved from 0.00733 to 0.00726, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 79: loss improved from 0.00726 to 0.00718, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 80: loss improved from 0.00718 to 0.00708, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 81: loss improved from 0.00708 to 0.00687, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 82: loss improved from 0.00687 to 0.00678, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 83: loss improved from 0.00678 to 0.00672, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 84: loss improved from 0.00672 to 0.00661, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 85: loss improved from 0.00661 to 0.00650, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 86: loss improved from 0.00650 to 0.00641, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 87: loss improved from 0.00641 to 0.00638, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 88: loss improved from 0.00638 to 0.00633, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 89: loss improved from 0.00633 to 0.00614, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 90: loss did not improve from 0.00614\n",
      "\n",
      "Epoch 91: loss did not improve from 0.00614\n",
      "\n",
      "Epoch 92: loss improved from 0.00614 to 0.00603, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 93: loss improved from 0.00603 to 0.00592, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 94: loss improved from 0.00592 to 0.00584, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 95: loss improved from 0.00584 to 0.00577, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 96: loss improved from 0.00577 to 0.00567, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 97: loss improved from 0.00567 to 0.00565, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 98: loss improved from 0.00565 to 0.00554, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 99: loss improved from 0.00554 to 0.00553, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 100: loss improved from 0.00553 to 0.00545, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 101: loss improved from 0.00545 to 0.00538, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 102: loss improved from 0.00538 to 0.00526, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 103: loss did not improve from 0.00526\n",
      "\n",
      "Epoch 104: loss did not improve from 0.00526\n",
      "\n",
      "Epoch 105: loss improved from 0.00526 to 0.00519, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 106: loss improved from 0.00519 to 0.00514, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 107: loss improved from 0.00514 to 0.00509, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 108: loss improved from 0.00509 to 0.00500, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 109: loss improved from 0.00500 to 0.00496, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 110: loss did not improve from 0.00496\n",
      "\n",
      "Epoch 111: loss improved from 0.00496 to 0.00486, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 112: loss improved from 0.00486 to 0.00483, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 113: loss improved from 0.00483 to 0.00477, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 114: loss did not improve from 0.00477\n",
      "\n",
      "Epoch 115: loss did not improve from 0.00477\n",
      "\n",
      "Epoch 116: loss did not improve from 0.00477\n",
      "\n",
      "Epoch 117: loss did not improve from 0.00477\n",
      "\n",
      "Epoch 118: loss improved from 0.00477 to 0.00465, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 119: loss did not improve from 0.00465\n",
      "\n",
      "Epoch 120: loss did not improve from 0.00465\n",
      "\n",
      "Epoch 121: loss did not improve from 0.00465\n",
      "\n",
      "Epoch 122: loss did not improve from 0.00465\n",
      "\n",
      "Epoch 123: loss improved from 0.00465 to 0.00457, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 124: loss improved from 0.00457 to 0.00455, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 125: loss improved from 0.00455 to 0.00450, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 126: loss improved from 0.00450 to 0.00447, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 127: loss improved from 0.00447 to 0.00441, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 128: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 129: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 130: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 131: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 132: loss improved from 0.00441 to 0.00437, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 133: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 134: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 135: loss improved from 0.00437 to 0.00432, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 136: loss improved from 0.00432 to 0.00427, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 137: loss did not improve from 0.00427\n",
      "\n",
      "Epoch 138: loss improved from 0.00427 to 0.00426, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 139: loss improved from 0.00426 to 0.00422, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 140: loss did not improve from 0.00422\n",
      "\n",
      "Epoch 141: loss did not improve from 0.00422\n",
      "\n",
      "Epoch 142: loss improved from 0.00422 to 0.00420, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 143: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 144: loss improved from 0.00420 to 0.00414, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 145: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 146: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 147: loss improved from 0.00414 to 0.00411, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 148: loss did not improve from 0.00411\n",
      "\n",
      "Epoch 149: loss did not improve from 0.00411\n",
      "\n",
      "Epoch 150: loss did not improve from 0.00411\n",
      "\n",
      "Epoch 151: loss improved from 0.00411 to 0.00408, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 152: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 153: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 154: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 155: loss improved from 0.00408 to 0.00405, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 156: loss did not improve from 0.00405\n",
      "\n",
      "Epoch 157: loss improved from 0.00405 to 0.00403, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 158: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 159: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 160: loss improved from 0.00403 to 0.00401, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 161: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 162: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 163: loss improved from 0.00401 to 0.00398, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 164: loss did not improve from 0.00398\n",
      "\n",
      "Epoch 165: loss improved from 0.00398 to 0.00396, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 166: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 167: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 168: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 169: loss improved from 0.00396 to 0.00395, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 170: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 171: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 172: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 173: loss improved from 0.00395 to 0.00394, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 174: loss did not improve from 0.00394\n",
      "\n",
      "Epoch 175: loss improved from 0.00394 to 0.00393, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 176: loss improved from 0.00393 to 0.00393, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 177: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 178: loss improved from 0.00393 to 0.00393, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 179: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 180: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 181: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 182: loss improved from 0.00393 to 0.00392, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 183: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 184: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 185: loss improved from 0.00392 to 0.00388, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 186: loss did not improve from 0.00388\n",
      "\n",
      "Epoch 187: loss did not improve from 0.00388\n",
      "\n",
      "Epoch 188: loss did not improve from 0.00388\n",
      "\n",
      "Epoch 189: loss improved from 0.00388 to 0.00385, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 190: loss did not improve from 0.00385\n",
      "\n",
      "Epoch 191: loss improved from 0.00385 to 0.00384, saving model to ../result\\lstm_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 192: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 193: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 194: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 195: loss did not improve from 0.00384\n",
      "\n",
      "Epoch 196: loss did not improve from 0.00384\n",
      "Epoch 196: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO: [units, batch_size, dropout, look_back, is_ema]\n",
    "config = [[[64]], [1, 2, 4, 8], [0.2],[10,12,15,17], [True]] \n",
    "df = read_data('../temp_data/influA_vietnam_last_10_days.csv', num_features=2)\n",
    "hist = LSTM_HyperParameter_Tuning(config, df, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>units</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>dropout</th>\n",
       "      <th>look_back</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[64]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.0035680029541254044, 0.05973276123404503]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.0035725662019103765, 0.05977094918489456]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.0035865954123437405, 0.059888191521167755]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.003640269860625267, 0.06033464893698692]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0036754074972122908, 0.060625139623880386]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.0036852953489869833, 0.06070663034915924]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0037550595588982105, 0.06127854064106941]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.003757554106414318, 0.06129889190196991]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.0037691318430006504, 0.06139325723052025]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[64]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.003817929420620203, 0.06178940087556839]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>[0.003818080062046647, 0.06179061532020569]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[64]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12</td>\n",
       "      <td>[0.0038816460873931646, 0.062302857637405396]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[64]</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.0038933949545025826, 0.062397073954343796]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[64]</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.003949396777898073, 0.06284422427415848]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[64]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>17</td>\n",
       "      <td>[0.003987519536167383, 0.06314680725336075]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[64]</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>15</td>\n",
       "      <td>[0.024687960743904114, 0.15712404251098633]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   units  batch_size  dropout  look_back  \\\n",
       "12  [64]           8      0.2         10   \n",
       "8   [64]           4      0.2         10   \n",
       "4   [64]           2      0.2         10   \n",
       "1   [64]           1      0.2         12   \n",
       "5   [64]           2      0.2         12   \n",
       "2   [64]           1      0.2         15   \n",
       "9   [64]           4      0.2         12   \n",
       "10  [64]           4      0.2         15   \n",
       "6   [64]           2      0.2         15   \n",
       "15  [64]           8      0.2         17   \n",
       "0   [64]           1      0.2         10   \n",
       "13  [64]           8      0.2         12   \n",
       "11  [64]           4      0.2         17   \n",
       "7   [64]           2      0.2         17   \n",
       "3   [64]           1      0.2         17   \n",
       "14  [64]           8      0.2         15   \n",
       "\n",
       "                                       train_loss  \n",
       "12   [0.0035680029541254044, 0.05973276123404503]  \n",
       "8    [0.0035725662019103765, 0.05977094918489456]  \n",
       "4   [0.0035865954123437405, 0.059888191521167755]  \n",
       "1     [0.003640269860625267, 0.06033464893698692]  \n",
       "5   [0.0036754074972122908, 0.060625139623880386]  \n",
       "2    [0.0036852953489869833, 0.06070663034915924]  \n",
       "9    [0.0037550595588982105, 0.06127854064106941]  \n",
       "10    [0.003757554106414318, 0.06129889190196991]  \n",
       "6    [0.0037691318430006504, 0.06139325723052025]  \n",
       "15    [0.003817929420620203, 0.06178940087556839]  \n",
       "0     [0.003818080062046647, 0.06179061532020569]  \n",
       "13  [0.0038816460873931646, 0.062302857637405396]  \n",
       "11  [0.0038933949545025826, 0.062397073954343796]  \n",
       "7     [0.003949396777898073, 0.06284422427415848]  \n",
       "3     [0.003987519536167383, 0.06314680725336075]  \n",
       "14    [0.024687960743904114, 0.15712404251098633]  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# hist = pd.DataFrame(hist)\n",
    "# hist = hist.sort_values(by=[4], ascending=True)\n",
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def inverse_transform(data, scaler):\n",
    "#     flattened_data = data.flatten()\n",
    "#     inverse_flattened_data = scaler.inverse_transform(flattened_data.reshape(-1,1))\n",
    "#     return inverse_flattened_data.reshape(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# model = load_model(r\"D:\\my_study\\gr3\\DATN\\result\\lstm_ema\\10\\best_lstm_m2m_model.keras\")\n",
    "# df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=2)\n",
    "# trainX, trainY, testX, testY = prepare_data(df, 15, scaler, is_ema=True)\n",
    "# testY_hat = forecast(testX, model)\n",
    "# y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "# y_inverse = inverse_transform(testY, scaler)\n",
    "# print(y_inverse, y_hat_inverse)\n",
    "\n",
    "# save_plot(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten(), 'abc.png')\n",
    "# model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hist.iloc[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# testY_hat = forecast(testX, model)\n",
    "# y_hat_inverse = np.expand_dims(scaler.inverse_transform(testY_hat[0]), axis=0)\n",
    "# y_inverse = np.expand_dims(scaler.inverse_transform(testY[0]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# testY_hat = forecast(testX, model)\n",
    "# y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "# y_inverse = inverse_transform(testY, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot(y_inverse, y_hat_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = read_data('../temp_data/influA_vietnam_last_10_days.csv')\n",
    "# trainX, trainY, testX, testY = prepare_data(df, hist.iloc[0][3], scaler=None, is_ema=True)\n",
    "# testY"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
