{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "scaler = MinMaxScaler()\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN, LSTM, TimeDistributed, Input, Dropout, GRU\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from keras.saving import register_keras_serializable\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0, len(dataset)-2 *look_back+1, look_back):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back: i+ 2*look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def exponential_moving_average(data, span):\n",
    "    return data.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def read_data(file_path, num_features = 1):\n",
    "    from pandas import read_csv\n",
    "    series_influ_A_df = read_csv(file_path, index_col=0, engine='python')\n",
    "    series_influ_A_df = series_influ_A_df.rename(columns= {\"Influenza A - All types of surveillance\": \"case\"})\n",
    "    series_influ_A_df = series_influ_A_df[[\"case\", \"humidity\", \"temp\", \"dew\",\"windspeed\", \"tempmax\",][:num_features]]\n",
    "    return series_influ_A_df.dropna()\n",
    "\n",
    "def prepare_data(series, look_back, scaler, is_ema = False):\n",
    "    if is_ema:\n",
    "        span = 52  # Bạn có thể điều chỉnh độ dài span tùy ý\n",
    "        series['case'] = exponential_moving_average(series['case'], span)\n",
    "    series = series.astype('float32')\n",
    "    series = series.values\n",
    "    if scaler is not None:\n",
    "        flattened_dataset = series.flatten()\n",
    "        dataset = scaler.fit_transform(flattened_dataset.reshape(-1,1))\n",
    "        dataset = dataset.reshape(series.shape)\n",
    "\n",
    "    else: \n",
    "        dataset = series\n",
    "\n",
    "    rest = len(dataset) % look_back\n",
    "    dataset = dataset[rest:, :]\n",
    "    trainsize = len(dataset) - look_back\n",
    "    train = dataset[:trainsize, :]\n",
    "    test = dataset[trainsize - look_back:, :]\n",
    "\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "def forecast(input, model):\n",
    "    predicted = model.predict(input, verbose=0)\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def save_plot(x,y, file_path):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy import stats\n",
    "\n",
    "    # Generate some sample data\n",
    "    # x = y_inverse.flatten()\n",
    "    # y = y_hat_inverse.flatten()\n",
    "\n",
    "    # Compute the linear regression line\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    # Create the R-squared line\n",
    "    r2_line = slope * x + intercept\n",
    "    r2 = r2_score(x, y)\n",
    "    r2_pearson = r_value**2\n",
    "    squared_error = np.square(x-y)\n",
    "\n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(x, y, label='Data Points')\n",
    "    plt.plot(x, squared_error, color='red', marker=\"o\", label=f'squared Error (R²={r2:.2f})')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('actual number of infection')\n",
    "    plt.ylabel('forecast number of infection')\n",
    "    plt.title('Scatter Plot with R-squared Line')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "\n",
    "def inverse_transform(data, scaler):\n",
    "    flattened_data = data.flatten()\n",
    "    inverse_flattened_data = scaler.inverse_transform(flattened_data.reshape(-1,1))\n",
    "    return inverse_flattened_data.reshape(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class MyLSTM (Sequential):\n",
    "    def __init__(self, look_back, dense_units =[],unit=64, optimizer='adam',name='lstm'):\n",
    "        super().__init__(name=name)\n",
    "        self.look_back = look_back\n",
    "        self.add(Input(shape=(look_back,1)))\n",
    "        self.add(LSTM(units=unit, activation='relu', return_sequences=True))\n",
    "        for unit in dense_units:\n",
    "            self.add(Dense(units=unit, activation='relu'))\n",
    "        self.add(TimeDistributed(Dense(units=5, activation='sigmoid' )))\n",
    "        self.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "\n",
    "def build_model(input_shape, dropout=None, dense_units = [], unit=64, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    #Encoder:\n",
    "    # First LSTM layer with Dropout regularisation\n",
    "    model.add(LSTM(units=dense_units[0], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Second LSTM layer\n",
    "    model.add(LSTM(units=dense_units[1], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Third LSTM layer\n",
    "    model.add(LSTM(units=dense_units[2], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    #Decoder\n",
    "    # Fourth LSTM layer\n",
    "    model.add(LSTM(units=dense_units[2], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(units=dense_units[1], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Fourth LSTM layer\n",
    "    model.add(LSTM(units=dense_units[0], return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # if first_additional_layer:\n",
    "    #     model.add(LSTM(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "\n",
    "    # if second_additional_layer:\n",
    "    #     model.add(LSTM(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "\n",
    "    # if third_additional_layer:\n",
    "    #     model.add(GRU(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "    model.add(TimeDistributed(Dense(units=input_shape[1], activation='sigmoid' )))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(testY, forecasts):\n",
    "    import matplotlib.pyplot as plt\n",
    "    forecastsPlot = forecasts[:,:,0].reshape(-1)\n",
    "    testPlot = testY[:,:,0].reshape(-1)\n",
    "    plt.plot(testPlot, \"-y\", label=\"actual\", marker= '.')\n",
    "    plt.plot(forecastsPlot, color = 'green',marker='x', label=\"forecast\")\n",
    "    plt.ylabel(\"Number of infections\")\n",
    "    plt.legend([\"actual\", \"forecast\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os, json\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def LSTM_HyperParameter_Tuning(config, df, scaler):\n",
    "    \n",
    "    num_features, layers, n_neurons, n_batch_sizes, dropouts, look_backs, is_emas = config\n",
    "    possible_combinations = list(itertools.product(num_features, layers, n_neurons, n_batch_sizes, dropouts, look_backs, is_emas))\n",
    "    \n",
    "    print(possible_combinations)\n",
    "    print('\\n')\n",
    "    \n",
    "    hist = []\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "        print(f'{i+1}th combination: \\n')\n",
    "        print('--------------------------------------------------------------------')\n",
    "        num_features, layers, n_neurons, n_batch_size, dropout, look_back, is_ema = possible_combinations[i]\n",
    "\n",
    "        df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=num_features)\n",
    "        \n",
    "        trainX, trainY, testX, testY = prepare_data(df, look_back, scaler, is_ema=is_ema)\n",
    "        model = build_model(\n",
    "            input_shape=(trainX.shape[1], trainX.shape[2]),\n",
    "            # first_additional_layer= layers[0],\n",
    "            # second_additional_layer=layers[1],\n",
    "            # third_additional_layer=layers[2],\n",
    "            dense_units=n_neurons[1:],\n",
    "            unit=n_neurons[0])\n",
    "\n",
    "        es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "        '''''\n",
    "        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n",
    "        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n",
    "        '''''\n",
    "        a = 'ema' if is_ema else 'not_ema'\n",
    "        lstm_dir = os.path.join(\"../result\", f\"\"\"lstm_AE_{a}\"\"\")\n",
    "        lstm_combination_dir = os.path.join(lstm_dir, str(i))\n",
    "        os.makedirs(lstm_combination_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(lstm_combination_dir, 'best_lstm_m2m_model.keras')\n",
    "\n",
    "        mc = ModelCheckpoint(file_path, monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "        '''''\n",
    "        cb = Callback(...)  # First, callbacks must be instantiated.\n",
    "        cb_list = [cb, ...]  # Then, one or more callbacks that you intend to use must be added to a Python list.\n",
    "        model.fit(..., callbacks=cb_list)  # Finally, the list of callbacks is provided to the callback argument when fitting the model.\n",
    "        '''''\n",
    "\n",
    "        model.fit(trainX, trainY,batch_size=n_batch_size, callbacks=[es, mc], verbose=0, epochs=200)\n",
    "        train_accuracy = model.evaluate(trainX, trainY, verbose=0)\n",
    "        # test_accuracy = model.evaluate(testX, testY, verbose=0)\n",
    "        # hist.append(list((n_neurons, n_batch_size, dropout,look_back,\n",
    "        #                   train_accuracy, test_accuracy)))\n",
    "        hist.append(list((n_neurons, n_batch_size, dropout,look_back,\n",
    "                          train_accuracy)))\n",
    "        \n",
    "        \n",
    "        config= {\n",
    "            \"num_features\": num_features,\n",
    "            \"layers\": layers,\n",
    "            \"units\": n_neurons,\n",
    "            \"n_batch_size\": n_batch_size,\n",
    "            \"dropout\": dropout,\n",
    "            \"look_back\": look_back,\n",
    "            \"is_ema\": is_ema\n",
    "        }\n",
    "        with open(os.path.join(lstm_combination_dir,'config.json'), 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "        \n",
    "\n",
    "        # print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy}')\n",
    "        \n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "\n",
    "        num_features, layers, n_neurons, n_batch_size, dropout, look_back, is_ema = possible_combinations[i]\n",
    "        df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=num_features)\n",
    "        trainX, trainY, testX, testY = prepare_data(df, look_back, scaler, is_ema=is_ema)\n",
    "\n",
    "        a = 'ema' if is_ema else 'not_ema'\n",
    "        lstm_dir = os.path.join(\"../result\", f\"\"\"lstm_AE_{a}\"\"\")\n",
    "        lstm_combination_dir = os.path.join(lstm_dir, str(i))\n",
    "        os.makedirs(lstm_combination_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(lstm_combination_dir, 'best_lstm_m2m_model.keras')\n",
    "\n",
    "\n",
    "        model = load_model(file_path)\n",
    "\n",
    "        #TODO: save r square\n",
    "        testY_hat = forecast(testX, model)\n",
    "        y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "        y_inverse = inverse_transform(testY, scaler)\n",
    "\n",
    "        r2_image_path = os.path.join(lstm_combination_dir, 'r2_image.png')\n",
    "        save_plot(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten(), r2_image_path)\n",
    "        \n",
    "    import pandas as pd\n",
    "    hist_df = pd.DataFrame(hist)\n",
    "    hist_df = hist_df.rename(columns={0: 'units', 1: 'batch_size', 2: 'dropout', 3: 'look_back', 4: 'train_loss'})\n",
    "    hist_df = hist_df.sort_values(by=['train_loss'], ascending=True)\n",
    "    hist_df.to_csv(os.path.join(lstm_dir, 'history.csv'))\n",
    "    return hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, [False, True, True], [64, 64, 32, 16], 1, 0.2, 10, False), (1, [False, True, True], [64, 64, 32, 16], 1, 0.2, 12, False), (1, [False, True, True], [64, 64, 32, 16], 1, 0.2, 15, False), (1, [False, True, True], [64, 64, 32, 16], 1, 0.2, 17, False), (1, [False, True, True], [64, 64, 32, 16], 2, 0.2, 10, False), (1, [False, True, True], [64, 64, 32, 16], 2, 0.2, 12, False), (1, [False, True, True], [64, 64, 32, 16], 2, 0.2, 15, False), (1, [False, True, True], [64, 64, 32, 16], 2, 0.2, 17, False), (1, [False, True, True], [64, 64, 32, 16], 4, 0.2, 10, False), (1, [False, True, True], [64, 64, 32, 16], 4, 0.2, 12, False), (1, [False, True, True], [64, 64, 32, 16], 4, 0.2, 15, False), (1, [False, True, True], [64, 64, 32, 16], 4, 0.2, 17, False), (1, [False, True, True], [64, 64, 32, 16], 8, 0.2, 10, False), (1, [False, True, True], [64, 64, 32, 16], 8, 0.2, 12, False), (1, [False, True, True], [64, 64, 32, 16], 8, 0.2, 15, False), (1, [False, True, True], [64, 64, 32, 16], 8, 0.2, 17, False), (1, [False, True, True], [64, 128, 64, 32], 1, 0.2, 10, False), (1, [False, True, True], [64, 128, 64, 32], 1, 0.2, 12, False), (1, [False, True, True], [64, 128, 64, 32], 1, 0.2, 15, False), (1, [False, True, True], [64, 128, 64, 32], 1, 0.2, 17, False), (1, [False, True, True], [64, 128, 64, 32], 2, 0.2, 10, False), (1, [False, True, True], [64, 128, 64, 32], 2, 0.2, 12, False), (1, [False, True, True], [64, 128, 64, 32], 2, 0.2, 15, False), (1, [False, True, True], [64, 128, 64, 32], 2, 0.2, 17, False), (1, [False, True, True], [64, 128, 64, 32], 4, 0.2, 10, False), (1, [False, True, True], [64, 128, 64, 32], 4, 0.2, 12, False), (1, [False, True, True], [64, 128, 64, 32], 4, 0.2, 15, False), (1, [False, True, True], [64, 128, 64, 32], 4, 0.2, 17, False), (1, [False, True, True], [64, 128, 64, 32], 8, 0.2, 10, False), (1, [False, True, True], [64, 128, 64, 32], 8, 0.2, 12, False), (1, [False, True, True], [64, 128, 64, 32], 8, 0.2, 15, False), (1, [False, True, True], [64, 128, 64, 32], 8, 0.2, 17, False), (2, [False, True, True], [64, 64, 32, 16], 1, 0.2, 10, False), (2, [False, True, True], [64, 64, 32, 16], 1, 0.2, 12, False), (2, [False, True, True], [64, 64, 32, 16], 1, 0.2, 15, False), (2, [False, True, True], [64, 64, 32, 16], 1, 0.2, 17, False), (2, [False, True, True], [64, 64, 32, 16], 2, 0.2, 10, False), (2, [False, True, True], [64, 64, 32, 16], 2, 0.2, 12, False), (2, [False, True, True], [64, 64, 32, 16], 2, 0.2, 15, False), (2, [False, True, True], [64, 64, 32, 16], 2, 0.2, 17, False), (2, [False, True, True], [64, 64, 32, 16], 4, 0.2, 10, False), (2, [False, True, True], [64, 64, 32, 16], 4, 0.2, 12, False), (2, [False, True, True], [64, 64, 32, 16], 4, 0.2, 15, False), (2, [False, True, True], [64, 64, 32, 16], 4, 0.2, 17, False), (2, [False, True, True], [64, 64, 32, 16], 8, 0.2, 10, False), (2, [False, True, True], [64, 64, 32, 16], 8, 0.2, 12, False), (2, [False, True, True], [64, 64, 32, 16], 8, 0.2, 15, False), (2, [False, True, True], [64, 64, 32, 16], 8, 0.2, 17, False), (2, [False, True, True], [64, 128, 64, 32], 1, 0.2, 10, False), (2, [False, True, True], [64, 128, 64, 32], 1, 0.2, 12, False), (2, [False, True, True], [64, 128, 64, 32], 1, 0.2, 15, False), (2, [False, True, True], [64, 128, 64, 32], 1, 0.2, 17, False), (2, [False, True, True], [64, 128, 64, 32], 2, 0.2, 10, False), (2, [False, True, True], [64, 128, 64, 32], 2, 0.2, 12, False), (2, [False, True, True], [64, 128, 64, 32], 2, 0.2, 15, False), (2, [False, True, True], [64, 128, 64, 32], 2, 0.2, 17, False), (2, [False, True, True], [64, 128, 64, 32], 4, 0.2, 10, False), (2, [False, True, True], [64, 128, 64, 32], 4, 0.2, 12, False), (2, [False, True, True], [64, 128, 64, 32], 4, 0.2, 15, False), (2, [False, True, True], [64, 128, 64, 32], 4, 0.2, 17, False), (2, [False, True, True], [64, 128, 64, 32], 8, 0.2, 10, False), (2, [False, True, True], [64, 128, 64, 32], 8, 0.2, 12, False), (2, [False, True, True], [64, 128, 64, 32], 8, 0.2, 15, False), (2, [False, True, True], [64, 128, 64, 32], 8, 0.2, 17, False)]\n",
      "\n",
      "\n",
      "1th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07873, saving model to ../result\\lstm_AE_not_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07873 to 0.04045, saving model to ../result\\lstm_AE_not_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04045 to 0.03580, saving model to ../result\\lstm_AE_not_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03580 to 0.02850, saving model to ../result\\lstm_AE_not_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02850 to 0.02372, saving model to ../result\\lstm_AE_not_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02372 to 0.02184, saving model to ../result\\lstm_AE_not_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02184 to 0.02141, saving model to ../result\\lstm_AE_not_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02141 to 0.02105, saving model to ../result\\lstm_AE_not_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02105\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02105\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02105\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02105\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02105\n",
      "Epoch 13: early stopping\n",
      "2th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07196, saving model to ../result\\lstm_AE_not_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07196 to 0.03434, saving model to ../result\\lstm_AE_not_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03434 to 0.03061, saving model to ../result\\lstm_AE_not_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03061 to 0.02807, saving model to ../result\\lstm_AE_not_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02807 to 0.02694, saving model to ../result\\lstm_AE_not_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02694 to 0.02565, saving model to ../result\\lstm_AE_not_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02565 to 0.02519, saving model to ../result\\lstm_AE_not_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02519 to 0.02491, saving model to ../result\\lstm_AE_not_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02491\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02491\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02491\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02491\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02491\n",
      "Epoch 13: early stopping\n",
      "3th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08846, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08846 to 0.03806, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03806 to 0.03343, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03343 to 0.03026, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03026 to 0.02537, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02537 to 0.02176, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02176 to 0.02032, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02032 to 0.01943, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01943 to 0.01842, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01842 to 0.01805, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01805 to 0.01773, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01773 to 0.01706, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01706 to 0.01677, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01677\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01677\n",
      "\n",
      "Epoch 16: loss improved from 0.01677 to 0.01664, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01664\n",
      "\n",
      "Epoch 18: loss improved from 0.01664 to 0.01641, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01641\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01641\n",
      "\n",
      "Epoch 21: loss improved from 0.01641 to 0.01633, saving model to ../result\\lstm_AE_not_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01633\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01633\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01633\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01633\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01633\n",
      "Epoch 26: early stopping\n",
      "4th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08885, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08885 to 0.03596, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03596 to 0.03259, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03259 to 0.03055, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03055 to 0.02897, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02897 to 0.02814, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02814 to 0.02728, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02728 to 0.02681, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02681 to 0.02611, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02611 to 0.02544, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02544 to 0.02497, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02497 to 0.02475, saving model to ../result\\lstm_AE_not_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02475\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02475\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02475\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02475\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02475\n",
      "Epoch 17: early stopping\n",
      "5th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.09553, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.09553 to 0.04512, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04512 to 0.04037, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04037 to 0.03746, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03746 to 0.03537, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03537 to 0.03409, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03409 to 0.03201, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03201 to 0.03105, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03105 to 0.03100, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.03100\n",
      "\n",
      "Epoch 11: loss did not improve from 0.03100\n",
      "\n",
      "Epoch 12: loss did not improve from 0.03100\n",
      "\n",
      "Epoch 13: loss did not improve from 0.03100\n",
      "\n",
      "Epoch 14: loss improved from 0.03100 to 0.03096, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.03096\n",
      "\n",
      "Epoch 16: loss improved from 0.03096 to 0.03093, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.03093\n",
      "\n",
      "Epoch 18: loss did not improve from 0.03093\n",
      "\n",
      "Epoch 19: loss did not improve from 0.03093\n",
      "\n",
      "Epoch 20: loss improved from 0.03093 to 0.02826, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02826 to 0.02167, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02167\n",
      "\n",
      "Epoch 23: loss improved from 0.02167 to 0.02159, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02159 to 0.02117, saving model to ../result\\lstm_AE_not_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02117\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02117\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02117\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02117\n",
      "\n",
      "Epoch 29: loss did not improve from 0.02117\n",
      "Epoch 29: early stopping\n",
      "WARNING:tensorflow:5 out of the last 10 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x000001A597FA5FC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "6th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10559, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.10559 to 0.04278, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04278 to 0.03600, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03600 to 0.03307, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03307 to 0.03114, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03114 to 0.02934, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02934 to 0.02814, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02814 to 0.02716, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02716 to 0.02583, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02583 to 0.02515, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02515 to 0.02502, saving model to ../result\\lstm_AE_not_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02502\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02502\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02502\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02502\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02502\n",
      "Epoch 16: early stopping\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function TensorFlowTrainer.make_test_function.<locals>.one_step_on_iterator at 0x000001A58BB38A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "7th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11223, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11223 to 0.04403, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04403 to 0.03675, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03675 to 0.03438, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03438 to 0.03265, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03265 to 0.03134, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03134 to 0.02997, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02997 to 0.02902, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02902 to 0.02829, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02829 to 0.02751, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02751 to 0.02675, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02675 to 0.02613, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02613 to 0.02546, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02546 to 0.02518, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02518 to 0.02491, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02491 to 0.02487, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02487 to 0.02475, saving model to ../result\\lstm_AE_not_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02475\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02475\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02475\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02475\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02475\n",
      "Epoch 22: early stopping\n",
      "8th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11774, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11774 to 0.04426, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04426 to 0.03719, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03719 to 0.03457, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03457 to 0.03288, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03288 to 0.03146, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03146 to 0.03038, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03038 to 0.02944, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02944 to 0.02884, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02884 to 0.02791, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02791 to 0.02375, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02375 to 0.02073, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02073 to 0.01957, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01957 to 0.01896, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01896 to 0.01811, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01811 to 0.01743, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01743 to 0.01666, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01666\n",
      "\n",
      "Epoch 19: loss improved from 0.01666 to 0.01637, saving model to ../result\\lstm_AE_not_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01637\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01637\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01637\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01637\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01637\n",
      "Epoch 24: early stopping\n",
      "9th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.14488, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.14488 to 0.05856, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05856 to 0.04812, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04812 to 0.04336, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04336 to 0.04118, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04118 to 0.03932, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03932 to 0.03763, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03763 to 0.03628, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03628 to 0.03497, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03497 to 0.03310, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03310 to 0.02773, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02773 to 0.02490, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02490 to 0.02294, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02294 to 0.02149, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02149 to 0.02124, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02124\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02124\n",
      "\n",
      "Epoch 18: loss improved from 0.02124 to 0.02118, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02118\n",
      "\n",
      "Epoch 20: loss improved from 0.02118 to 0.02111, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02111 to 0.02082, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02082 to 0.02074, saving model to ../result\\lstm_AE_not_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02074\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02074\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02074\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02074\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02074\n",
      "Epoch 27: early stopping\n",
      "10th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.15254, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.15254 to 0.06752, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.06752 to 0.04440, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04440 to 0.03932, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03932 to 0.03651, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03651 to 0.03475, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03475 to 0.03341, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03341 to 0.03194, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03194 to 0.03100, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03100 to 0.03002, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03002 to 0.02918, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02918 to 0.02857, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02857 to 0.02793, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02793 to 0.02716, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02716 to 0.02635, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02635 to 0.02570, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02570 to 0.02530, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02530 to 0.02496, saving model to ../result\\lstm_AE_not_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02496\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02496\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02496\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02496\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02496\n",
      "Epoch 23: early stopping\n",
      "11th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.15791, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.15791 to 0.06943, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.06943 to 0.04464, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04464 to 0.03890, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03890 to 0.03669, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03669 to 0.03517, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03517 to 0.03375, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03375 to 0.03299, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03299 to 0.03207, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03207 to 0.03116, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03116 to 0.03057, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03057 to 0.03001, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03001 to 0.02922, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02922 to 0.02878, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02878 to 0.02851, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02851 to 0.02814, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02814 to 0.02776, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02776 to 0.02731, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02731 to 0.02701, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02701 to 0.02664, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02664 to 0.02639, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02639 to 0.02594, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02594 to 0.02545, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02545 to 0.02527, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.02527 to 0.02511, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02511 to 0.02494, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.02494 to 0.02479, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02479\n",
      "\n",
      "Epoch 29: loss did not improve from 0.02479\n",
      "\n",
      "Epoch 30: loss improved from 0.02479 to 0.02468, saving model to ../result\\lstm_AE_not_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.02468\n",
      "\n",
      "Epoch 32: loss did not improve from 0.02468\n",
      "\n",
      "Epoch 33: loss did not improve from 0.02468\n",
      "\n",
      "Epoch 34: loss did not improve from 0.02468\n",
      "\n",
      "Epoch 35: loss did not improve from 0.02468\n",
      "Epoch 35: early stopping\n",
      "12th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.16103, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.16103 to 0.08041, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.08041 to 0.04590, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04590 to 0.04058, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04058 to 0.03717, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03717 to 0.03577, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03577 to 0.03472, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03472 to 0.03380, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03380 to 0.03288, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03288 to 0.03216, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03216 to 0.03165, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03165 to 0.03086, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03086 to 0.03044, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.03044 to 0.02977, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02977 to 0.02952, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02952 to 0.02924, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02924 to 0.02866, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02866 to 0.02842, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02842 to 0.02807, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02807 to 0.02765, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02765 to 0.02745, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02745 to 0.02715, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02715 to 0.02691, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02691\n",
      "\n",
      "Epoch 25: loss improved from 0.02691 to 0.02676, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02676 to 0.02626, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.02626 to 0.02586, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.02586 to 0.02538, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.02538 to 0.02522, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.02522 to 0.02486, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.02486 to 0.02471, saving model to ../result\\lstm_AE_not_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.02471\n",
      "\n",
      "Epoch 33: loss did not improve from 0.02471\n",
      "\n",
      "Epoch 34: loss did not improve from 0.02471\n",
      "\n",
      "Epoch 35: loss did not improve from 0.02471\n",
      "\n",
      "Epoch 36: loss did not improve from 0.02471\n",
      "Epoch 36: early stopping\n",
      "13th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.16456, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.16456 to 0.11800, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.11800 to 0.06226, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.06226 to 0.05167, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.05167 to 0.04775, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04775 to 0.04494, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04494 to 0.04350, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.04350 to 0.04219, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.04219 to 0.04096, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.04096 to 0.04015, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.04015 to 0.03940, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03940 to 0.03830, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03830 to 0.03770, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.03770 to 0.03686, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.03686 to 0.03638, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.03638 to 0.03570, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03570 to 0.03524, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.03524 to 0.03477, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.03477 to 0.03404, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.03404 to 0.03286, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.03286 to 0.03174, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.03174 to 0.03138, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.03138 to 0.03074, saving model to ../result\\lstm_AE_not_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.03074\n",
      "\n",
      "Epoch 25: loss did not improve from 0.03074\n",
      "\n",
      "Epoch 26: loss did not improve from 0.03074\n",
      "\n",
      "Epoch 27: loss did not improve from 0.03074\n",
      "\n",
      "Epoch 28: loss did not improve from 0.03074\n",
      "Epoch 28: early stopping\n",
      "14th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.16866, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.16866 to 0.13081, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.13081 to 0.07244, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.07244 to 0.05109, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.05109 to 0.04432, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04432 to 0.04097, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04097 to 0.03864, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03864 to 0.03732, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03732 to 0.03613, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03613 to 0.03495, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03495 to 0.03415, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03415 to 0.03324, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03324 to 0.03267, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.03267 to 0.03184, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.03184 to 0.03130, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.03130 to 0.03082, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03082 to 0.03034, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.03034 to 0.02992, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02992 to 0.02942, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02942 to 0.02928, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02928 to 0.02872, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02872 to 0.02853, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02853 to 0.02813, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02813 to 0.02754, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02754\n",
      "\n",
      "Epoch 26: loss improved from 0.02754 to 0.02709, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.02709 to 0.02641, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.02641 to 0.02579, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.02579 to 0.02561, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.02561 to 0.02508, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.02508\n",
      "\n",
      "Epoch 32: loss did not improve from 0.02508\n",
      "\n",
      "Epoch 33: loss did not improve from 0.02508\n",
      "\n",
      "Epoch 34: loss improved from 0.02508 to 0.02480, saving model to ../result\\lstm_AE_not_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.02480\n",
      "\n",
      "Epoch 36: loss did not improve from 0.02480\n",
      "\n",
      "Epoch 37: loss did not improve from 0.02480\n",
      "\n",
      "Epoch 38: loss did not improve from 0.02480\n",
      "\n",
      "Epoch 39: loss did not improve from 0.02480\n",
      "Epoch 39: early stopping\n",
      "15th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.17191, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.17191 to 0.14279, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.14279 to 0.08509, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.08509 to 0.05526, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.05526 to 0.04630, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04630 to 0.04188, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04188 to 0.03962, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03962 to 0.03819, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03819 to 0.03687, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03687 to 0.03599, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03599 to 0.03540, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03540 to 0.03453, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03453 to 0.03397, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.03397 to 0.03337, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.03337 to 0.03283, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.03283 to 0.03246, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03246 to 0.03177, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.03177 to 0.03141, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.03141 to 0.03110, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.03110 to 0.03075, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.03075 to 0.03014, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.03014 to 0.02973, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02973 to 0.02935, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02935 to 0.02919, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.02919 to 0.02869, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02869 to 0.02844, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.02844 to 0.02786, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.02786 to 0.02784, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.02784 to 0.02750, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.02750\n",
      "\n",
      "Epoch 31: loss improved from 0.02750 to 0.02675, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.02675 to 0.02644, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.02644 to 0.02602, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.02602 to 0.02532, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.02532 to 0.02498, saving model to ../result\\lstm_AE_not_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.02498\n",
      "\n",
      "Epoch 37: loss did not improve from 0.02498\n",
      "\n",
      "Epoch 38: loss did not improve from 0.02498\n",
      "\n",
      "Epoch 39: loss did not improve from 0.02498\n",
      "\n",
      "Epoch 40: loss did not improve from 0.02498\n",
      "Epoch 40: early stopping\n",
      "16th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.17330, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.17330 to 0.14833, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.14833 to 0.09767, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.09767 to 0.06123, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.06123 to 0.04859, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04859 to 0.04384, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04384 to 0.04098, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.04098 to 0.03933, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03933 to 0.03793, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03793 to 0.03679, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03679 to 0.03616, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03616 to 0.03517, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03517 to 0.03458, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.03458 to 0.03392, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.03392 to 0.03351, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.03351 to 0.03308, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03308 to 0.03250, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.03250 to 0.03202, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.03202 to 0.03182, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.03182 to 0.03145, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.03145 to 0.03117, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.03117 to 0.03062, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.03062 to 0.03041, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.03041 to 0.03030, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.03030 to 0.03005, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.03005 to 0.02967, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.02967 to 0.02934, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.02934 to 0.02908, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.02908 to 0.02906, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.02906 to 0.02884, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.02884 to 0.02859, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.02859 to 0.02828, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.02828 to 0.02815, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.02815 to 0.02792, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.02792 to 0.02786, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.02786 to 0.02765, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.02765 to 0.02761, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.02761 to 0.02723, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.02723\n",
      "\n",
      "Epoch 40: loss improved from 0.02723 to 0.02717, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.02717 to 0.02694, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.02694 to 0.02689, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.02689 to 0.02659, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.02659 to 0.02652, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.02652 to 0.02639, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.02639 to 0.02605, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.02605 to 0.02583, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.02583 to 0.02557, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss improved from 0.02557 to 0.02506, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.02506 to 0.02440, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss improved from 0.02440 to 0.02273, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.02273 to 0.01992, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.01992 to 0.01740, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss improved from 0.01740 to 0.01737, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss improved from 0.01737 to 0.01707, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss improved from 0.01707 to 0.01663, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss improved from 0.01663 to 0.01658, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.01658 to 0.01641, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.01641\n",
      "\n",
      "Epoch 60: loss improved from 0.01641 to 0.01624, saving model to ../result\\lstm_AE_not_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss did not improve from 0.01624\n",
      "\n",
      "Epoch 62: loss did not improve from 0.01624\n",
      "\n",
      "Epoch 63: loss did not improve from 0.01624\n",
      "\n",
      "Epoch 64: loss did not improve from 0.01624\n",
      "\n",
      "Epoch 65: loss did not improve from 0.01624\n",
      "Epoch 65: early stopping\n",
      "17th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06860, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06860 to 0.03682, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03682 to 0.03172, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03172 to 0.03104, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss did not improve from 0.03104\n",
      "\n",
      "Epoch 6: loss did not improve from 0.03104\n",
      "\n",
      "Epoch 7: loss improved from 0.03104 to 0.03089, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.03089\n",
      "\n",
      "Epoch 9: loss did not improve from 0.03089\n",
      "\n",
      "Epoch 10: loss improved from 0.03089 to 0.03084, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.03084\n",
      "\n",
      "Epoch 12: loss improved from 0.03084 to 0.02295, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02295 to 0.02146, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02146\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02146\n",
      "\n",
      "Epoch 16: loss improved from 0.02146 to 0.02139, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02139\n",
      "\n",
      "Epoch 18: loss improved from 0.02139 to 0.02128, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02128\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02128\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02128\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02128\n",
      "\n",
      "Epoch 23: loss improved from 0.02128 to 0.02090, saving model to ../result\\lstm_AE_not_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02090\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02090\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02090\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02090\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02090\n",
      "Epoch 28: early stopping\n",
      "18th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05904, saving model to ../result\\lstm_AE_not_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05904 to 0.03103, saving model to ../result\\lstm_AE_not_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03103 to 0.02762, saving model to ../result\\lstm_AE_not_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02762 to 0.02549, saving model to ../result\\lstm_AE_not_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02549 to 0.02533, saving model to ../result\\lstm_AE_not_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02533 to 0.02510, saving model to ../result\\lstm_AE_not_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02510 to 0.02499, saving model to ../result\\lstm_AE_not_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.02499\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02499\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02499\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02499\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02499\n",
      "Epoch 12: early stopping\n",
      "19th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07226, saving model to ../result\\lstm_AE_not_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07226 to 0.03226, saving model to ../result\\lstm_AE_not_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03226 to 0.02876, saving model to ../result\\lstm_AE_not_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02876 to 0.02612, saving model to ../result\\lstm_AE_not_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02612 to 0.02488, saving model to ../result\\lstm_AE_not_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.02488\n",
      "\n",
      "Epoch 7: loss did not improve from 0.02488\n",
      "\n",
      "Epoch 8: loss did not improve from 0.02488\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02488\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02488\n",
      "Epoch 10: early stopping\n",
      "20th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07366, saving model to ../result\\lstm_AE_not_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07366 to 0.03304, saving model to ../result\\lstm_AE_not_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03304 to 0.02993, saving model to ../result\\lstm_AE_not_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02993 to 0.02820, saving model to ../result\\lstm_AE_not_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02820 to 0.02691, saving model to ../result\\lstm_AE_not_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02691 to 0.02573, saving model to ../result\\lstm_AE_not_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02573 to 0.02491, saving model to ../result\\lstm_AE_not_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02491 to 0.02476, saving model to ../result\\lstm_AE_not_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02476\n",
      "\n",
      "Epoch 10: loss improved from 0.02476 to 0.02469, saving model to ../result\\lstm_AE_not_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02469\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02469\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02469\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02469\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02469\n",
      "Epoch 15: early stopping\n",
      "21th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08040, saving model to ../result\\lstm_AE_not_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08040 to 0.04056, saving model to ../result\\lstm_AE_not_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04056 to 0.03650, saving model to ../result\\lstm_AE_not_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03650 to 0.03348, saving model to ../result\\lstm_AE_not_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03348 to 0.03141, saving model to ../result\\lstm_AE_not_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03141 to 0.03121, saving model to ../result\\lstm_AE_not_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03121 to 0.03093, saving model to ../result\\lstm_AE_not_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.03093\n",
      "\n",
      "Epoch 9: loss did not improve from 0.03093\n",
      "\n",
      "Epoch 10: loss did not improve from 0.03093\n",
      "\n",
      "Epoch 11: loss improved from 0.03093 to 0.03089, saving model to ../result\\lstm_AE_not_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03089 to 0.03086, saving model to ../result\\lstm_AE_not_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.03086\n",
      "\n",
      "Epoch 14: loss improved from 0.03086 to 0.03083, saving model to ../result\\lstm_AE_not_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.03083\n",
      "\n",
      "Epoch 16: loss did not improve from 0.03083\n",
      "\n",
      "Epoch 17: loss did not improve from 0.03083\n",
      "\n",
      "Epoch 18: loss did not improve from 0.03083\n",
      "\n",
      "Epoch 19: loss did not improve from 0.03083\n",
      "Epoch 19: early stopping\n",
      "22th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08742, saving model to ../result\\lstm_AE_not_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08742 to 0.03628, saving model to ../result\\lstm_AE_not_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03628 to 0.03194, saving model to ../result\\lstm_AE_not_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03194 to 0.02938, saving model to ../result\\lstm_AE_not_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02938 to 0.02775, saving model to ../result\\lstm_AE_not_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02775 to 0.02548, saving model to ../result\\lstm_AE_not_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02548 to 0.02501, saving model to ../result\\lstm_AE_not_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.02501\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02501\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02501\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02501\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02501\n",
      "Epoch 12: early stopping\n",
      "23th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08837, saving model to ../result\\lstm_AE_not_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08837 to 0.03610, saving model to ../result\\lstm_AE_not_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03610 to 0.03258, saving model to ../result\\lstm_AE_not_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03258 to 0.03068, saving model to ../result\\lstm_AE_not_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03068 to 0.02896, saving model to ../result\\lstm_AE_not_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02896 to 0.02782, saving model to ../result\\lstm_AE_not_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02782 to 0.02615, saving model to ../result\\lstm_AE_not_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02615 to 0.02494, saving model to ../result\\lstm_AE_not_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02494\n",
      "\n",
      "Epoch 10: loss improved from 0.02494 to 0.02472, saving model to ../result\\lstm_AE_not_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02472\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02472\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02472\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02472\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02472\n",
      "Epoch 15: early stopping\n",
      "24th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.09698, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.09698 to 0.03795, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03795 to 0.03332, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03332 to 0.03109, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03109 to 0.02970, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02970 to 0.02856, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02856 to 0.02786, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02786 to 0.02719, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02719 to 0.02624, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02624 to 0.02522, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02522 to 0.02468, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02468\n",
      "\n",
      "Epoch 13: loss improved from 0.02468 to 0.02464, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02464\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02464\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02464\n",
      "\n",
      "Epoch 17: loss improved from 0.02464 to 0.02461, saving model to ../result\\lstm_AE_not_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02461\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02461\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02461\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02461\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02461\n",
      "Epoch 22: early stopping\n",
      "25th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12276, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12276 to 0.05059, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05059 to 0.04309, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04309 to 0.04021, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04021 to 0.03816, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03816 to 0.03653, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03653 to 0.03504, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03504 to 0.03394, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03394 to 0.03242, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03242 to 0.03125, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03125 to 0.03089, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.03089\n",
      "\n",
      "Epoch 13: loss did not improve from 0.03089\n",
      "\n",
      "Epoch 14: loss did not improve from 0.03089\n",
      "\n",
      "Epoch 15: loss did not improve from 0.03089\n",
      "\n",
      "Epoch 16: loss improved from 0.03089 to 0.03086, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03086 to 0.03081, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.03081 to 0.02845, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02845 to 0.02163, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02163\n",
      "\n",
      "Epoch 21: loss improved from 0.02163 to 0.02132, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02132\n",
      "\n",
      "Epoch 23: loss improved from 0.02132 to 0.02104, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02104 to 0.02097, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02097\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02097\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02097\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02097\n",
      "\n",
      "Epoch 29: loss improved from 0.02097 to 0.02080, saving model to ../result\\lstm_AE_not_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.02080\n",
      "\n",
      "Epoch 31: loss did not improve from 0.02080\n",
      "\n",
      "Epoch 32: loss did not improve from 0.02080\n",
      "\n",
      "Epoch 33: loss did not improve from 0.02080\n",
      "\n",
      "Epoch 34: loss did not improve from 0.02080\n",
      "Epoch 34: early stopping\n",
      "26th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12613, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12613 to 0.04578, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04578 to 0.03757, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03757 to 0.03400, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03400 to 0.03176, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03176 to 0.02994, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02994 to 0.02887, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02887 to 0.02751, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02751 to 0.02566, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02566 to 0.02517, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02517\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02517\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02517\n",
      "\n",
      "Epoch 14: loss improved from 0.02517 to 0.02499, saving model to ../result\\lstm_AE_not_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02499\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02499\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02499\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02499\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02499\n",
      "Epoch 19: early stopping\n",
      "27th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13310, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13310 to 0.04874, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04874 to 0.03774, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03774 to 0.03498, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03498 to 0.03321, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03321 to 0.03185, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03185 to 0.03082, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03082 to 0.02996, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02996 to 0.02912, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02912 to 0.02823, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02823 to 0.02784, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02784 to 0.02705, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02705 to 0.02583, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02583 to 0.02500, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02500 to 0.02497, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02497\n",
      "\n",
      "Epoch 17: loss improved from 0.02497 to 0.02487, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02487\n",
      "\n",
      "Epoch 19: loss improved from 0.02487 to 0.02482, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02482\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02482\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02482\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02482\n",
      "\n",
      "Epoch 24: loss improved from 0.02482 to 0.02477, saving model to ../result\\lstm_AE_not_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02477\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02477\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02477\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02477\n",
      "\n",
      "Epoch 29: loss did not improve from 0.02477\n",
      "Epoch 29: early stopping\n",
      "28th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.14496, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.14496 to 0.05204, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05204 to 0.03914, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03914 to 0.03517, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03517 to 0.03347, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03347 to 0.03214, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03214 to 0.03118, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03118 to 0.03039, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03039 to 0.02974, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02974 to 0.02903, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02903 to 0.02863, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02863 to 0.02808, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02808 to 0.02766, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02766 to 0.02733, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02733 to 0.02691, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02691 to 0.02618, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02618 to 0.02579, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02579 to 0.02515, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02515 to 0.02477, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02477\n",
      "\n",
      "Epoch 21: loss improved from 0.02477 to 0.02471, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02471\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02471\n",
      "\n",
      "Epoch 24: loss improved from 0.02471 to 0.02460, saving model to ../result\\lstm_AE_not_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02460\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02460\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02460\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02460\n",
      "\n",
      "Epoch 29: loss did not improve from 0.02460\n",
      "Epoch 29: early stopping\n",
      "29th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.15456, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.15456 to 0.07997, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.07997 to 0.05105, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.05105 to 0.04526, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04526 to 0.04235, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04235 to 0.04079, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04079 to 0.03939, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03939 to 0.03812, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03812 to 0.03699, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03699 to 0.03616, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03616 to 0.03527, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03527 to 0.03451, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03451 to 0.03331, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.03331 to 0.03215, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.03215 to 0.03127, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.03127 to 0.03115, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.03115 to 0.03103, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.03103\n",
      "\n",
      "Epoch 19: loss did not improve from 0.03103\n",
      "\n",
      "Epoch 20: loss did not improve from 0.03103\n",
      "\n",
      "Epoch 21: loss improved from 0.03103 to 0.03099, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.03099\n",
      "\n",
      "Epoch 23: loss improved from 0.03099 to 0.03079, saving model to ../result\\lstm_AE_not_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.03079\n",
      "\n",
      "Epoch 25: loss did not improve from 0.03079\n",
      "\n",
      "Epoch 26: loss did not improve from 0.03079\n",
      "\n",
      "Epoch 27: loss did not improve from 0.03079\n",
      "\n",
      "Epoch 28: loss did not improve from 0.03079\n",
      "Epoch 28: early stopping\n",
      "30th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.16212, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.16212 to 0.08989, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.08989 to 0.04973, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04973 to 0.04071, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04071 to 0.03733, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03733 to 0.03525, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03525 to 0.03381, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03381 to 0.03278, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03278 to 0.03161, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03161 to 0.03077, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03077 to 0.02994, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02994 to 0.02927, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02927 to 0.02888, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02888 to 0.02821, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02821 to 0.02702, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02702 to 0.02609, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02609 to 0.02528, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02528 to 0.02524, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02524\n",
      "\n",
      "Epoch 20: loss improved from 0.02524 to 0.02520, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02520\n",
      "\n",
      "Epoch 22: loss improved from 0.02520 to 0.02512, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02512 to 0.02500, saving model to ../result\\lstm_AE_not_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02500\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02500\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02500\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02500\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02500\n",
      "Epoch 28: early stopping\n",
      "31th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.16679, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.16679 to 0.09760, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.09760 to 0.05191, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.05191 to 0.04184, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04184 to 0.03804, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03804 to 0.03581, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03581 to 0.03459, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03459 to 0.03366, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03366 to 0.03276, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03276 to 0.03209, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03209 to 0.03126, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03126 to 0.03059, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03059 to 0.03000, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.03000 to 0.02951, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02951 to 0.02898, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02898 to 0.02874, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02874 to 0.02834, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02834 to 0.02795, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02795 to 0.02734, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02734 to 0.02635, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02635 to 0.02557, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02557 to 0.02496, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02496 to 0.02478, saving model to ../result\\lstm_AE_not_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02478\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02478\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02478\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02478\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02478\n",
      "Epoch 28: early stopping\n",
      "32th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.16667, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.16667 to 0.10141, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.10141 to 0.05153, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.05153 to 0.04260, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04260 to 0.03873, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03873 to 0.03616, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03616 to 0.03482, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03482 to 0.03380, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03380 to 0.03279, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.03279 to 0.03233, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.03233 to 0.03166, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.03166 to 0.03124, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.03124 to 0.03068, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.03068 to 0.03042, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.03042 to 0.02991, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02991 to 0.02970, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02970 to 0.02930, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02930 to 0.02885, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02885 to 0.02868, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02868 to 0.02835, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02835 to 0.02815, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02815 to 0.02800, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02800 to 0.02762, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02762 to 0.02749, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.02749 to 0.02723, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02723 to 0.02703, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.02703 to 0.02682, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.02682 to 0.02657, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.02657 to 0.02617, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.02617 to 0.02595, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.02595 to 0.02562, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.02562 to 0.02519, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.02519 to 0.02505, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.02505 to 0.02484, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.02484 to 0.02472, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.02472\n",
      "\n",
      "Epoch 37: loss improved from 0.02472 to 0.02471, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.02471\n",
      "\n",
      "Epoch 39: loss improved from 0.02471 to 0.02471, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.02471\n",
      "\n",
      "Epoch 41: loss did not improve from 0.02471\n",
      "\n",
      "Epoch 42: loss improved from 0.02471 to 0.02464, saving model to ../result\\lstm_AE_not_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.02464\n",
      "\n",
      "Epoch 44: loss did not improve from 0.02464\n",
      "\n",
      "Epoch 45: loss did not improve from 0.02464\n",
      "\n",
      "Epoch 46: loss did not improve from 0.02464\n",
      "\n",
      "Epoch 47: loss did not improve from 0.02464\n",
      "Epoch 47: early stopping\n",
      "33th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06200, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06200 to 0.02424, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02424 to 0.01702, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01702 to 0.01161, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01161 to 0.01095, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.01095\n",
      "\n",
      "Epoch 7: loss did not improve from 0.01095\n",
      "\n",
      "Epoch 8: loss improved from 0.01095 to 0.01084, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01084 to 0.01083, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.01083\n",
      "\n",
      "Epoch 11: loss improved from 0.01083 to 0.01082, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.01082\n",
      "\n",
      "Epoch 13: loss improved from 0.01082 to 0.01066, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01066\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01066\n",
      "\n",
      "Epoch 16: loss improved from 0.01066 to 0.01061, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01061 to 0.01055, saving model to ../result\\lstm_AE_not_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01055\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01055\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01055\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01055\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01055\n",
      "Epoch 22: early stopping\n",
      "34th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05817, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05817 to 0.02227, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02227 to 0.01650, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01650 to 0.01265, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01265 to 0.01059, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01059 to 0.00946, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00946 to 0.00930, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.00930\n",
      "\n",
      "Epoch 9: loss improved from 0.00930 to 0.00926, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00926 to 0.00920, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00920\n",
      "\n",
      "Epoch 12: loss improved from 0.00920 to 0.00914, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00914\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00914\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00914\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00914\n",
      "\n",
      "Epoch 17: loss improved from 0.00914 to 0.00910, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00910\n",
      "\n",
      "Epoch 19: loss improved from 0.00910 to 0.00903, saving model to ../result\\lstm_AE_not_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00903\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00903\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00903\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00903\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00903\n",
      "Epoch 24: early stopping\n",
      "35th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06796, saving model to ../result\\lstm_AE_not_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06796 to 0.02505, saving model to ../result\\lstm_AE_not_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02505 to 0.02009, saving model to ../result\\lstm_AE_not_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02009 to 0.01655, saving model to ../result\\lstm_AE_not_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01655 to 0.01224, saving model to ../result\\lstm_AE_not_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01224 to 0.00985, saving model to ../result\\lstm_AE_not_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00985 to 0.00954, saving model to ../result\\lstm_AE_not_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00954 to 0.00932, saving model to ../result\\lstm_AE_not_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00932 to 0.00917, saving model to ../result\\lstm_AE_not_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00917 to 0.00900, saving model to ../result\\lstm_AE_not_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00900\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00900\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00900\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00900\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00900\n",
      "Epoch 15: early stopping\n",
      "36th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06698, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06698 to 0.02450, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02450 to 0.02095, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02095 to 0.01798, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01798 to 0.01600, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01600 to 0.01339, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01339 to 0.01053, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01053 to 0.00964, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00964 to 0.00930, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00930\n",
      "\n",
      "Epoch 11: loss improved from 0.00930 to 0.00929, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00929 to 0.00922, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00922 to 0.00902, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00902\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00902\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00902\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00902\n",
      "\n",
      "Epoch 18: loss improved from 0.00902 to 0.00896, saving model to ../result\\lstm_AE_not_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00896\n",
      "Epoch 23: early stopping\n",
      "37th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08683, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08683 to 0.03181, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03181 to 0.02448, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02448 to 0.02049, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02049 to 0.01661, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01661 to 0.01443, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01443 to 0.01267, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01267 to 0.01098, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01098 to 0.01079, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.01079\n",
      "\n",
      "Epoch 11: loss did not improve from 0.01079\n",
      "\n",
      "Epoch 12: loss improved from 0.01079 to 0.01078, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01078\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01078\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01078\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01078\n",
      "\n",
      "Epoch 17: loss improved from 0.01078 to 0.01067, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01067\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01067\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01067\n",
      "\n",
      "Epoch 21: loss improved from 0.01067 to 0.01044, saving model to ../result\\lstm_AE_not_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01044\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01044\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01044\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01044\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01044\n",
      "Epoch 26: early stopping\n",
      "38th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08753, saving model to ../result\\lstm_AE_not_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08753 to 0.03126, saving model to ../result\\lstm_AE_not_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03126 to 0.02352, saving model to ../result\\lstm_AE_not_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02352 to 0.02048, saving model to ../result\\lstm_AE_not_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02048 to 0.01751, saving model to ../result\\lstm_AE_not_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01751 to 0.01507, saving model to ../result\\lstm_AE_not_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01507 to 0.01289, saving model to ../result\\lstm_AE_not_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01289 to 0.01114, saving model to ../result\\lstm_AE_not_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01114 to 0.00998, saving model to ../result\\lstm_AE_not_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00998 to 0.00913, saving model to ../result\\lstm_AE_not_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00913\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00913\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00913\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00913\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00913\n",
      "Epoch 15: early stopping\n",
      "39th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10142, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.10142 to 0.03525, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03525 to 0.02596, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02596 to 0.02273, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02273 to 0.02014, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02014 to 0.01834, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01834 to 0.01550, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01550 to 0.01313, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01313 to 0.01121, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01121 to 0.00971, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00971 to 0.00953, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00953 to 0.00939, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00939\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00939\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00939\n",
      "\n",
      "Epoch 16: loss improved from 0.00939 to 0.00921, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00921 to 0.00912, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00912 to 0.00911, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00911\n",
      "\n",
      "Epoch 20: loss improved from 0.00911 to 0.00887, saving model to ../result\\lstm_AE_not_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00887\n",
      "Epoch 25: early stopping\n",
      "40th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.09831, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.09831 to 0.03487, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03487 to 0.02654, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02654 to 0.02347, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02347 to 0.02143, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02143 to 0.02005, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02005 to 0.01798, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01798 to 0.01582, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01582 to 0.01422, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01422 to 0.01252, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01252 to 0.01102, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01102 to 0.01015, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01015 to 0.00947, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00947 to 0.00939, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00939 to 0.00932, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00932 to 0.00923, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00923\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00923\n",
      "\n",
      "Epoch 19: loss improved from 0.00923 to 0.00898, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00898\n",
      "\n",
      "Epoch 21: loss improved from 0.00898 to 0.00891, saving model to ../result\\lstm_AE_not_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00891\n",
      "Epoch 26: early stopping\n",
      "41th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11915, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11915 to 0.04909, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04909 to 0.03369, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03369 to 0.02871, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02871 to 0.02528, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02528 to 0.02271, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02271 to 0.02049, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02049 to 0.01844, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01844 to 0.01633, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01633 to 0.01478, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01478 to 0.01420, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01420 to 0.01378, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01378 to 0.01288, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01288 to 0.01154, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01154 to 0.01103, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01103 to 0.01085, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01085 to 0.01081, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01081 to 0.01072, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01072\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01072\n",
      "\n",
      "Epoch 21: loss improved from 0.01072 to 0.01064, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01064 to 0.01062, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01062\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01062\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01062\n",
      "\n",
      "Epoch 26: loss improved from 0.01062 to 0.01058, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01058 to 0.01055, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01055\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01055\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01055\n",
      "\n",
      "Epoch 31: loss improved from 0.01055 to 0.01050, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01050\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01050\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01050\n",
      "\n",
      "Epoch 35: loss improved from 0.01050 to 0.01047, saving model to ../result\\lstm_AE_not_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01047\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01047\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01047\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01047\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01047\n",
      "Epoch 40: early stopping\n",
      "42th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12220, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12220 to 0.05382, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05382 to 0.03430, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03430 to 0.02810, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02810 to 0.02492, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02492 to 0.02206, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02206 to 0.02058, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02058 to 0.01887, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01887 to 0.01738, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01738 to 0.01608, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01608 to 0.01451, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01451 to 0.01309, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01309 to 0.01193, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01193 to 0.01085, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01085 to 0.00969, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00969 to 0.00927, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00927 to 0.00926, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00926 to 0.00915, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00915 to 0.00908, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00908\n",
      "\n",
      "Epoch 21: loss improved from 0.00908 to 0.00899, saving model to ../result\\lstm_AE_not_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00899\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00899\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00899\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00899\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00899\n",
      "Epoch 26: early stopping\n",
      "43th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12454, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12454 to 0.05489, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05489 to 0.03802, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03802 to 0.02953, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02953 to 0.02586, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02586 to 0.02387, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02387 to 0.02227, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02227 to 0.02109, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02109 to 0.01973, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01973 to 0.01855, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01855 to 0.01724, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01724 to 0.01562, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01562 to 0.01445, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01445 to 0.01348, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01348 to 0.01247, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01247 to 0.01140, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01140 to 0.01048, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01048 to 0.00961, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00961 to 0.00928, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00928 to 0.00923, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00923\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00923\n",
      "\n",
      "Epoch 23: loss improved from 0.00923 to 0.00904, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00904\n",
      "\n",
      "Epoch 25: loss improved from 0.00904 to 0.00901, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00901 to 0.00891, saving model to ../result\\lstm_AE_not_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00891\n",
      "Epoch 31: early stopping\n",
      "44th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12435, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12435 to 0.06020, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.06020 to 0.03789, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03789 to 0.03071, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03071 to 0.02713, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02713 to 0.02493, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02493 to 0.02345, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02345 to 0.02188, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02188 to 0.02085, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02085 to 0.02003, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02003 to 0.01911, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01911 to 0.01818, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01818 to 0.01744, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01744 to 0.01648, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01648 to 0.01520, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01520 to 0.01387, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01387 to 0.01292, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01292 to 0.01243, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01243 to 0.01192, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01192 to 0.01126, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01126 to 0.01048, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01048 to 0.00994, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00994 to 0.00980, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00980 to 0.00936, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00936 to 0.00927, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00927 to 0.00914, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00914\n",
      "\n",
      "Epoch 28: loss improved from 0.00914 to 0.00912, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00912 to 0.00906, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00906\n",
      "\n",
      "Epoch 31: loss improved from 0.00906 to 0.00901, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 34: loss improved from 0.00901 to 0.00899, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00899\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00899\n",
      "\n",
      "Epoch 37: loss improved from 0.00899 to 0.00895, saving model to ../result\\lstm_AE_not_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00895\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00895\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00895\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00895\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00895\n",
      "Epoch 42: early stopping\n",
      "45th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13452, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13452 to 0.10423, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.10423 to 0.05600, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.05600 to 0.04285, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04285 to 0.03546, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03546 to 0.03146, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03146 to 0.02870, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02870 to 0.02700, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02700 to 0.02502, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02502 to 0.02387, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02387 to 0.02234, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02234 to 0.02104, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02104 to 0.01971, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01971 to 0.01821, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01821 to 0.01651, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01651 to 0.01527, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01527 to 0.01461, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01461 to 0.01426, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01426 to 0.01400, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01400 to 0.01362, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01362 to 0.01277, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01277 to 0.01152, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01152 to 0.01135, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01135 to 0.01067, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01067 to 0.01063, saving model to ../result\\lstm_AE_not_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01063\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01063\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01063\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01063\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01063\n",
      "Epoch 30: early stopping\n",
      "46th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13600, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13600 to 0.10674, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.10674 to 0.06031, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.06031 to 0.04421, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04421 to 0.03808, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03808 to 0.03228, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03228 to 0.02858, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02858 to 0.02676, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02676 to 0.02509, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02509 to 0.02389, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02389 to 0.02287, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02287 to 0.02162, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02162 to 0.02054, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02054 to 0.02003, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02003 to 0.01915, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01915 to 0.01825, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01825 to 0.01734, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01734 to 0.01680, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01680 to 0.01597, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01597 to 0.01508, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01508 to 0.01356, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01356 to 0.01184, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01184 to 0.01069, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01069 to 0.00996, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00996 to 0.00940, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00940\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00940\n",
      "\n",
      "Epoch 28: loss improved from 0.00940 to 0.00923, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00923 to 0.00915, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00915\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00915\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00915\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00915\n",
      "\n",
      "Epoch 34: loss improved from 0.00915 to 0.00912, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00912\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00912\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00912\n",
      "\n",
      "Epoch 38: loss improved from 0.00912 to 0.00896, saving model to ../result\\lstm_AE_not_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00896\n",
      "Epoch 43: early stopping\n",
      "47th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13756, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13756 to 0.11120, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.11120 to 0.06444, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.06444 to 0.04484, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04484 to 0.03921, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03921 to 0.03294, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03294 to 0.02890, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02890 to 0.02664, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02664 to 0.02539, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02539 to 0.02453, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02453 to 0.02338, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02338 to 0.02214, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02214 to 0.02174, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02174 to 0.02115, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02115 to 0.02025, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02025 to 0.01970, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01970 to 0.01860, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01860 to 0.01833, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01833 to 0.01779, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01779 to 0.01689, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01689 to 0.01584, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01584 to 0.01520, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01520 to 0.01438, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01438 to 0.01332, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01332 to 0.01249, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01249 to 0.01234, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01234 to 0.01129, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01129 to 0.01062, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01062 to 0.01008, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01008 to 0.00949, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00949 to 0.00946, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00946\n",
      "\n",
      "Epoch 33: loss improved from 0.00946 to 0.00941, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00941 to 0.00931, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00931 to 0.00918, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.00918 to 0.00904, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00904\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00904\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00904\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00904\n",
      "\n",
      "Epoch 41: loss improved from 0.00904 to 0.00901, saving model to ../result\\lstm_AE_not_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00901\n",
      "Epoch 46: early stopping\n",
      "48th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13758, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13758 to 0.11302, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.11302 to 0.06810, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.06810 to 0.04654, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04654 to 0.03851, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03851 to 0.03249, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03249 to 0.02954, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02954 to 0.02738, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02738 to 0.02601, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02601 to 0.02439, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02439 to 0.02326, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02326 to 0.02261, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02261 to 0.02197, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02197 to 0.02131, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02131 to 0.02058, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02058 to 0.01982, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01982 to 0.01944, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01944 to 0.01882, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01882 to 0.01831, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01831 to 0.01771, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01771 to 0.01690, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01690 to 0.01611, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01611 to 0.01535, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01535 to 0.01461, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01461 to 0.01417, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01417 to 0.01342, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01342 to 0.01324, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01324 to 0.01281, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01281 to 0.01241, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01241 to 0.01222, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.01222 to 0.01177, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01177 to 0.01145, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01145 to 0.01096, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.01096 to 0.01051, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.01051 to 0.01004, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.01004 to 0.00984, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00984 to 0.00963, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00963 to 0.00932, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00932\n",
      "\n",
      "Epoch 40: loss improved from 0.00932 to 0.00930, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00930 to 0.00913, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00913\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00913\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00913\n",
      "\n",
      "Epoch 45: loss improved from 0.00913 to 0.00908, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00908\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00908\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00908\n",
      "\n",
      "Epoch 49: loss improved from 0.00908 to 0.00903, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss improved from 0.00903 to 0.00887, saving model to ../result\\lstm_AE_not_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00887\n",
      "Epoch 55: early stopping\n",
      "49th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05158, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05158 to 0.01986, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01986 to 0.01491, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01491 to 0.01426, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01426 to 0.01222, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01222 to 0.01114, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01114 to 0.01101, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01101 to 0.01090, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01090 to 0.01081, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.01081\n",
      "\n",
      "Epoch 11: loss improved from 0.01081 to 0.01078, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01078 to 0.01058, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01058 to 0.01057, saving model to ../result\\lstm_AE_not_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01057\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01057\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01057\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01057\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01057\n",
      "Epoch 18: early stopping\n",
      "50th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04951, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04951 to 0.01893, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01893 to 0.01371, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01371 to 0.01212, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01212 to 0.00997, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00997 to 0.00941, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00941 to 0.00934, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00934 to 0.00931, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00931 to 0.00926, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00926\n",
      "\n",
      "Epoch 11: loss improved from 0.00926 to 0.00910, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00910 to 0.00894, saving model to ../result\\lstm_AE_not_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00894\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00894\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00894\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00894\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00894\n",
      "Epoch 17: early stopping\n",
      "51th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05429, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05429 to 0.02088, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02088 to 0.01600, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01600 to 0.01305, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01305 to 0.01248, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.01248\n",
      "\n",
      "Epoch 7: loss improved from 0.01248 to 0.01133, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01133 to 0.00997, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00997 to 0.00975, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00975 to 0.00926, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00926 to 0.00922, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00922\n",
      "\n",
      "Epoch 13: loss improved from 0.00922 to 0.00918, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00918 to 0.00900, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00900 to 0.00895, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00895 to 0.00887, saving model to ../result\\lstm_AE_not_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00887\n",
      "Epoch 21: early stopping\n",
      "52th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05682, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05682 to 0.02156, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02156 to 0.01756, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01756 to 0.01522, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01522 to 0.01278, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01278 to 0.01248, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01248 to 0.01211, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01211 to 0.01106, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01106 to 0.00953, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00953 to 0.00930, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00930 to 0.00920, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00920\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00920\n",
      "\n",
      "Epoch 14: loss improved from 0.00920 to 0.00909, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00909\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00909\n",
      "\n",
      "Epoch 17: loss improved from 0.00909 to 0.00891, saving model to ../result\\lstm_AE_not_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00891\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00891\n",
      "Epoch 22: early stopping\n",
      "53th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06810, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06810 to 0.02688, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02688 to 0.02045, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02045 to 0.01553, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01553 to 0.01505, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01505 to 0.01468, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01468 to 0.01366, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01366 to 0.01157, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01157 to 0.01088, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01088 to 0.01069, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.01069\n",
      "\n",
      "Epoch 12: loss improved from 0.01069 to 0.01061, saving model to ../result\\lstm_AE_not_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01061\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01061\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01061\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01061\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01061\n",
      "Epoch 17: early stopping\n",
      "54th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07428, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07428 to 0.02492, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02492 to 0.01927, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01927 to 0.01618, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01618 to 0.01354, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01354 to 0.01268, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01268 to 0.01231, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.01231\n",
      "\n",
      "Epoch 9: loss improved from 0.01231 to 0.01140, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01140 to 0.01008, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01008 to 0.00925, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00925 to 0.00915, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00915\n",
      "\n",
      "Epoch 14: loss improved from 0.00915 to 0.00915, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00915\n",
      "\n",
      "Epoch 16: loss improved from 0.00915 to 0.00899, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00899\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00899\n",
      "\n",
      "Epoch 19: loss improved from 0.00899 to 0.00874, saving model to ../result\\lstm_AE_not_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00874\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00874\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00874\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00874\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00874\n",
      "Epoch 24: early stopping\n",
      "55th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07811, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07811 to 0.02775, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02775 to 0.02166, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02166 to 0.01838, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01838 to 0.01579, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01579 to 0.01350, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01350 to 0.01274, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01274 to 0.01223, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01223 to 0.01218, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01218 to 0.01162, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01162 to 0.00987, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00987 to 0.00924, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00924\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00924\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00924\n",
      "\n",
      "Epoch 16: loss improved from 0.00924 to 0.00908, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00908\n",
      "\n",
      "Epoch 18: loss improved from 0.00908 to 0.00907, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00907 to 0.00904, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00904\n",
      "\n",
      "Epoch 21: loss improved from 0.00904 to 0.00901, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 23: loss improved from 0.00901 to 0.00895, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00895\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00895\n",
      "\n",
      "Epoch 26: loss improved from 0.00895 to 0.00877, saving model to ../result\\lstm_AE_not_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00877\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00877\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00877\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00877\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00877\n",
      "Epoch 31: early stopping\n",
      "56th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.08066, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.08066 to 0.02952, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02952 to 0.02173, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02173 to 0.01932, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01932 to 0.01738, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01738 to 0.01570, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01570 to 0.01422, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01422 to 0.01259, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01259 to 0.01011, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01011 to 0.00949, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00949 to 0.00923, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00923\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00923\n",
      "\n",
      "Epoch 14: loss improved from 0.00923 to 0.00896, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 17: loss improved from 0.00896 to 0.00894, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00894\n",
      "\n",
      "Epoch 19: loss improved from 0.00894 to 0.00890, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00890 to 0.00884, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00884\n",
      "\n",
      "Epoch 22: loss improved from 0.00884 to 0.00882, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00882\n",
      "\n",
      "Epoch 24: loss improved from 0.00882 to 0.00867, saving model to ../result\\lstm_AE_not_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00867\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00867\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00867\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00867\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00867\n",
      "Epoch 29: early stopping\n",
      "57th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.09785, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.09785 to 0.03798, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03798 to 0.02668, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02668 to 0.02254, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02254 to 0.01936, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01936 to 0.01617, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01617 to 0.01521, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01521 to 0.01462, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.01462\n",
      "\n",
      "Epoch 10: loss improved from 0.01462 to 0.01438, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01438 to 0.01435, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01435 to 0.01411, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01411 to 0.01392, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01392 to 0.01345, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01345 to 0.01183, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01183 to 0.01084, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01084 to 0.01060, saving model to ../result\\lstm_AE_not_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01060\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01060\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01060\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01060\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01060\n",
      "Epoch 22: early stopping\n",
      "58th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10569, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.10569 to 0.03787, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03787 to 0.02600, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02600 to 0.02199, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02199 to 0.01939, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01939 to 0.01696, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01696 to 0.01458, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01458 to 0.01313, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01313 to 0.01272, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01272 to 0.01269, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01269 to 0.01223, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.01223\n",
      "\n",
      "Epoch 13: loss improved from 0.01223 to 0.01197, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01197\n",
      "\n",
      "Epoch 15: loss improved from 0.01197 to 0.01164, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01164 to 0.01045, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01045 to 0.00961, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00961 to 0.00909, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00909 to 0.00901, saving model to ../result\\lstm_AE_not_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00901\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00901\n",
      "Epoch 24: early stopping\n",
      "59th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11038, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11038 to 0.04205, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04205 to 0.02854, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02854 to 0.02375, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02375 to 0.02168, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02168 to 0.02007, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02007 to 0.01869, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01869 to 0.01745, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01745 to 0.01623, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01623 to 0.01505, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01505 to 0.01375, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01375 to 0.01257, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01257 to 0.01215, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01215 to 0.01186, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01186 to 0.01174, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01174 to 0.01075, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01075 to 0.00929, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00929\n",
      "\n",
      "Epoch 19: loss improved from 0.00929 to 0.00898, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00898\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00898\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00898\n",
      "\n",
      "Epoch 23: loss improved from 0.00898 to 0.00888, saving model to ../result\\lstm_AE_not_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00888\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00888\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00888\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00888\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00888\n",
      "Epoch 28: early stopping\n",
      "60th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11073, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11073 to 0.04423, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04423 to 0.02834, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02834 to 0.02427, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02427 to 0.02194, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02194 to 0.02040, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02040 to 0.01918, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01918 to 0.01858, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01858 to 0.01704, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01704 to 0.01617, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01617 to 0.01536, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01536 to 0.01455, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01455 to 0.01357, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01357 to 0.01255, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01255 to 0.01226, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01226\n",
      "\n",
      "Epoch 17: loss improved from 0.01226 to 0.01211, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01211 to 0.01205, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01205 to 0.01174, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01174 to 0.01166, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01166 to 0.01077, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01077 to 0.00955, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00955 to 0.00916, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00916\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00916\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00916\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00916\n",
      "\n",
      "Epoch 28: loss improved from 0.00916 to 0.00908, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00908 to 0.00890, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00890\n",
      "\n",
      "Epoch 31: loss improved from 0.00890 to 0.00877, saving model to ../result\\lstm_AE_not_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00877\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00877\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00877\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00877\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00877\n",
      "Epoch 36: early stopping\n",
      "61th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.12853, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.12853 to 0.06562, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.06562 to 0.04185, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04185 to 0.03165, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03165 to 0.02748, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02748 to 0.02451, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02451 to 0.02238, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02238 to 0.02074, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02074 to 0.01908, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01908 to 0.01704, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01704 to 0.01550, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01550 to 0.01528, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01528 to 0.01449, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01449\n",
      "\n",
      "Epoch 15: loss improved from 0.01449 to 0.01447, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01447 to 0.01432, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01432 to 0.01421, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01421\n",
      "\n",
      "Epoch 19: loss improved from 0.01421 to 0.01390, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01390 to 0.01340, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01340 to 0.01209, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01209 to 0.01096, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01096 to 0.01080, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01080\n",
      "\n",
      "Epoch 25: loss improved from 0.01080 to 0.01060, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01060\n",
      "\n",
      "Epoch 27: loss improved from 0.01060 to 0.01057, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01057\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01057\n",
      "\n",
      "Epoch 30: loss improved from 0.01057 to 0.01052, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01052\n",
      "\n",
      "Epoch 32: loss improved from 0.01052 to 0.01047, saving model to ../result\\lstm_AE_not_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01047\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01047\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01047\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01047\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01047\n",
      "Epoch 37: early stopping\n",
      "62th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13185, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13185 to 0.07440, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.07440 to 0.04222, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04222 to 0.03203, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03203 to 0.02759, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02759 to 0.02409, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02409 to 0.02260, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02260 to 0.02120, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02120 to 0.01980, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01980 to 0.01822, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01822 to 0.01763, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01763 to 0.01634, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01634 to 0.01536, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01536 to 0.01438, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01438 to 0.01354, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01354 to 0.01275, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01275\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01275\n",
      "\n",
      "Epoch 19: loss improved from 0.01275 to 0.01262, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01262\n",
      "\n",
      "Epoch 21: loss improved from 0.01262 to 0.01229, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01229\n",
      "\n",
      "Epoch 23: loss improved from 0.01229 to 0.01226, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01226\n",
      "\n",
      "Epoch 25: loss improved from 0.01226 to 0.01212, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01212 to 0.01206, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01206 to 0.01185, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01185 to 0.01171, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01171 to 0.01137, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01137 to 0.01049, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.01049 to 0.00921, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00921\n",
      "\n",
      "Epoch 33: loss improved from 0.00921 to 0.00902, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00902\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00902\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00902\n",
      "\n",
      "Epoch 37: loss improved from 0.00902 to 0.00896, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00896\n",
      "\n",
      "Epoch 42: loss improved from 0.00896 to 0.00888, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00888\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00888\n",
      "\n",
      "Epoch 45: loss improved from 0.00888 to 0.00887, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00887\n",
      "\n",
      "Epoch 47: loss improved from 0.00887 to 0.00883, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00883 to 0.00882, saving model to ../result\\lstm_AE_not_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00882\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00882\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00882\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00882\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00882\n",
      "Epoch 53: early stopping\n",
      "63th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13518, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13518 to 0.07868, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.07868 to 0.04436, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04436 to 0.03251, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03251 to 0.02774, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02774 to 0.02564, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02564 to 0.02381, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02381 to 0.02232, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02232 to 0.02096, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02096 to 0.02021, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02021 to 0.01919, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01919 to 0.01859, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01859 to 0.01753, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01753 to 0.01703, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01703 to 0.01618, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01618 to 0.01563, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01563 to 0.01505, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01505 to 0.01376, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01376 to 0.01301, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01301 to 0.01262, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01262 to 0.01239, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01239 to 0.01209, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01209\n",
      "\n",
      "Epoch 24: loss improved from 0.01209 to 0.01192, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01192\n",
      "\n",
      "Epoch 26: loss improved from 0.01192 to 0.01175, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01175 to 0.01125, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01125 to 0.01057, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01057 to 0.00948, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00948 to 0.00913, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00913 to 0.00907, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00907 to 0.00893, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00893\n",
      "\n",
      "Epoch 34: loss improved from 0.00893 to 0.00888, saving model to ../result\\lstm_AE_not_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00888\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00888\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00888\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00888\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00888\n",
      "Epoch 39: early stopping\n",
      "64th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.13564, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.13564 to 0.08591, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.08591 to 0.04796, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04796 to 0.03652, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03652 to 0.02951, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02951 to 0.02594, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02594 to 0.02418, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02418 to 0.02278, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02278 to 0.02143, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02143 to 0.02059, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02059 to 0.01963, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01963 to 0.01902, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01902 to 0.01874, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01874 to 0.01790, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01790 to 0.01738, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01738 to 0.01713, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01713 to 0.01632, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01632 to 0.01561, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01561 to 0.01548, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01548 to 0.01489, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01489 to 0.01450, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01450 to 0.01364, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01364 to 0.01300, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01300 to 0.01269, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01269 to 0.01211, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01211 to 0.01191, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01191 to 0.01171, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01171 to 0.01161, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01161 to 0.01117, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01117 to 0.01069, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.01069 to 0.01000, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01000 to 0.00893, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00893\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00893\n",
      "\n",
      "Epoch 35: loss improved from 0.00893 to 0.00881, saving model to ../result\\lstm_AE_not_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00881\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00881\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00881\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00881\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00881\n",
      "Epoch 40: early stopping\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001A719608040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001A71AA75360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO: [layers, units, batch_size, dropout, look_back, is_ema]\n",
    "num_features = [1,2]\n",
    "layers = [[False, True, True]] # at this file, not effect\n",
    "units = [[64,64,32,16], [64, 128, 64, 32]]\n",
    "config = [num_features, layers, units, [1, 2, 4, 8], [0.2],[10,12,15,17], [False]] \n",
    "df = read_data('../temp_data/influA_vietnam_last_10_days.csv', num_features=1)\n",
    "hist = LSTM_HyperParameter_Tuning(config, df, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(r\"D:\\my_study\\gr3\\DATN\\result\\lstm_AE_ema\\51\\best_lstm_m2m_model.keras\")\n",
    "df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=2)\n",
    "trainX, trainY, testX, testY = prepare_data(df, 17, scaler, is_ema=True)\n",
    "testY_hat = forecast(testX, model)\n",
    "y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "y_inverse = inverse_transform(testY, scaler)\n",
    "plot(y_inverse, y_hat_inverse)\n",
    "# save_plot(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten(), 'abc.png')\n",
    "# model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.092629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(np.sqrt(mean_squared_error(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten())))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
