{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "scaler = MinMaxScaler()\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN, LSTM, TimeDistributed, Input, Dropout, GRU\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tensorflow as tf\n",
    "from keras.saving import register_keras_serializable\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(0, len(dataset)-2 *look_back+1, look_back):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back: i+ 2*look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def exponential_moving_average(data, span):\n",
    "    return data.ewm(span=span, adjust=False).mean()\n",
    "\n",
    "def read_data(file_path, num_features = 1):\n",
    "    from pandas import read_csv\n",
    "    series_influ_A_df = read_csv(file_path, index_col=0, engine='python')\n",
    "    series_influ_A_df = series_influ_A_df.rename(columns= {\"Influenza A - All types of surveillance\": \"case\"})\n",
    "    series_influ_A_df = series_influ_A_df[[\"case\", \"humidity\", \"temp\", \"dew\",\"windspeed\", \"tempmax\",][:num_features]]\n",
    "    return series_influ_A_df.dropna()\n",
    "\n",
    "def prepare_data(series, look_back, scaler, is_ema = False):\n",
    "    if is_ema:\n",
    "        span = 52  # Bạn có thể điều chỉnh độ dài span tùy ý\n",
    "        series['case'] = exponential_moving_average(series['case'], span)\n",
    "    series = series.astype('float32')\n",
    "    series = series.values\n",
    "    if scaler is not None:\n",
    "        flattened_dataset = series.flatten()\n",
    "        dataset = scaler.fit_transform(flattened_dataset.reshape(-1,1))\n",
    "        dataset = dataset.reshape(series.shape)\n",
    "\n",
    "    else: \n",
    "        dataset = series\n",
    "\n",
    "    rest = len(dataset) % look_back\n",
    "    dataset = dataset[rest:, :]\n",
    "    trainsize = len(dataset) - look_back\n",
    "    train = dataset[:trainsize, :]\n",
    "    test = dataset[trainsize - look_back:, :]\n",
    "\n",
    "    trainX, trainY = create_dataset(train, look_back)\n",
    "    testX, testY = create_dataset(test, look_back)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "def forecast(input, model):\n",
    "    predicted = model.predict(input, verbose=0)\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def save_plot(x,y, file_path):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from scipy import stats\n",
    "\n",
    "    # Generate some sample data\n",
    "    # x = y_inverse.flatten()\n",
    "    # y = y_hat_inverse.flatten()\n",
    "\n",
    "    # Compute the linear regression line\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "    # Create the R-squared line\n",
    "    r2_line = slope * x + intercept\n",
    "    r2 = r2_score(x, y)\n",
    "    r2_pearson = r_value**2\n",
    "    squared_error = np.square(x-y)\n",
    "\n",
    "    # Create the scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(x, y, label='Data Points')\n",
    "    plt.plot(x, squared_error, color='red', marker=\"o\", label=f'squared Error (R²={r2:.2f})')\n",
    "\n",
    "    # Add labels and title\n",
    "    plt.xlabel('actual number of infection')\n",
    "    plt.ylabel('forecast number of infection')\n",
    "    plt.title('Scatter Plot with R-squared Line')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()\n",
    "\n",
    "def inverse_transform(data, scaler):\n",
    "    flattened_data = data.flatten()\n",
    "    inverse_flattened_data = scaler.inverse_transform(flattened_data.reshape(-1,1))\n",
    "    return inverse_flattened_data.reshape(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_keras_serializable()\n",
    "class MyLSTM (Sequential):\n",
    "    def __init__(self, look_back, dense_units =[],unit=64, optimizer='adam',name='lstm'):\n",
    "        super().__init__(name=name)\n",
    "        self.look_back = look_back\n",
    "        self.add(Input(shape=(look_back,1)))\n",
    "        self.add(LSTM(units=unit, activation='relu', return_sequences=True))\n",
    "        for unit in dense_units:\n",
    "            self.add(Dense(units=unit, activation='relu'))\n",
    "        self.add(TimeDistributed(Dense(units=5, activation='sigmoid' )))\n",
    "        self.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "\n",
    "def build_model(input_shape, first_additional_layer, second_additional_layer, third_additional_layer, dropout=None, dense_units = [], unit=64, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    # First LSTM layer with Dropout regularisation\n",
    "    model.add(LSTM(units=unit, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Second LSTM layer\n",
    "    if first_additional_layer:\n",
    "        model.add(LSTM(units=unit, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "    # Third LSTM layer\n",
    "    if second_additional_layer:\n",
    "        model.add(GRU(units=unit, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "    # Fourth LSTM layer\n",
    "    if third_additional_layer:\n",
    "        model.add(GRU(units=unit, return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "    # if first_additional_layer:\n",
    "    #     model.add(LSTM(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "\n",
    "    # if second_additional_layer:\n",
    "    #     model.add(LSTM(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "\n",
    "    # if third_additional_layer:\n",
    "    #     model.add(GRU(units=unit, return_sequences=True))\n",
    "    #     model.add(Dropout(dropout))\n",
    "    for unit in dense_units:\n",
    "        model.add(Dense(units=unit, activation='relu'))\n",
    "    model.add(TimeDistributed(Dense(units=input_shape[1], activation='sigmoid' )))\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(testY, forecasts):\n",
    "    import matplotlib.pyplot as plt\n",
    "    forecastsPlot = forecasts[:,:,0].reshape(-1)\n",
    "    testPlot = testY[:,:,0].reshape(-1)\n",
    "    plt.plot(testPlot, \"-y\", label=\"actual\", marker= '.')\n",
    "    plt.plot(forecastsPlot, color = 'green', label=\"forecast\")\n",
    "    plt.ylabel(\"Number of infections\")\n",
    "    plt.legend([\"actual\", \"forecast\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os, json\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def LSTM_HyperParameter_Tuning(config, df, scaler):\n",
    "    \n",
    "    num_features, layers, n_neurons, n_batch_sizes, dropouts, look_backs, is_emas = config\n",
    "    possible_combinations = list(itertools.product(num_features, layers, n_neurons, n_batch_sizes, dropouts, look_backs, is_emas))\n",
    "    \n",
    "    print(possible_combinations)\n",
    "    print('\\n')\n",
    "    \n",
    "    hist = []\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "        print(f'{i+1}th combination: \\n')\n",
    "        print('--------------------------------------------------------------------')\n",
    "        num_features, layers, n_neurons, n_batch_size, dropout, look_back, is_ema = possible_combinations[i]\n",
    "\n",
    "        df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=num_features)\n",
    "        \n",
    "        trainX, trainY, testX, testY = prepare_data(df, look_back, scaler, is_ema=is_ema)\n",
    "        model = build_model(\n",
    "            input_shape=(trainX.shape[1], trainX.shape[2]),\n",
    "            first_additional_layer= layers[0],\n",
    "            second_additional_layer=layers[1],\n",
    "            third_additional_layer=layers[2],\n",
    "            dense_units=n_neurons[1:],\n",
    "            unit=n_neurons[0])\n",
    "\n",
    "        es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=5)\n",
    "        '''''\n",
    "        From the mentioned article above --> If a validation dataset is specified to the fit() function via the validation_data or v\n",
    "        alidation_split arguments,then the loss on the validation dataset will be made available via the name “val_loss.”\n",
    "        '''''\n",
    "        a = 'ema' if is_ema else 'not_ema'\n",
    "        lstm_dir = os.path.join(\"../result\", f\"\"\"lstm_gru_{a}\"\"\")\n",
    "        lstm_combination_dir = os.path.join(lstm_dir, str(i))\n",
    "        os.makedirs(lstm_combination_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(lstm_combination_dir, 'best_lstm_m2m_model.keras')\n",
    "\n",
    "        mc = ModelCheckpoint(file_path, monitor='loss', mode='min', verbose=1, save_best_only=True)\n",
    "\n",
    "        '''''\n",
    "        cb = Callback(...)  # First, callbacks must be instantiated.\n",
    "        cb_list = [cb, ...]  # Then, one or more callbacks that you intend to use must be added to a Python list.\n",
    "        model.fit(..., callbacks=cb_list)  # Finally, the list of callbacks is provided to the callback argument when fitting the model.\n",
    "        '''''\n",
    "\n",
    "        model.fit(trainX, trainY,batch_size=n_batch_size, callbacks=[es, mc], verbose=0, epochs=200)\n",
    "        train_accuracy = model.evaluate(trainX, trainY, verbose=0)\n",
    "        # test_accuracy = model.evaluate(testX, testY, verbose=0)\n",
    "        # hist.append(list((n_neurons, n_batch_size, dropout,look_back,\n",
    "        #                   train_accuracy, test_accuracy)))\n",
    "        hist.append(list((n_neurons, n_batch_size, dropout,look_back,\n",
    "                          train_accuracy)))\n",
    "        \n",
    "        \n",
    "        config= {\n",
    "            \"layers\": layers,\n",
    "            \"units\": n_neurons,\n",
    "            \"n_batch_size\": n_batch_size,\n",
    "            \"dropout\": dropout,\n",
    "            \"look_back\": look_back,\n",
    "            \"is_ema\": is_ema\n",
    "        }\n",
    "        with open(os.path.join(lstm_combination_dir,'config.json'), 'w') as f:\n",
    "            json.dump(config, f)\n",
    "\n",
    "        \n",
    "\n",
    "        # print(f'{str(i)}-th combination = {possible_combinations[i]} \\n train accuracy: {train_accuracy}')\n",
    "        \n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "        # print('--------------------------------------------------------------------')\n",
    "    for i in range(0, len(possible_combinations)):\n",
    "\n",
    "        num_features, layers, n_neurons, n_batch_size, dropout, look_back, is_ema = possible_combinations[i]\n",
    "        df = read_data('../temp_data/influA_vietnam_last_10_days.csv',num_features=num_features)\n",
    "        trainX, trainY, testX, testY = prepare_data(df, look_back, scaler, is_ema=is_ema)\n",
    "\n",
    "        a = 'ema' if is_ema else 'not_ema'\n",
    "        lstm_dir = os.path.join(\"../result\", f\"\"\"lstm_gru_{a}\"\"\")\n",
    "        lstm_combination_dir = os.path.join(lstm_dir, str(i))\n",
    "        os.makedirs(lstm_combination_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(lstm_combination_dir, 'best_lstm_m2m_model.keras')\n",
    "\n",
    "\n",
    "        model = load_model(file_path)\n",
    "\n",
    "        #TODO: save r square\n",
    "        testY_hat = forecast(testX, model)\n",
    "        y_hat_inverse = inverse_transform(testY_hat, scaler)\n",
    "        y_inverse = inverse_transform(testY, scaler)\n",
    "\n",
    "        r2_image_path = os.path.join(lstm_combination_dir, 'r2_image.png')\n",
    "        save_plot(y_inverse[:,:,0].flatten(), y_hat_inverse[:,:,0].flatten(), r2_image_path)\n",
    "        \n",
    "    import pandas as pd\n",
    "    hist_df = pd.DataFrame(hist)\n",
    "    hist_df = hist_df.rename(columns={0: 'units', 1: 'batch_size', 2: 'dropout', 3: 'look_back', 4: 'train_loss'})\n",
    "    hist_df = hist_df.sort_values(by=['train_loss'], ascending=True)\n",
    "    hist_df.to_csv(os.path.join(lstm_dir, 'history.csv'))\n",
    "    return hist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, [False, True, True], [64], 1, 0.2, 10, True), (1, [False, True, True], [64], 1, 0.2, 12, True), (1, [False, True, True], [64], 1, 0.2, 15, True), (1, [False, True, True], [64], 1, 0.2, 17, True), (1, [False, True, True], [64], 2, 0.2, 10, True), (1, [False, True, True], [64], 2, 0.2, 12, True), (1, [False, True, True], [64], 2, 0.2, 15, True), (1, [False, True, True], [64], 2, 0.2, 17, True), (1, [False, True, True], [64], 4, 0.2, 10, True), (1, [False, True, True], [64], 4, 0.2, 12, True), (1, [False, True, True], [64], 4, 0.2, 15, True), (1, [False, True, True], [64], 4, 0.2, 17, True), (1, [False, True, True], [64], 8, 0.2, 10, True), (1, [False, True, True], [64], 8, 0.2, 12, True), (1, [False, True, True], [64], 8, 0.2, 15, True), (1, [False, True, True], [64], 8, 0.2, 17, True), (1, [True, False, True], [64], 1, 0.2, 10, True), (1, [True, False, True], [64], 1, 0.2, 12, True), (1, [True, False, True], [64], 1, 0.2, 15, True), (1, [True, False, True], [64], 1, 0.2, 17, True), (1, [True, False, True], [64], 2, 0.2, 10, True), (1, [True, False, True], [64], 2, 0.2, 12, True), (1, [True, False, True], [64], 2, 0.2, 15, True), (1, [True, False, True], [64], 2, 0.2, 17, True), (1, [True, False, True], [64], 4, 0.2, 10, True), (1, [True, False, True], [64], 4, 0.2, 12, True), (1, [True, False, True], [64], 4, 0.2, 15, True), (1, [True, False, True], [64], 4, 0.2, 17, True), (1, [True, False, True], [64], 8, 0.2, 10, True), (1, [True, False, True], [64], 8, 0.2, 12, True), (1, [True, False, True], [64], 8, 0.2, 15, True), (1, [True, False, True], [64], 8, 0.2, 17, True), (2, [False, True, True], [64], 1, 0.2, 10, True), (2, [False, True, True], [64], 1, 0.2, 12, True), (2, [False, True, True], [64], 1, 0.2, 15, True), (2, [False, True, True], [64], 1, 0.2, 17, True), (2, [False, True, True], [64], 2, 0.2, 10, True), (2, [False, True, True], [64], 2, 0.2, 12, True), (2, [False, True, True], [64], 2, 0.2, 15, True), (2, [False, True, True], [64], 2, 0.2, 17, True), (2, [False, True, True], [64], 4, 0.2, 10, True), (2, [False, True, True], [64], 4, 0.2, 12, True), (2, [False, True, True], [64], 4, 0.2, 15, True), (2, [False, True, True], [64], 4, 0.2, 17, True), (2, [False, True, True], [64], 8, 0.2, 10, True), (2, [False, True, True], [64], 8, 0.2, 12, True), (2, [False, True, True], [64], 8, 0.2, 15, True), (2, [False, True, True], [64], 8, 0.2, 17, True), (2, [True, False, True], [64], 1, 0.2, 10, True), (2, [True, False, True], [64], 1, 0.2, 12, True), (2, [True, False, True], [64], 1, 0.2, 15, True), (2, [True, False, True], [64], 1, 0.2, 17, True), (2, [True, False, True], [64], 2, 0.2, 10, True), (2, [True, False, True], [64], 2, 0.2, 12, True), (2, [True, False, True], [64], 2, 0.2, 15, True), (2, [True, False, True], [64], 2, 0.2, 17, True), (2, [True, False, True], [64], 4, 0.2, 10, True), (2, [True, False, True], [64], 4, 0.2, 12, True), (2, [True, False, True], [64], 4, 0.2, 15, True), (2, [True, False, True], [64], 4, 0.2, 17, True), (2, [True, False, True], [64], 8, 0.2, 10, True), (2, [True, False, True], [64], 8, 0.2, 12, True), (2, [True, False, True], [64], 8, 0.2, 15, True), (2, [True, False, True], [64], 8, 0.2, 17, True)]\n",
      "\n",
      "\n",
      "1th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04453, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04453 to 0.02750, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02750 to 0.02365, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02365 to 0.02040, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02040 to 0.01925, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01925 to 0.01725, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01725 to 0.01616, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01616 to 0.01503, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01503 to 0.01409, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.01409\n",
      "\n",
      "Epoch 11: loss improved from 0.01409 to 0.01353, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01353 to 0.01311, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01311 to 0.01238, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01238\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01238\n",
      "\n",
      "Epoch 16: loss improved from 0.01238 to 0.01197, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01197\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01197\n",
      "\n",
      "Epoch 19: loss improved from 0.01197 to 0.01178, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01178 to 0.01167, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01167\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01167\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01167\n",
      "\n",
      "Epoch 24: loss improved from 0.01167 to 0.01129, saving model to ../result\\lstm_gru_ema\\0\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01129\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01129\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01129\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01129\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01129\n",
      "Epoch 29: early stopping\n",
      "2th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05579, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05579 to 0.03158, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03158 to 0.02538, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02538 to 0.02332, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss did not improve from 0.02332\n",
      "\n",
      "Epoch 6: loss improved from 0.02332 to 0.02101, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02101 to 0.01939, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01939 to 0.01740, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.01740\n",
      "\n",
      "Epoch 10: loss improved from 0.01740 to 0.01592, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.01592\n",
      "\n",
      "Epoch 12: loss improved from 0.01592 to 0.01513, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01513 to 0.01503, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01503 to 0.01381, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01381\n",
      "\n",
      "Epoch 16: loss improved from 0.01381 to 0.01340, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01340\n",
      "\n",
      "Epoch 18: loss improved from 0.01340 to 0.01322, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01322\n",
      "\n",
      "Epoch 20: loss improved from 0.01322 to 0.01300, saving model to ../result\\lstm_gru_ema\\1\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01300\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01300\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01300\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01300\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01300\n",
      "Epoch 25: early stopping\n",
      "3th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05256, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05256 to 0.03336, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03336 to 0.02949, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02949 to 0.02535, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss did not improve from 0.02535\n",
      "\n",
      "Epoch 6: loss improved from 0.02535 to 0.02312, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02312 to 0.02099, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.02099\n",
      "\n",
      "Epoch 9: loss improved from 0.02099 to 0.01861, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.01861\n",
      "\n",
      "Epoch 11: loss improved from 0.01861 to 0.01735, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01735 to 0.01722, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01722 to 0.01665, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01665\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01665\n",
      "\n",
      "Epoch 16: loss improved from 0.01665 to 0.01602, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01602\n",
      "\n",
      "Epoch 18: loss improved from 0.01602 to 0.01571, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01571\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01571\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01571\n",
      "\n",
      "Epoch 22: loss improved from 0.01571 to 0.01497, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01497\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01497\n",
      "\n",
      "Epoch 25: loss improved from 0.01497 to 0.01465, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01465\n",
      "\n",
      "Epoch 27: loss improved from 0.01465 to 0.01460, saving model to ../result\\lstm_gru_ema\\2\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01460\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01460\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01460\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01460\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01460\n",
      "Epoch 32: early stopping\n",
      "4th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05472, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05472 to 0.03723, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03723 to 0.02951, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02951 to 0.02847, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02847 to 0.02741, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02741 to 0.02550, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02550 to 0.02480, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02480 to 0.02398, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02398\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02398\n",
      "\n",
      "Epoch 11: loss improved from 0.02398 to 0.02104, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02104 to 0.01985, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01985 to 0.01970, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01970 to 0.01921, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01921\n",
      "\n",
      "Epoch 16: loss improved from 0.01921 to 0.01892, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01892\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01892\n",
      "\n",
      "Epoch 19: loss improved from 0.01892 to 0.01829, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01829\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01829\n",
      "\n",
      "Epoch 22: loss improved from 0.01829 to 0.01801, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01801 to 0.01782, saving model to ../result\\lstm_gru_ema\\3\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01782\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01782\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01782\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01782\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01782\n",
      "Epoch 28: early stopping\n",
      "5th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06066, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06066 to 0.04277, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04277 to 0.02866, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02866 to 0.02394, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02394 to 0.02353, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02353 to 0.02009, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02009 to 0.01941, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01941 to 0.01739, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01739 to 0.01672, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01672 to 0.01608, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01608 to 0.01532, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01532 to 0.01385, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01385\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01385\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01385\n",
      "\n",
      "Epoch 16: loss improved from 0.01385 to 0.01325, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01325\n",
      "\n",
      "Epoch 18: loss improved from 0.01325 to 0.01271, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01271\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01271\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01271\n",
      "\n",
      "Epoch 22: loss improved from 0.01271 to 0.01145, saving model to ../result\\lstm_gru_ema\\4\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01145\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01145\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01145\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01145\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01145\n",
      "Epoch 27: early stopping\n",
      "6th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05601, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05601 to 0.03323, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03323 to 0.02831, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02831 to 0.02485, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02485 to 0.02278, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02278 to 0.02083, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.02083\n",
      "\n",
      "Epoch 8: loss improved from 0.02083 to 0.01788, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.01788\n",
      "\n",
      "Epoch 10: loss improved from 0.01788 to 0.01646, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.01646\n",
      "\n",
      "Epoch 12: loss improved from 0.01646 to 0.01567, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01567\n",
      "\n",
      "Epoch 14: loss improved from 0.01567 to 0.01501, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01501 to 0.01494, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01494 to 0.01478, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01478 to 0.01456, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01456 to 0.01437, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01437 to 0.01343, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01343\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01343\n",
      "\n",
      "Epoch 22: loss improved from 0.01343 to 0.01259, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01259\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01259\n",
      "\n",
      "Epoch 25: loss improved from 0.01259 to 0.01247, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01247\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01247\n",
      "\n",
      "Epoch 28: loss improved from 0.01247 to 0.01213, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01213\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01213\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01213\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01213\n",
      "\n",
      "Epoch 33: loss improved from 0.01213 to 0.01208, saving model to ../result\\lstm_gru_ema\\5\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01208\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01208\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01208\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01208\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01208\n",
      "Epoch 38: early stopping\n",
      "7th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06624, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06624 to 0.04357, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04357 to 0.03965, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03965 to 0.03090, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03090 to 0.02527, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02527 to 0.02384, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02384 to 0.02185, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.02185\n",
      "\n",
      "Epoch 9: loss improved from 0.02185 to 0.02124, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02124 to 0.01964, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01964 to 0.01926, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.01926\n",
      "\n",
      "Epoch 13: loss improved from 0.01926 to 0.01811, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01811\n",
      "\n",
      "Epoch 15: loss improved from 0.01811 to 0.01722, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01722\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01722\n",
      "\n",
      "Epoch 18: loss improved from 0.01722 to 0.01668, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01668\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01668\n",
      "\n",
      "Epoch 21: loss improved from 0.01668 to 0.01612, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01612\n",
      "\n",
      "Epoch 23: loss improved from 0.01612 to 0.01577, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01577\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01577\n",
      "\n",
      "Epoch 26: loss improved from 0.01577 to 0.01575, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01575\n",
      "\n",
      "Epoch 28: loss improved from 0.01575 to 0.01525, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01525\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01525\n",
      "\n",
      "Epoch 31: loss improved from 0.01525 to 0.01524, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01524 to 0.01513, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01513\n",
      "\n",
      "Epoch 34: loss improved from 0.01513 to 0.01511, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.01511 to 0.01434, saving model to ../result\\lstm_gru_ema\\6\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01434\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01434\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01434\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01434\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01434\n",
      "Epoch 40: early stopping\n",
      "8th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05749, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05749 to 0.03851, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03851 to 0.03453, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03453 to 0.02909, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02909 to 0.02773, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02773 to 0.02482, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.02482\n",
      "\n",
      "Epoch 8: loss improved from 0.02482 to 0.02322, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02322\n",
      "\n",
      "Epoch 10: loss improved from 0.02322 to 0.02176, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02176\n",
      "\n",
      "Epoch 12: loss improved from 0.02176 to 0.02086, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02086\n",
      "\n",
      "Epoch 14: loss improved from 0.02086 to 0.02080, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02080 to 0.01995, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01995\n",
      "\n",
      "Epoch 17: loss improved from 0.01995 to 0.01863, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01863\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01863\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01863\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01863\n",
      "\n",
      "Epoch 22: loss improved from 0.01863 to 0.01719, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01719\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01719\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01719\n",
      "\n",
      "Epoch 26: loss improved from 0.01719 to 0.01706, saving model to ../result\\lstm_gru_ema\\7\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01706\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01706\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01706\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01706\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01706\n",
      "Epoch 31: early stopping\n",
      "9th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06005, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06005 to 0.04254, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04254 to 0.03250, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03250 to 0.03017, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03017 to 0.02357, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02357 to 0.02320, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02320 to 0.02126, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02126 to 0.01996, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01996 to 0.01977, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01977 to 0.01830, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01830 to 0.01819, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01819 to 0.01642, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01642\n",
      "\n",
      "Epoch 14: loss improved from 0.01642 to 0.01573, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01573 to 0.01566, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01566 to 0.01520, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01520\n",
      "\n",
      "Epoch 18: loss improved from 0.01520 to 0.01502, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01502 to 0.01444, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01444\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01444\n",
      "\n",
      "Epoch 22: loss improved from 0.01444 to 0.01336, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01336\n",
      "\n",
      "Epoch 24: loss improved from 0.01336 to 0.01323, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01323\n",
      "\n",
      "Epoch 26: loss improved from 0.01323 to 0.01310, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01310\n",
      "\n",
      "Epoch 28: loss improved from 0.01310 to 0.01299, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01299 to 0.01297, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01297 to 0.01234, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01234\n",
      "\n",
      "Epoch 32: loss improved from 0.01234 to 0.01202, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01202\n",
      "\n",
      "Epoch 34: loss improved from 0.01202 to 0.01179, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01179\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01179\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01179\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01179\n",
      "\n",
      "Epoch 39: loss improved from 0.01179 to 0.01158, saving model to ../result\\lstm_gru_ema\\8\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01158\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01158\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01158\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01158\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01158\n",
      "Epoch 44: early stopping\n",
      "10th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06541, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06541 to 0.04529, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04529 to 0.03419, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03419 to 0.02671, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02671 to 0.02590, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02590 to 0.02361, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02361 to 0.02269, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02269 to 0.02268, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02268 to 0.02039, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02039\n",
      "\n",
      "Epoch 11: loss improved from 0.02039 to 0.01882, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01882 to 0.01823, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01823\n",
      "\n",
      "Epoch 14: loss improved from 0.01823 to 0.01820, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01820 to 0.01717, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01717 to 0.01611, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01611\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01611\n",
      "\n",
      "Epoch 19: loss improved from 0.01611 to 0.01515, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01515 to 0.01495, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01495\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01495\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01495\n",
      "\n",
      "Epoch 24: loss improved from 0.01495 to 0.01421, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01421\n",
      "\n",
      "Epoch 26: loss improved from 0.01421 to 0.01411, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01411 to 0.01339, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01339\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01339\n",
      "\n",
      "Epoch 30: loss improved from 0.01339 to 0.01327, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01327\n",
      "\n",
      "Epoch 32: loss improved from 0.01327 to 0.01306, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01306 to 0.01295, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01295\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01295\n",
      "\n",
      "Epoch 36: loss improved from 0.01295 to 0.01282, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01282\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01282\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01282\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01282\n",
      "\n",
      "Epoch 41: loss improved from 0.01282 to 0.01275, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.01275 to 0.01259, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.01259 to 0.01195, saving model to ../result\\lstm_gru_ema\\9\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01195\n",
      "\n",
      "Epoch 45: loss did not improve from 0.01195\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01195\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01195\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01195\n",
      "Epoch 48: early stopping\n",
      "11th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06728, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06728 to 0.05035, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05035 to 0.04077, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04077 to 0.03440, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03440 to 0.02766, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02766 to 0.02737, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.02737\n",
      "\n",
      "Epoch 8: loss improved from 0.02737 to 0.02482, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02482 to 0.02323, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02323\n",
      "\n",
      "Epoch 11: loss improved from 0.02323 to 0.02237, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02237 to 0.02185, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02185 to 0.02127, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02127 to 0.02018, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02018\n",
      "\n",
      "Epoch 16: loss improved from 0.02018 to 0.01984, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01984\n",
      "\n",
      "Epoch 18: loss improved from 0.01984 to 0.01897, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01897\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01897\n",
      "\n",
      "Epoch 21: loss improved from 0.01897 to 0.01857, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01857 to 0.01756, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01756 to 0.01710, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01710 to 0.01710, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01710\n",
      "\n",
      "Epoch 26: loss improved from 0.01710 to 0.01695, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01695 to 0.01663, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01663 to 0.01645, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01645 to 0.01576, saving model to ../result\\lstm_gru_ema\\10\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01576\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01576\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01576\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01576\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01576\n",
      "Epoch 34: early stopping\n",
      "12th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06925, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06925 to 0.04981, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04981 to 0.04319, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04319 to 0.03563, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03563 to 0.03410, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03410 to 0.02998, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02998 to 0.02721, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02721 to 0.02602, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02602\n",
      "\n",
      "Epoch 10: loss improved from 0.02602 to 0.02463, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02463 to 0.02333, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02333 to 0.02252, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02252\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02252\n",
      "\n",
      "Epoch 15: loss improved from 0.02252 to 0.02156, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02156\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02156\n",
      "\n",
      "Epoch 18: loss improved from 0.02156 to 0.02148, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02148 to 0.02065, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02065\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02065\n",
      "\n",
      "Epoch 22: loss improved from 0.02065 to 0.01990, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01990 to 0.01906, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01906\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01906\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01906\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01906\n",
      "\n",
      "Epoch 28: loss improved from 0.01906 to 0.01800, saving model to ../result\\lstm_gru_ema\\11\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01800\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01800\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01800\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01800\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01800\n",
      "Epoch 33: early stopping\n",
      "13th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07028, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07028 to 0.04915, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04915 to 0.04636, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04636 to 0.03804, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03804 to 0.03344, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03344 to 0.02627, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02627 to 0.02617, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02617 to 0.02377, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02377 to 0.02322, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02322 to 0.02216, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02216 to 0.02123, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02123 to 0.02025, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02025 to 0.01932, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01932 to 0.01869, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01869 to 0.01850, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01850 to 0.01730, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01730 to 0.01686, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01686 to 0.01651, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01651\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01651\n",
      "\n",
      "Epoch 21: loss improved from 0.01651 to 0.01617, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01617 to 0.01561, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.01561 to 0.01549, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01549 to 0.01458, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01458\n",
      "\n",
      "Epoch 26: loss improved from 0.01458 to 0.01412, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01412\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01412\n",
      "\n",
      "Epoch 29: loss improved from 0.01412 to 0.01389, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01389\n",
      "\n",
      "Epoch 31: loss improved from 0.01389 to 0.01359, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01359\n",
      "\n",
      "Epoch 33: loss improved from 0.01359 to 0.01298, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01298\n",
      "\n",
      "Epoch 35: loss improved from 0.01298 to 0.01288, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01288\n",
      "\n",
      "Epoch 37: loss improved from 0.01288 to 0.01262, saving model to ../result\\lstm_gru_ema\\12\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01262\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01262\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01262\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01262\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01262\n",
      "Epoch 42: early stopping\n",
      "14th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07441, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07441 to 0.05766, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05766 to 0.04821, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04821 to 0.04290, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04290 to 0.03773, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03773 to 0.03064, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03064 to 0.02813, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02813 to 0.02564, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02564 to 0.02434, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02434 to 0.02361, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02361 to 0.02264, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02264\n",
      "\n",
      "Epoch 13: loss improved from 0.02264 to 0.02075, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02075 to 0.02048, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02048\n",
      "\n",
      "Epoch 16: loss improved from 0.02048 to 0.01947, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01947 to 0.01816, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01816\n",
      "\n",
      "Epoch 19: loss improved from 0.01816 to 0.01798, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01798 to 0.01733, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01733\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01733\n",
      "\n",
      "Epoch 23: loss improved from 0.01733 to 0.01723, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01723 to 0.01689, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01689 to 0.01680, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01680 to 0.01611, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01611 to 0.01603, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01603\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01603\n",
      "\n",
      "Epoch 30: loss improved from 0.01603 to 0.01586, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.01586 to 0.01561, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01561 to 0.01503, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01503 to 0.01495, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01495\n",
      "\n",
      "Epoch 35: loss improved from 0.01495 to 0.01453, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01453\n",
      "\n",
      "Epoch 37: loss improved from 0.01453 to 0.01428, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01428\n",
      "\n",
      "Epoch 39: loss improved from 0.01428 to 0.01413, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.01413 to 0.01371, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01371\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01371\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01371\n",
      "\n",
      "Epoch 44: loss improved from 0.01371 to 0.01344, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.01344 to 0.01343, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01343\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01343\n",
      "\n",
      "Epoch 48: loss improved from 0.01343 to 0.01335, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01335\n",
      "\n",
      "Epoch 50: loss did not improve from 0.01335\n",
      "\n",
      "Epoch 51: loss improved from 0.01335 to 0.01263, saving model to ../result\\lstm_gru_ema\\13\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss did not improve from 0.01263\n",
      "\n",
      "Epoch 53: loss did not improve from 0.01263\n",
      "\n",
      "Epoch 54: loss did not improve from 0.01263\n",
      "\n",
      "Epoch 55: loss did not improve from 0.01263\n",
      "\n",
      "Epoch 56: loss did not improve from 0.01263\n",
      "Epoch 56: early stopping\n",
      "15th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07237, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07237 to 0.05777, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05777 to 0.04925, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04925 to 0.04462, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04462 to 0.03988, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03988 to 0.03489, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03489 to 0.02762, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.02762\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02762\n",
      "\n",
      "Epoch 10: loss improved from 0.02762 to 0.02597, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02597\n",
      "\n",
      "Epoch 12: loss improved from 0.02597 to 0.02505, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02505 to 0.02366, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02366 to 0.02317, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02317\n",
      "\n",
      "Epoch 16: loss improved from 0.02317 to 0.02262, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02262\n",
      "\n",
      "Epoch 18: loss improved from 0.02262 to 0.02250, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02250\n",
      "\n",
      "Epoch 20: loss improved from 0.02250 to 0.02237, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02237 to 0.02195, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02195 to 0.02101, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02101 to 0.02054, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02054 to 0.02004, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.02004 to 0.02002, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.02002 to 0.01964, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01964 to 0.01906, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01906 to 0.01828, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01828\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01828\n",
      "\n",
      "Epoch 31: loss improved from 0.01828 to 0.01723, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01723\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01723\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01723\n",
      "\n",
      "Epoch 35: loss improved from 0.01723 to 0.01702, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01702\n",
      "\n",
      "Epoch 37: loss improved from 0.01702 to 0.01652, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01652\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01652\n",
      "\n",
      "Epoch 40: loss improved from 0.01652 to 0.01617, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01617\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01617\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01617\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01617\n",
      "\n",
      "Epoch 45: loss improved from 0.01617 to 0.01609, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.01609 to 0.01599, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01599\n",
      "\n",
      "Epoch 48: loss improved from 0.01599 to 0.01592, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01592\n",
      "\n",
      "Epoch 50: loss did not improve from 0.01592\n",
      "\n",
      "Epoch 51: loss did not improve from 0.01592\n",
      "\n",
      "Epoch 52: loss did not improve from 0.01592\n",
      "\n",
      "Epoch 53: loss improved from 0.01592 to 0.01554, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss did not improve from 0.01554\n",
      "\n",
      "Epoch 55: loss improved from 0.01554 to 0.01533, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 56: loss did not improve from 0.01533\n",
      "\n",
      "Epoch 57: loss did not improve from 0.01533\n",
      "\n",
      "Epoch 58: loss improved from 0.01533 to 0.01518, saving model to ../result\\lstm_gru_ema\\14\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.01518\n",
      "\n",
      "Epoch 60: loss did not improve from 0.01518\n",
      "\n",
      "Epoch 61: loss did not improve from 0.01518\n",
      "\n",
      "Epoch 62: loss did not improve from 0.01518\n",
      "\n",
      "Epoch 63: loss did not improve from 0.01518\n",
      "Epoch 63: early stopping\n",
      "16th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07301, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07301 to 0.05907, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05907 to 0.04906, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04906 to 0.04485, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04485 to 0.03970, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03970 to 0.03462, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03462 to 0.03003, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03003 to 0.02897, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02897 to 0.02850, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02850 to 0.02660, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02660 to 0.02594, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02594 to 0.02535, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02535\n",
      "\n",
      "Epoch 14: loss improved from 0.02535 to 0.02397, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02397 to 0.02366, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02366 to 0.02323, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02323\n",
      "\n",
      "Epoch 18: loss did not improve from 0.02323\n",
      "\n",
      "Epoch 19: loss improved from 0.02323 to 0.02166, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02166\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02166\n",
      "\n",
      "Epoch 22: loss improved from 0.02166 to 0.02046, saving model to ../result\\lstm_gru_ema\\15\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02046\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02046\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02046\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02046\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02046\n",
      "Epoch 27: early stopping\n",
      "17th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04871, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04871 to 0.03246, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03246 to 0.02695, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02695 to 0.02421, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02421 to 0.02179, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02179 to 0.01903, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01903 to 0.01835, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01835 to 0.01764, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01764 to 0.01525, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01525 to 0.01457, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01457 to 0.01410, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01410 to 0.01383, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01383 to 0.01382, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01382 to 0.01375, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01375 to 0.01312, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01312 to 0.01234, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01234\n",
      "\n",
      "Epoch 18: loss improved from 0.01234 to 0.01206, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01206 to 0.01201, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01201\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01201\n",
      "\n",
      "Epoch 22: loss improved from 0.01201 to 0.01199, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01199\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01199\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01199\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01199\n",
      "\n",
      "Epoch 27: loss improved from 0.01199 to 0.01153, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01153\n",
      "\n",
      "Epoch 29: loss improved from 0.01153 to 0.01148, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01148\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01148\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01148\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01148\n",
      "\n",
      "Epoch 34: loss improved from 0.01148 to 0.01145, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.01145 to 0.01092, saving model to ../result\\lstm_gru_ema\\16\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01092\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01092\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01092\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01092\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01092\n",
      "Epoch 40: early stopping\n",
      "18th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06332, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06332 to 0.03837, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03837 to 0.02788, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss did not improve from 0.02788\n",
      "\n",
      "Epoch 5: loss improved from 0.02788 to 0.02326, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02326 to 0.02226, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02226 to 0.01949, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.01949\n",
      "\n",
      "Epoch 9: loss improved from 0.01949 to 0.01724, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.01724\n",
      "\n",
      "Epoch 11: loss improved from 0.01724 to 0.01572, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.01572\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01572\n",
      "\n",
      "Epoch 14: loss improved from 0.01572 to 0.01549, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01549 to 0.01496, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01496 to 0.01442, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01442\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01442\n",
      "\n",
      "Epoch 19: loss improved from 0.01442 to 0.01418, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01418 to 0.01317, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01317\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01317\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01317\n",
      "\n",
      "Epoch 24: loss improved from 0.01317 to 0.01283, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01283\n",
      "\n",
      "Epoch 26: loss improved from 0.01283 to 0.01248, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01248\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01248\n",
      "\n",
      "Epoch 29: loss improved from 0.01248 to 0.01185, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01185\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01185\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01185\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01185\n",
      "\n",
      "Epoch 34: loss improved from 0.01185 to 0.01149, saving model to ../result\\lstm_gru_ema\\17\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01149\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01149\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01149\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01149\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01149\n",
      "Epoch 39: early stopping\n",
      "19th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05729, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05729 to 0.04172, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04172 to 0.03072, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03072 to 0.03055, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03055 to 0.02612, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.02612\n",
      "\n",
      "Epoch 7: loss did not improve from 0.02612\n",
      "\n",
      "Epoch 8: loss improved from 0.02612 to 0.02057, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02057 to 0.02046, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02046\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02046\n",
      "\n",
      "Epoch 12: loss improved from 0.02046 to 0.01974, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01974 to 0.01936, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01936 to 0.01823, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01823 to 0.01757, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01757 to 0.01745, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01745 to 0.01689, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01689 to 0.01638, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01638\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01638\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01638\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01638\n",
      "\n",
      "Epoch 23: loss improved from 0.01638 to 0.01603, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01603 to 0.01589, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01589 to 0.01580, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01580 to 0.01570, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01570\n",
      "\n",
      "Epoch 28: loss improved from 0.01570 to 0.01518, saving model to ../result\\lstm_gru_ema\\18\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01518\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01518\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01518\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01518\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01518\n",
      "Epoch 33: early stopping\n",
      "20th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05847, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05847 to 0.04196, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04196 to 0.03573, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03573 to 0.03007, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03007 to 0.02892, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02892 to 0.02563, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.02563\n",
      "\n",
      "Epoch 8: loss did not improve from 0.02563\n",
      "\n",
      "Epoch 9: loss improved from 0.02563 to 0.02527, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02527 to 0.02492, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02492 to 0.02243, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02243\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02243\n",
      "\n",
      "Epoch 14: loss improved from 0.02243 to 0.02181, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02181\n",
      "\n",
      "Epoch 16: loss improved from 0.02181 to 0.02117, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02117 to 0.02027, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02027 to 0.02021, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02021 to 0.01963, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01963\n",
      "\n",
      "Epoch 21: loss improved from 0.01963 to 0.01893, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01893 to 0.01827, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01827\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01827\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01827\n",
      "\n",
      "Epoch 26: loss improved from 0.01827 to 0.01812, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01812\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01812\n",
      "\n",
      "Epoch 29: loss improved from 0.01812 to 0.01804, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01804 to 0.01764, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01764\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01764\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01764\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01764\n",
      "\n",
      "Epoch 35: loss improved from 0.01764 to 0.01755, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss improved from 0.01755 to 0.01702, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01702\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01702\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01702\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01702\n",
      "\n",
      "Epoch 41: loss improved from 0.01702 to 0.01701, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.01701 to 0.01627, saving model to ../result\\lstm_gru_ema\\19\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01627\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01627\n",
      "\n",
      "Epoch 45: loss did not improve from 0.01627\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01627\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01627\n",
      "Epoch 47: early stopping\n",
      "21th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05786, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05786 to 0.04081, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04081 to 0.02752, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02752 to 0.02576, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02576 to 0.02525, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02525 to 0.02290, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02290 to 0.02149, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02149 to 0.01974, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01974 to 0.01851, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01851 to 0.01746, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01746 to 0.01647, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01647 to 0.01581, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01581 to 0.01559, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.01559\n",
      "\n",
      "Epoch 15: loss improved from 0.01559 to 0.01538, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01538 to 0.01531, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01531 to 0.01436, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01436\n",
      "\n",
      "Epoch 19: loss improved from 0.01436 to 0.01348, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01348 to 0.01307, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01307 to 0.01269, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01269\n",
      "\n",
      "Epoch 23: loss improved from 0.01269 to 0.01218, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01218\n",
      "\n",
      "Epoch 25: loss improved from 0.01218 to 0.01205, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.01205 to 0.01184, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01184\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01184\n",
      "\n",
      "Epoch 29: loss improved from 0.01184 to 0.01153, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01153\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01153\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01153\n",
      "\n",
      "Epoch 33: loss improved from 0.01153 to 0.01121, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01121\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01121\n",
      "\n",
      "Epoch 36: loss improved from 0.01121 to 0.01115, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01115\n",
      "\n",
      "Epoch 38: loss improved from 0.01115 to 0.01111, saving model to ../result\\lstm_gru_ema\\20\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01111\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01111\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01111\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01111\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01111\n",
      "Epoch 43: early stopping\n",
      "22th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05648, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05648 to 0.03580, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03580 to 0.02872, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02872 to 0.02766, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02766 to 0.02424, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss did not improve from 0.02424\n",
      "\n",
      "Epoch 7: loss improved from 0.02424 to 0.02195, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02195 to 0.02110, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02110\n",
      "\n",
      "Epoch 10: loss improved from 0.02110 to 0.01967, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.01967\n",
      "\n",
      "Epoch 12: loss improved from 0.01967 to 0.01750, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.01750\n",
      "\n",
      "Epoch 14: loss improved from 0.01750 to 0.01652, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01652\n",
      "\n",
      "Epoch 16: loss improved from 0.01652 to 0.01630, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01630\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01630\n",
      "\n",
      "Epoch 19: loss improved from 0.01630 to 0.01469, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01469\n",
      "\n",
      "Epoch 21: loss improved from 0.01469 to 0.01445, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01445\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01445\n",
      "\n",
      "Epoch 24: loss improved from 0.01445 to 0.01389, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01389\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01389\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01389\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01389\n",
      "\n",
      "Epoch 29: loss improved from 0.01389 to 0.01326, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01326 to 0.01302, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01302\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01302\n",
      "\n",
      "Epoch 33: loss improved from 0.01302 to 0.01206, saving model to ../result\\lstm_gru_ema\\21\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01206\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01206\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01206\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01206\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01206\n",
      "Epoch 38: early stopping\n",
      "23th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06162, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06162 to 0.04295, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04295 to 0.03118, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss did not improve from 0.03118\n",
      "\n",
      "Epoch 5: loss improved from 0.03118 to 0.02798, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02798 to 0.02550, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02550 to 0.02427, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02427 to 0.02352, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02352 to 0.02209, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02209\n",
      "\n",
      "Epoch 11: loss improved from 0.02209 to 0.02158, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02158\n",
      "\n",
      "Epoch 13: loss improved from 0.02158 to 0.01981, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01981 to 0.01915, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01915 to 0.01875, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.01875\n",
      "\n",
      "Epoch 17: loss improved from 0.01875 to 0.01855, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01855 to 0.01765, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01765 to 0.01716, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01716\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01716\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01716\n",
      "\n",
      "Epoch 23: loss improved from 0.01716 to 0.01668, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01668 to 0.01659, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01659 to 0.01624, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01624\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01624\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01624\n",
      "\n",
      "Epoch 29: loss improved from 0.01624 to 0.01564, saving model to ../result\\lstm_gru_ema\\22\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01564\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01564\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01564\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01564\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01564\n",
      "Epoch 34: early stopping\n",
      "24th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05838, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05838 to 0.04520, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04520 to 0.03777, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03777 to 0.03240, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss did not improve from 0.03240\n",
      "\n",
      "Epoch 6: loss improved from 0.03240 to 0.03088, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03088 to 0.03001, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03001 to 0.02866, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02866 to 0.02508, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.02508\n",
      "\n",
      "Epoch 11: loss improved from 0.02508 to 0.02454, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02454 to 0.02381, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02381 to 0.02333, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02333 to 0.02327, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02327 to 0.02213, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02213\n",
      "\n",
      "Epoch 17: loss improved from 0.02213 to 0.02102, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02102 to 0.02083, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02083 to 0.02064, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.02064\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02064\n",
      "\n",
      "Epoch 22: loss did not improve from 0.02064\n",
      "\n",
      "Epoch 23: loss improved from 0.02064 to 0.01926, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.01926 to 0.01879, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01879\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01879\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01879\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01879\n",
      "\n",
      "Epoch 29: loss improved from 0.01879 to 0.01875, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01875 to 0.01788, saving model to ../result\\lstm_gru_ema\\23\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01788\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01788\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01788\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01788\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01788\n",
      "Epoch 35: early stopping\n",
      "25th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06270, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06270 to 0.04526, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04526 to 0.03876, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03876 to 0.03076, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03076 to 0.02848, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02848 to 0.02612, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02612 to 0.02472, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02472 to 0.02320, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02320 to 0.02241, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02241 to 0.02148, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02148 to 0.01989, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01989 to 0.01974, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01974 to 0.01862, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01862 to 0.01726, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.01726\n",
      "\n",
      "Epoch 16: loss improved from 0.01726 to 0.01635, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.01635\n",
      "\n",
      "Epoch 18: loss did not improve from 0.01635\n",
      "\n",
      "Epoch 19: loss improved from 0.01635 to 0.01585, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01585\n",
      "\n",
      "Epoch 21: loss improved from 0.01585 to 0.01583, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.01583 to 0.01541, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01541\n",
      "\n",
      "Epoch 24: loss improved from 0.01541 to 0.01442, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.01442\n",
      "\n",
      "Epoch 26: loss improved from 0.01442 to 0.01409, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.01409 to 0.01385, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01385 to 0.01373, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01373 to 0.01315, saving model to ../result\\lstm_gru_ema\\24\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01315\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01315\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01315\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01315\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01315\n",
      "Epoch 34: early stopping\n",
      "26th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06235, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06235 to 0.04577, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04577 to 0.03393, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03393 to 0.02789, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02789 to 0.02579, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02579 to 0.02559, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.02559\n",
      "\n",
      "Epoch 8: loss improved from 0.02559 to 0.02345, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02345 to 0.02171, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02171 to 0.02160, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02160 to 0.02136, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02136 to 0.02119, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02119 to 0.02049, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02049\n",
      "\n",
      "Epoch 15: loss improved from 0.02049 to 0.01843, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01843 to 0.01819, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01819 to 0.01804, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01804 to 0.01731, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01731 to 0.01703, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01703 to 0.01661, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.01661 to 0.01594, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01594\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01594\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01594\n",
      "\n",
      "Epoch 25: loss improved from 0.01594 to 0.01489, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01489\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01489\n",
      "\n",
      "Epoch 28: loss improved from 0.01489 to 0.01424, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01424\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01424\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01424\n",
      "\n",
      "Epoch 32: loss improved from 0.01424 to 0.01398, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01398 to 0.01397, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01397\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01397\n",
      "\n",
      "Epoch 36: loss improved from 0.01397 to 0.01336, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.01336 to 0.01330, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01330\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01330\n",
      "\n",
      "Epoch 40: loss improved from 0.01330 to 0.01283, saving model to ../result\\lstm_gru_ema\\25\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01283\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01283\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01283\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01283\n",
      "\n",
      "Epoch 45: loss did not improve from 0.01283\n",
      "Epoch 45: early stopping\n",
      "27th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06866, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06866 to 0.05009, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05009 to 0.04271, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04271 to 0.03462, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03462 to 0.03047, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03047 to 0.02963, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02963 to 0.02863, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02863 to 0.02708, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02708 to 0.02550, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02550 to 0.02478, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02478 to 0.02461, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02461 to 0.02358, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02358 to 0.02237, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.02237\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02237\n",
      "\n",
      "Epoch 16: loss improved from 0.02237 to 0.02139, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02139\n",
      "\n",
      "Epoch 18: loss improved from 0.02139 to 0.02090, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02090 to 0.01948, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.01948 to 0.01923, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01923\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01923\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01923\n",
      "\n",
      "Epoch 24: loss improved from 0.01923 to 0.01917, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.01917 to 0.01800, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01800\n",
      "\n",
      "Epoch 27: loss improved from 0.01800 to 0.01745, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.01745\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01745\n",
      "\n",
      "Epoch 30: loss improved from 0.01745 to 0.01707, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01707\n",
      "\n",
      "Epoch 32: loss did not improve from 0.01707\n",
      "\n",
      "Epoch 33: loss improved from 0.01707 to 0.01675, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01675\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01675\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01675\n",
      "\n",
      "Epoch 37: loss improved from 0.01675 to 0.01656, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01656\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01656\n",
      "\n",
      "Epoch 40: loss improved from 0.01656 to 0.01612, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01612\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01612\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01612\n",
      "\n",
      "Epoch 44: loss improved from 0.01612 to 0.01590, saving model to ../result\\lstm_gru_ema\\26\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss did not improve from 0.01590\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01590\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01590\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01590\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01590\n",
      "Epoch 49: early stopping\n",
      "28th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07177, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07177 to 0.05165, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05165 to 0.04475, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04475 to 0.03890, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.03890 to 0.03308, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03308 to 0.03092, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03092 to 0.03029, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03029 to 0.02889, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.02889\n",
      "\n",
      "Epoch 10: loss improved from 0.02889 to 0.02692, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02692 to 0.02652, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02652 to 0.02533, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02533 to 0.02479, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02479 to 0.02417, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02417 to 0.02365, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02365\n",
      "\n",
      "Epoch 17: loss improved from 0.02365 to 0.02266, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02266 to 0.02205, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02205\n",
      "\n",
      "Epoch 20: loss improved from 0.02205 to 0.02133, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02133 to 0.02071, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02071 to 0.02014, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02014\n",
      "\n",
      "Epoch 24: loss did not improve from 0.02014\n",
      "\n",
      "Epoch 25: loss improved from 0.02014 to 0.01984, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01984\n",
      "\n",
      "Epoch 27: loss did not improve from 0.01984\n",
      "\n",
      "Epoch 28: loss improved from 0.01984 to 0.01963, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.01963\n",
      "\n",
      "Epoch 30: loss improved from 0.01963 to 0.01912, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01912\n",
      "\n",
      "Epoch 32: loss improved from 0.01912 to 0.01898, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.01898 to 0.01849, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.01849\n",
      "\n",
      "Epoch 35: loss improved from 0.01849 to 0.01831, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01831\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01831\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01831\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01831\n",
      "\n",
      "Epoch 40: loss improved from 0.01831 to 0.01779, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01779\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01779\n",
      "\n",
      "Epoch 43: loss improved from 0.01779 to 0.01759, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01759\n",
      "\n",
      "Epoch 45: loss improved from 0.01759 to 0.01737, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01737\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01737\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01737\n",
      "\n",
      "Epoch 49: loss improved from 0.01737 to 0.01727, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss did not improve from 0.01727\n",
      "\n",
      "Epoch 51: loss improved from 0.01727 to 0.01704, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss did not improve from 0.01704\n",
      "\n",
      "Epoch 53: loss did not improve from 0.01704\n",
      "\n",
      "Epoch 54: loss improved from 0.01704 to 0.01671, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss did not improve from 0.01671\n",
      "\n",
      "Epoch 56: loss did not improve from 0.01671\n",
      "\n",
      "Epoch 57: loss did not improve from 0.01671\n",
      "\n",
      "Epoch 58: loss improved from 0.01671 to 0.01651, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.01651\n",
      "\n",
      "Epoch 60: loss improved from 0.01651 to 0.01560, saving model to ../result\\lstm_gru_ema\\27\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 61: loss did not improve from 0.01560\n",
      "\n",
      "Epoch 62: loss did not improve from 0.01560\n",
      "\n",
      "Epoch 63: loss did not improve from 0.01560\n",
      "\n",
      "Epoch 64: loss did not improve from 0.01560\n",
      "\n",
      "Epoch 65: loss did not improve from 0.01560\n",
      "Epoch 65: early stopping\n",
      "29th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07238, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07238 to 0.05391, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05391 to 0.04735, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04735 to 0.04108, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04108 to 0.03391, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03391 to 0.03089, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03089 to 0.02879, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02879 to 0.02636, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02636 to 0.02501, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02501 to 0.02466, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02466 to 0.02363, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02363 to 0.02275, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02275 to 0.02206, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02206 to 0.02098, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02098 to 0.02038, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02038 to 0.02000, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02000 to 0.01872, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01872 to 0.01826, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.01826\n",
      "\n",
      "Epoch 20: loss improved from 0.01826 to 0.01702, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.01702\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01702\n",
      "\n",
      "Epoch 23: loss improved from 0.01702 to 0.01639, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01639\n",
      "\n",
      "Epoch 25: loss improved from 0.01639 to 0.01607, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01607\n",
      "\n",
      "Epoch 27: loss improved from 0.01607 to 0.01597, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01597 to 0.01589, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01589 to 0.01511, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01511\n",
      "\n",
      "Epoch 31: loss improved from 0.01511 to 0.01495, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01495 to 0.01476, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01476\n",
      "\n",
      "Epoch 34: loss improved from 0.01476 to 0.01378, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01378\n",
      "\n",
      "Epoch 36: loss improved from 0.01378 to 0.01375, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01375\n",
      "\n",
      "Epoch 38: loss improved from 0.01375 to 0.01365, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.01365 to 0.01311, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01311\n",
      "\n",
      "Epoch 41: loss did not improve from 0.01311\n",
      "\n",
      "Epoch 42: loss improved from 0.01311 to 0.01272, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01272\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01272\n",
      "\n",
      "Epoch 45: loss improved from 0.01272 to 0.01232, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01232\n",
      "\n",
      "Epoch 47: loss did not improve from 0.01232\n",
      "\n",
      "Epoch 48: loss did not improve from 0.01232\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01232\n",
      "\n",
      "Epoch 50: loss improved from 0.01232 to 0.01230, saving model to ../result\\lstm_gru_ema\\28\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss did not improve from 0.01230\n",
      "\n",
      "Epoch 52: loss did not improve from 0.01230\n",
      "\n",
      "Epoch 53: loss did not improve from 0.01230\n",
      "\n",
      "Epoch 54: loss did not improve from 0.01230\n",
      "\n",
      "Epoch 55: loss did not improve from 0.01230\n",
      "Epoch 55: early stopping\n",
      "30th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07322, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07322 to 0.05640, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05640 to 0.05034, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.05034 to 0.04414, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04414 to 0.03746, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.03746 to 0.03102, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03102 to 0.02791, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.02791 to 0.02757, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02757 to 0.02568, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02568 to 0.02504, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.02504 to 0.02496, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.02496 to 0.02293, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.02293\n",
      "\n",
      "Epoch 14: loss improved from 0.02293 to 0.02229, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02229 to 0.02076, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.02076\n",
      "\n",
      "Epoch 17: loss improved from 0.02076 to 0.02046, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02046 to 0.01945, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.01945 to 0.01868, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.01868\n",
      "\n",
      "Epoch 21: loss improved from 0.01868 to 0.01799, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.01799\n",
      "\n",
      "Epoch 23: loss did not improve from 0.01799\n",
      "\n",
      "Epoch 24: loss did not improve from 0.01799\n",
      "\n",
      "Epoch 25: loss improved from 0.01799 to 0.01759, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.01759\n",
      "\n",
      "Epoch 27: loss improved from 0.01759 to 0.01728, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.01728 to 0.01713, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01713 to 0.01677, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.01677 to 0.01623, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.01623\n",
      "\n",
      "Epoch 32: loss improved from 0.01623 to 0.01584, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01584\n",
      "\n",
      "Epoch 34: loss improved from 0.01584 to 0.01551, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.01551 to 0.01493, saving model to ../result\\lstm_gru_ema\\29\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01493\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01493\n",
      "Epoch 40: early stopping\n",
      "31th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07547, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07547 to 0.05492, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05492 to 0.04982, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.04982 to 0.04490, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04490 to 0.04063, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04063 to 0.03507, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.03507 to 0.03205, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03205 to 0.02932, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.02932 to 0.02850, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.02850 to 0.02835, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.02835\n",
      "\n",
      "Epoch 12: loss improved from 0.02835 to 0.02648, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.02648 to 0.02600, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02600 to 0.02449, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.02449\n",
      "\n",
      "Epoch 16: loss improved from 0.02449 to 0.02421, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.02421 to 0.02309, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.02309 to 0.02279, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.02279\n",
      "\n",
      "Epoch 20: loss improved from 0.02279 to 0.02191, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.02191 to 0.02119, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.02119 to 0.02102, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.02102\n",
      "\n",
      "Epoch 24: loss improved from 0.02102 to 0.02006, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02006\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02006\n",
      "\n",
      "Epoch 27: loss did not improve from 0.02006\n",
      "\n",
      "Epoch 28: loss improved from 0.02006 to 0.01939, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.01939 to 0.01923, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.01923\n",
      "\n",
      "Epoch 31: loss improved from 0.01923 to 0.01890, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.01890 to 0.01865, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.01865\n",
      "\n",
      "Epoch 34: loss improved from 0.01865 to 0.01841, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.01841\n",
      "\n",
      "Epoch 36: loss improved from 0.01841 to 0.01813, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.01813 to 0.01753, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01753\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01753\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01753\n",
      "\n",
      "Epoch 41: loss improved from 0.01753 to 0.01721, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01721\n",
      "\n",
      "Epoch 43: loss improved from 0.01721 to 0.01696, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01696\n",
      "\n",
      "Epoch 45: loss did not improve from 0.01696\n",
      "\n",
      "Epoch 46: loss improved from 0.01696 to 0.01691, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.01691 to 0.01647, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.01647 to 0.01647, saving model to ../result\\lstm_gru_ema\\30\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.01647\n",
      "\n",
      "Epoch 50: loss did not improve from 0.01647\n",
      "\n",
      "Epoch 51: loss did not improve from 0.01647\n",
      "\n",
      "Epoch 52: loss did not improve from 0.01647\n",
      "\n",
      "Epoch 53: loss did not improve from 0.01647\n",
      "Epoch 53: early stopping\n",
      "32th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07431, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07431 to 0.06140, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.06140 to 0.05263, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.05263 to 0.04735, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.04735 to 0.04413, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.04413 to 0.04104, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.04104 to 0.03782, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.03782 to 0.03294, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.03294 to 0.03086, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.03086\n",
      "\n",
      "Epoch 11: loss improved from 0.03086 to 0.02992, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.02992\n",
      "\n",
      "Epoch 13: loss improved from 0.02992 to 0.02880, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.02880 to 0.02795, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.02795 to 0.02744, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.02744 to 0.02635, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.02635\n",
      "\n",
      "Epoch 18: loss improved from 0.02635 to 0.02593, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.02593 to 0.02543, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.02543 to 0.02408, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.02408\n",
      "\n",
      "Epoch 22: loss improved from 0.02408 to 0.02305, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.02305 to 0.02267, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.02267 to 0.02201, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.02201\n",
      "\n",
      "Epoch 26: loss did not improve from 0.02201\n",
      "\n",
      "Epoch 27: loss improved from 0.02201 to 0.02156, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.02156\n",
      "\n",
      "Epoch 29: loss improved from 0.02156 to 0.02097, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.02097\n",
      "\n",
      "Epoch 31: loss improved from 0.02097 to 0.02054, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.02054\n",
      "\n",
      "Epoch 33: loss did not improve from 0.02054\n",
      "\n",
      "Epoch 34: loss improved from 0.02054 to 0.02029, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.02029\n",
      "\n",
      "Epoch 36: loss improved from 0.02029 to 0.01955, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.01955\n",
      "\n",
      "Epoch 38: loss did not improve from 0.01955\n",
      "\n",
      "Epoch 39: loss did not improve from 0.01955\n",
      "\n",
      "Epoch 40: loss did not improve from 0.01955\n",
      "\n",
      "Epoch 41: loss improved from 0.01955 to 0.01855, saving model to ../result\\lstm_gru_ema\\31\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.01855\n",
      "\n",
      "Epoch 43: loss did not improve from 0.01855\n",
      "\n",
      "Epoch 44: loss did not improve from 0.01855\n",
      "\n",
      "Epoch 45: loss did not improve from 0.01855\n",
      "\n",
      "Epoch 46: loss did not improve from 0.01855\n",
      "Epoch 46: early stopping\n",
      "33th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.03045, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.03045 to 0.01040, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01040 to 0.00619, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.00619 to 0.00536, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00536 to 0.00499, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00499 to 0.00479, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00479 to 0.00446, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00446 to 0.00443, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.00443\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00443\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00443\n",
      "\n",
      "Epoch 12: loss improved from 0.00443 to 0.00436, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00436 to 0.00432, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00432\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00432\n",
      "\n",
      "Epoch 16: loss improved from 0.00432 to 0.00419, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00419 to 0.00418, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00418\n",
      "\n",
      "Epoch 19: loss improved from 0.00418 to 0.00413, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00413 to 0.00396, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00396\n",
      "\n",
      "Epoch 22: loss improved from 0.00396 to 0.00393, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00393 to 0.00389, saving model to ../result\\lstm_gru_ema\\32\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00389\n",
      "Epoch 28: early stopping\n",
      "34th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.03058, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.03058 to 0.01257, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01257 to 0.00810, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.00810 to 0.00621, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00621 to 0.00541, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00541 to 0.00533, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00533 to 0.00510, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00510 to 0.00502, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00502 to 0.00462, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00462 to 0.00461, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00461\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00461\n",
      "\n",
      "Epoch 13: loss improved from 0.00461 to 0.00458, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00458 to 0.00435, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 17: loss improved from 0.00435 to 0.00430, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00430\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00430\n",
      "\n",
      "Epoch 20: loss improved from 0.00430 to 0.00417, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 23: loss improved from 0.00417 to 0.00393, saving model to ../result\\lstm_gru_ema\\33\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00393\n",
      "Epoch 28: early stopping\n",
      "35th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.03469, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.03469 to 0.01309, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01309 to 0.00926, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.00926 to 0.00716, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00716 to 0.00623, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00623 to 0.00532, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss did not improve from 0.00532\n",
      "\n",
      "Epoch 8: loss did not improve from 0.00532\n",
      "\n",
      "Epoch 9: loss improved from 0.00532 to 0.00503, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00503\n",
      "\n",
      "Epoch 11: loss improved from 0.00503 to 0.00477, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00477\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00477\n",
      "\n",
      "Epoch 14: loss improved from 0.00477 to 0.00469, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00469 to 0.00455, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00455\n",
      "\n",
      "Epoch 17: loss improved from 0.00455 to 0.00435, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 22: loss improved from 0.00435 to 0.00421, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00421 to 0.00417, saving model to ../result\\lstm_gru_ema\\34\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00417\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00417\n",
      "Epoch 28: early stopping\n",
      "36th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.03784, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.03784 to 0.01145, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01145 to 0.00833, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.00833 to 0.00724, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00724 to 0.00598, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00598 to 0.00563, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00563 to 0.00546, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00546 to 0.00518, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00518 to 0.00502, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00502 to 0.00486, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 13: loss improved from 0.00486 to 0.00460, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00460\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00460\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00460\n",
      "\n",
      "Epoch 17: loss improved from 0.00460 to 0.00455, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00455 to 0.00451, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00451 to 0.00446, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00446\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00446\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00446\n",
      "\n",
      "Epoch 23: loss improved from 0.00446 to 0.00439, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00439 to 0.00421, saving model to ../result\\lstm_gru_ema\\35\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00421\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00421\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00421\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00421\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00421\n",
      "Epoch 29: early stopping\n",
      "37th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04564, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04564 to 0.01561, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01561 to 0.01199, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01199 to 0.00878, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00878 to 0.00632, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00632 to 0.00555, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00555 to 0.00529, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00529 to 0.00521, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00521 to 0.00500, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00500 to 0.00490, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00490 to 0.00485, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00485 to 0.00464, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00464 to 0.00455, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00455\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00455\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00455\n",
      "\n",
      "Epoch 17: loss improved from 0.00455 to 0.00451, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00451 to 0.00448, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00448\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00448\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00448\n",
      "\n",
      "Epoch 22: loss improved from 0.00448 to 0.00435, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00435 to 0.00415, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00415\n",
      "\n",
      "Epoch 25: loss improved from 0.00415 to 0.00404, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00404\n",
      "\n",
      "Epoch 30: loss improved from 0.00404 to 0.00403, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00403 to 0.00400, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00400 to 0.00387, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00387\n",
      "\n",
      "Epoch 37: loss improved from 0.00387 to 0.00383, saving model to ../result\\lstm_gru_ema\\36\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00383\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00383\n",
      "Epoch 42: early stopping\n",
      "38th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04885, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04885 to 0.01531, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01531 to 0.01311, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01311 to 0.01163, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01163 to 0.00927, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00927 to 0.00660, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00660 to 0.00592, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00592 to 0.00584, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00584 to 0.00517, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00517 to 0.00508, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00508 to 0.00482, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00482\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00482\n",
      "\n",
      "Epoch 14: loss improved from 0.00482 to 0.00467, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00467\n",
      "\n",
      "Epoch 16: loss improved from 0.00467 to 0.00452, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00452\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00452\n",
      "\n",
      "Epoch 19: loss improved from 0.00452 to 0.00445, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 21: loss improved from 0.00445 to 0.00437, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 23: loss improved from 0.00437 to 0.00419, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 25: loss improved from 0.00419 to 0.00411, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00411\n",
      "\n",
      "Epoch 27: loss improved from 0.00411 to 0.00402, saving model to ../result\\lstm_gru_ema\\37\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00402\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00402\n",
      "Epoch 32: early stopping\n",
      "39th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05460, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05460 to 0.01791, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01791 to 0.01386, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01386 to 0.01243, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01243 to 0.01152, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01152 to 0.01106, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01106 to 0.00877, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00877 to 0.00716, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00716 to 0.00592, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00592 to 0.00580, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00580 to 0.00579, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00579 to 0.00561, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00561 to 0.00531, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00531\n",
      "\n",
      "Epoch 15: loss improved from 0.00531 to 0.00511, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00511 to 0.00504, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00504\n",
      "\n",
      "Epoch 18: loss improved from 0.00504 to 0.00473, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00473\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00473\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00473\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00473\n",
      "\n",
      "Epoch 23: loss improved from 0.00473 to 0.00454, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 25: loss improved from 0.00454 to 0.00452, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00452\n",
      "\n",
      "Epoch 27: loss improved from 0.00452 to 0.00445, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 29: loss improved from 0.00445 to 0.00436, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00436 to 0.00434, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00434\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00434\n",
      "\n",
      "Epoch 33: loss improved from 0.00434 to 0.00426, saving model to ../result\\lstm_gru_ema\\38\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00426\n",
      "Epoch 38: early stopping\n",
      "40th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05068, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05068 to 0.01762, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01762 to 0.01410, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01410 to 0.01166, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01166 to 0.00914, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00914 to 0.00794, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00794 to 0.00712, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00712 to 0.00636, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00636 to 0.00586, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00586 to 0.00551, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00551 to 0.00538, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00538 to 0.00537, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00537 to 0.00535, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00535 to 0.00492, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00492\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00492\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00492\n",
      "\n",
      "Epoch 18: loss improved from 0.00492 to 0.00479, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00479 to 0.00475, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00475 to 0.00456, saving model to ../result\\lstm_gru_ema\\39\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00456\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00456\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00456\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00456\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00456\n",
      "Epoch 25: early stopping\n",
      "41th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06628, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06628 to 0.02106, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02106 to 0.01544, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01544 to 0.01290, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01290 to 0.01123, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01123 to 0.00994, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00994 to 0.00842, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00842 to 0.00653, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00653 to 0.00587, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00587 to 0.00531, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00531 to 0.00506, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00506\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00506\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00506\n",
      "\n",
      "Epoch 15: loss improved from 0.00506 to 0.00488, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00488 to 0.00478, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00478 to 0.00466, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00466\n",
      "\n",
      "Epoch 19: loss improved from 0.00466 to 0.00445, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 24: loss improved from 0.00445 to 0.00442, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 27: loss improved from 0.00442 to 0.00425, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00425 to 0.00425, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00425\n",
      "\n",
      "Epoch 30: loss improved from 0.00425 to 0.00406, saving model to ../result\\lstm_gru_ema\\40\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00406\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00406\n",
      "Epoch 35: early stopping\n",
      "42th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07021, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07021 to 0.02193, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02193 to 0.01609, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01609 to 0.01429, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01429 to 0.01272, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01272 to 0.01147, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01147 to 0.00951, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00951 to 0.00761, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00761 to 0.00689, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00689 to 0.00650, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00650 to 0.00618, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00618 to 0.00565, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00565 to 0.00552, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00552 to 0.00505, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00505\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00505\n",
      "\n",
      "Epoch 17: loss improved from 0.00505 to 0.00497, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00497 to 0.00490, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00490 to 0.00469, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00469 to 0.00468, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00468 to 0.00465, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00465 to 0.00455, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00455\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00455\n",
      "\n",
      "Epoch 25: loss improved from 0.00455 to 0.00442, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 30: loss improved from 0.00442 to 0.00429, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00429\n",
      "\n",
      "Epoch 32: loss improved from 0.00429 to 0.00420, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 34: loss improved from 0.00420 to 0.00411, saving model to ../result\\lstm_gru_ema\\41\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00411\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00411\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00411\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00411\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00411\n",
      "Epoch 39: early stopping\n",
      "43th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07781, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07781 to 0.02346, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02346 to 0.01814, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01814 to 0.01442, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01442 to 0.01264, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01264 to 0.01095, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01095 to 0.00937, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00937 to 0.00869, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00869 to 0.00799, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00799 to 0.00755, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00755 to 0.00701, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00701 to 0.00635, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00635 to 0.00602, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00602 to 0.00578, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00578 to 0.00551, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00551 to 0.00531, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00531 to 0.00524, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00524\n",
      "\n",
      "Epoch 19: loss improved from 0.00524 to 0.00507, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00507 to 0.00484, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 22: loss improved from 0.00484 to 0.00478, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00478 to 0.00473, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00473\n",
      "\n",
      "Epoch 25: loss improved from 0.00473 to 0.00466, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00466\n",
      "\n",
      "Epoch 27: loss improved from 0.00466 to 0.00461, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00461 to 0.00447, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 31: loss improved from 0.00447 to 0.00431, saving model to ../result\\lstm_gru_ema\\42\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00431\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00431\n",
      "Epoch 36: early stopping\n",
      "44th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.09202, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.09202 to 0.02486, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02486 to 0.01834, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01834 to 0.01555, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01555 to 0.01429, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01429 to 0.01273, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01273 to 0.01182, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01182 to 0.01024, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01024 to 0.00912, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00912 to 0.00845, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00845 to 0.00755, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00755 to 0.00720, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00720 to 0.00701, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00701 to 0.00673, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00673 to 0.00621, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00621 to 0.00584, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00584 to 0.00575, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00575 to 0.00554, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00554\n",
      "\n",
      "Epoch 20: loss improved from 0.00554 to 0.00551, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00551 to 0.00520, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00520\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00520\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00520\n",
      "\n",
      "Epoch 25: loss improved from 0.00520 to 0.00515, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00515 to 0.00490, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00490 to 0.00490, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00490\n",
      "\n",
      "Epoch 29: loss improved from 0.00490 to 0.00472, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 33: loss improved from 0.00472 to 0.00447, saving model to ../result\\lstm_gru_ema\\43\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00447\n",
      "Epoch 38: early stopping\n",
      "45th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.09873, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.09873 to 0.03259, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03259 to 0.02422, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02422 to 0.01913, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01913 to 0.01668, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01668 to 0.01461, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01461 to 0.01372, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01372 to 0.01276, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01276 to 0.01214, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01214 to 0.01112, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01112 to 0.01039, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01039 to 0.00929, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00929 to 0.00758, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00758 to 0.00687, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00687 to 0.00629, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00629 to 0.00597, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00597 to 0.00549, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00549\n",
      "\n",
      "Epoch 20: loss improved from 0.00549 to 0.00529, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00529 to 0.00523, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00523 to 0.00510, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00510 to 0.00483, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00483 to 0.00472, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00472 to 0.00468, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00468\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00468\n",
      "\n",
      "Epoch 28: loss improved from 0.00468 to 0.00455, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00455 to 0.00451, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00451\n",
      "\n",
      "Epoch 31: loss improved from 0.00451 to 0.00444, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00444\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00444\n",
      "\n",
      "Epoch 34: loss improved from 0.00444 to 0.00427, saving model to ../result\\lstm_gru_ema\\44\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00427\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00427\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00427\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00427\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00427\n",
      "Epoch 39: early stopping\n",
      "46th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10025, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.10025 to 0.03707, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03707 to 0.02363, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02363 to 0.01950, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01950 to 0.01807, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01807 to 0.01579, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01579 to 0.01478, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01478 to 0.01396, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01396 to 0.01324, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01324 to 0.01279, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01279 to 0.01193, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01193 to 0.01180, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01180 to 0.01132, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01132 to 0.01016, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01016 to 0.00980, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00980 to 0.00857, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00857 to 0.00752, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00752 to 0.00689, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00689 to 0.00651, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00651 to 0.00611, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00611 to 0.00595, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00595 to 0.00579, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00579 to 0.00546, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00546 to 0.00529, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00529\n",
      "\n",
      "Epoch 26: loss improved from 0.00529 to 0.00502, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00502\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00502\n",
      "\n",
      "Epoch 29: loss improved from 0.00502 to 0.00494, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00494 to 0.00488, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 32: loss improved from 0.00488 to 0.00467, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00467 to 0.00464, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00464\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00464\n",
      "\n",
      "Epoch 36: loss improved from 0.00464 to 0.00446, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00446 to 0.00442, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 42: loss improved from 0.00442 to 0.00436, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 44: loss improved from 0.00436 to 0.00432, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00432 to 0.00429, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00429\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00429\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00429\n",
      "\n",
      "Epoch 49: loss improved from 0.00429 to 0.00426, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 54: loss improved from 0.00426 to 0.00420, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 57: loss improved from 0.00420 to 0.00408, saving model to ../result\\lstm_gru_ema\\45\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 60: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00408\n",
      "\n",
      "Epoch 62: loss did not improve from 0.00408\n",
      "Epoch 62: early stopping\n",
      "47th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11052, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11052 to 0.03983, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03983 to 0.02318, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02318 to 0.01950, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01950 to 0.01794, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01794 to 0.01621, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01621 to 0.01557, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01557 to 0.01471, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01471 to 0.01401, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01401 to 0.01354, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01354 to 0.01272, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.01272\n",
      "\n",
      "Epoch 13: loss improved from 0.01272 to 0.01199, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01199 to 0.01158, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01158 to 0.01099, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01099 to 0.01024, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01024 to 0.00884, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00884 to 0.00843, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00843 to 0.00780, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00780 to 0.00743, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00743 to 0.00713, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00713\n",
      "\n",
      "Epoch 23: loss improved from 0.00713 to 0.00665, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00665 to 0.00616, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00616 to 0.00614, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00614 to 0.00592, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00592 to 0.00591, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00591 to 0.00575, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00575 to 0.00562, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00562 to 0.00556, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00556 to 0.00546, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00546 to 0.00522, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00522\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00522\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00522\n",
      "\n",
      "Epoch 36: loss improved from 0.00522 to 0.00501, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00501\n",
      "\n",
      "Epoch 38: loss improved from 0.00501 to 0.00499, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00499 to 0.00496, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00496\n",
      "\n",
      "Epoch 41: loss improved from 0.00496 to 0.00488, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00488 to 0.00481, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00481 to 0.00467, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00467 to 0.00458, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00458\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00458\n",
      "\n",
      "Epoch 47: loss improved from 0.00458 to 0.00454, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 51: loss improved from 0.00454 to 0.00450, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00450\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00450\n",
      "\n",
      "Epoch 54: loss improved from 0.00450 to 0.00444, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00444\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00444\n",
      "\n",
      "Epoch 57: loss improved from 0.00444 to 0.00443, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 58: loss improved from 0.00443 to 0.00430, saving model to ../result\\lstm_gru_ema\\46\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00430\n",
      "\n",
      "Epoch 60: loss did not improve from 0.00430\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00430\n",
      "\n",
      "Epoch 62: loss did not improve from 0.00430\n",
      "\n",
      "Epoch 63: loss did not improve from 0.00430\n",
      "Epoch 63: early stopping\n",
      "48th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11414, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11414 to 0.04840, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04840 to 0.02320, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02320 to 0.02162, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02162 to 0.01750, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01750 to 0.01630, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01630 to 0.01487, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01487 to 0.01424, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01424 to 0.01313, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01313 to 0.01278, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01278 to 0.01198, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01198 to 0.01132, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01132 to 0.01040, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01040 to 0.00983, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00983 to 0.00879, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00879 to 0.00839, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00839\n",
      "\n",
      "Epoch 18: loss improved from 0.00839 to 0.00772, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00772 to 0.00752, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00752\n",
      "\n",
      "Epoch 21: loss improved from 0.00752 to 0.00702, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00702 to 0.00685, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00685 to 0.00654, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00654 to 0.00629, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00629 to 0.00613, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00613 to 0.00589, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00589\n",
      "\n",
      "Epoch 28: loss improved from 0.00589 to 0.00572, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00572\n",
      "\n",
      "Epoch 30: loss improved from 0.00572 to 0.00569, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00569 to 0.00556, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00556 to 0.00532, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00532 to 0.00524, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00524\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00524\n",
      "\n",
      "Epoch 36: loss improved from 0.00524 to 0.00513, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00513 to 0.00503, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00503 to 0.00496, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00496\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00496\n",
      "\n",
      "Epoch 41: loss improved from 0.00496 to 0.00488, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00488\n",
      "\n",
      "Epoch 44: loss improved from 0.00488 to 0.00485, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00485 to 0.00485, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00485 to 0.00474, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss improved from 0.00474 to 0.00469, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss improved from 0.00469 to 0.00454, saving model to ../result\\lstm_gru_ema\\47\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00454\n",
      "Epoch 53: early stopping\n",
      "49th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.03373, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.03373 to 0.01368, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01368 to 0.01042, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01042 to 0.00844, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00844 to 0.00567, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00567 to 0.00541, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00541 to 0.00484, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 9: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00484\n",
      "\n",
      "Epoch 11: loss improved from 0.00484 to 0.00481, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss did not improve from 0.00481\n",
      "\n",
      "Epoch 13: loss improved from 0.00481 to 0.00460, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00460 to 0.00452, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00452 to 0.00445, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00445 to 0.00437, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00437\n",
      "\n",
      "Epoch 19: loss improved from 0.00437 to 0.00431, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00431 to 0.00407, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00407 to 0.00395, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00395\n",
      "\n",
      "Epoch 24: loss improved from 0.00395 to 0.00394, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00394\n",
      "\n",
      "Epoch 26: loss improved from 0.00394 to 0.00393, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00393\n",
      "\n",
      "Epoch 29: loss improved from 0.00393 to 0.00390, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00390\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00390\n",
      "\n",
      "Epoch 32: loss improved from 0.00390 to 0.00386, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss improved from 0.00386 to 0.00378, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00378\n",
      "\n",
      "Epoch 36: loss improved from 0.00378 to 0.00377, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00377 to 0.00361, saving model to ../result\\lstm_gru_ema\\48\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00361\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00361\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00361\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00361\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00361\n",
      "Epoch 42: early stopping\n",
      "50th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.03758, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.03758 to 0.01420, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01420 to 0.00943, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.00943 to 0.00714, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00714 to 0.00588, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00588 to 0.00534, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00534 to 0.00511, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00511 to 0.00494, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00494 to 0.00477, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00477 to 0.00459, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss did not improve from 0.00459\n",
      "\n",
      "Epoch 12: loss improved from 0.00459 to 0.00449, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00449\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00449\n",
      "\n",
      "Epoch 15: loss improved from 0.00449 to 0.00449, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00449 to 0.00447, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00447 to 0.00442, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00442\n",
      "\n",
      "Epoch 19: loss improved from 0.00442 to 0.00422, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00422 to 0.00419, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 23: loss improved from 0.00419 to 0.00411, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00411\n",
      "\n",
      "Epoch 25: loss improved from 0.00411 to 0.00407, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00407\n",
      "\n",
      "Epoch 27: loss improved from 0.00407 to 0.00392, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00392\n",
      "\n",
      "Epoch 30: loss improved from 0.00392 to 0.00389, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 35: loss improved from 0.00389 to 0.00389, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00389\n",
      "\n",
      "Epoch 38: loss improved from 0.00389 to 0.00387, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss improved from 0.00387 to 0.00382, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss improved from 0.00382 to 0.00379, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00379\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00379\n",
      "\n",
      "Epoch 43: loss improved from 0.00379 to 0.00373, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00373\n",
      "\n",
      "Epoch 47: loss improved from 0.00373 to 0.00370, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00370\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00370\n",
      "\n",
      "Epoch 50: loss improved from 0.00370 to 0.00363, saving model to ../result\\lstm_gru_ema\\49\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00363\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00363\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00363\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00363\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00363\n",
      "Epoch 55: early stopping\n",
      "51th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04270, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04270 to 0.01661, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01661 to 0.01291, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01291 to 0.01045, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01045 to 0.00751, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00751 to 0.00687, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00687 to 0.00601, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00601 to 0.00529, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.00529\n",
      "\n",
      "Epoch 10: loss improved from 0.00529 to 0.00514, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00514 to 0.00494, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00494 to 0.00469, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00469 to 0.00461, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00461\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00461\n",
      "\n",
      "Epoch 16: loss improved from 0.00461 to 0.00447, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 18: loss improved from 0.00447 to 0.00426, saving model to ../result\\lstm_gru_ema\\50\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00426\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00426\n",
      "Epoch 23: early stopping\n",
      "52th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.04008, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.04008 to 0.01563, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01563 to 0.01366, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01366 to 0.00933, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.00933 to 0.00756, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00756 to 0.00670, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00670 to 0.00614, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00614 to 0.00555, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss did not improve from 0.00555\n",
      "\n",
      "Epoch 10: loss improved from 0.00555 to 0.00500, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00500 to 0.00499, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00499 to 0.00498, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00498 to 0.00478, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 17: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 18: loss improved from 0.00478 to 0.00456, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00456 to 0.00447, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00447\n",
      "\n",
      "Epoch 23: loss improved from 0.00447 to 0.00441, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 26: loss improved from 0.00441 to 0.00424, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00424\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00424\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00424\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00424\n",
      "\n",
      "Epoch 31: loss improved from 0.00424 to 0.00418, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00418\n",
      "\n",
      "Epoch 33: loss improved from 0.00418 to 0.00413, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00413\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00413\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00413\n",
      "\n",
      "Epoch 37: loss improved from 0.00413 to 0.00403, saving model to ../result\\lstm_gru_ema\\51\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00403\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00403\n",
      "Epoch 42: early stopping\n",
      "53th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05475, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05475 to 0.01784, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01784 to 0.01424, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01424 to 0.01205, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01205 to 0.01032, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01032 to 0.00940, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00940 to 0.00689, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00689 to 0.00573, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00573 to 0.00511, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss did not improve from 0.00511\n",
      "\n",
      "Epoch 11: loss improved from 0.00511 to 0.00506, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00506 to 0.00486, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 15: loss improved from 0.00486 to 0.00477, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00477\n",
      "\n",
      "Epoch 17: loss improved from 0.00477 to 0.00476, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00476 to 0.00464, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00464 to 0.00458, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00458 to 0.00455, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00455 to 0.00441, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00441\n",
      "\n",
      "Epoch 25: loss improved from 0.00441 to 0.00436, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00436 to 0.00422, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00422\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00422\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00422\n",
      "\n",
      "Epoch 30: loss improved from 0.00422 to 0.00401, saving model to ../result\\lstm_gru_ema\\52\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00401\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00401\n",
      "Epoch 35: early stopping\n",
      "54th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05626, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05626 to 0.01926, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01926 to 0.01448, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01448 to 0.01210, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01210 to 0.00969, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.00969 to 0.00730, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.00730 to 0.00649, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00649 to 0.00606, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00606 to 0.00565, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00565 to 0.00542, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00542 to 0.00514, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00514 to 0.00514, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00514 to 0.00512, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00512 to 0.00497, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00497 to 0.00474, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00474\n",
      "\n",
      "Epoch 17: loss improved from 0.00474 to 0.00463, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00463\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00463\n",
      "\n",
      "Epoch 20: loss improved from 0.00463 to 0.00444, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00444 to 0.00435, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00435\n",
      "\n",
      "Epoch 26: loss improved from 0.00435 to 0.00418, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00418\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00418\n",
      "\n",
      "Epoch 29: loss improved from 0.00418 to 0.00416, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00416 to 0.00410, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00410 to 0.00397, saving model to ../result\\lstm_gru_ema\\53\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00397\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00397\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00397\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00397\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00397\n",
      "Epoch 36: early stopping\n",
      "55th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.05358, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.05358 to 0.01951, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.01951 to 0.01563, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01563 to 0.01416, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01416 to 0.01294, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01294 to 0.01172, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01172 to 0.01111, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01111 to 0.00898, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00898 to 0.00754, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00754 to 0.00628, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00628 to 0.00602, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00602 to 0.00578, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00578 to 0.00559, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00559 to 0.00518, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss did not improve from 0.00518\n",
      "\n",
      "Epoch 16: loss improved from 0.00518 to 0.00509, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00509 to 0.00492, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00492\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00492\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00492\n",
      "\n",
      "Epoch 21: loss improved from 0.00492 to 0.00487, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00487 to 0.00478, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 24: loss improved from 0.00478 to 0.00472, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00472\n",
      "\n",
      "Epoch 27: loss improved from 0.00472 to 0.00459, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00459 to 0.00457, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00457\n",
      "\n",
      "Epoch 30: loss improved from 0.00457 to 0.00454, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00454\n",
      "\n",
      "Epoch 33: loss improved from 0.00454 to 0.00436, saving model to ../result\\lstm_gru_ema\\54\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00436\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00436\n",
      "Epoch 38: early stopping\n",
      "56th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06489, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06489 to 0.02085, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02085 to 0.01676, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01676 to 0.01486, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01486 to 0.01353, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01353 to 0.01234, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01234 to 0.01130, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss did not improve from 0.01130\n",
      "\n",
      "Epoch 9: loss improved from 0.01130 to 0.01005, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01005 to 0.00821, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00821 to 0.00700, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00700 to 0.00642, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00642 to 0.00620, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00620 to 0.00587, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00587 to 0.00547, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00547\n",
      "\n",
      "Epoch 17: loss improved from 0.00547 to 0.00529, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00529 to 0.00511, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00511\n",
      "\n",
      "Epoch 20: loss improved from 0.00511 to 0.00496, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00496\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00496\n",
      "\n",
      "Epoch 23: loss improved from 0.00496 to 0.00494, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 26: loss improved from 0.00494 to 0.00479, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00479 to 0.00467, saving model to ../result\\lstm_gru_ema\\55\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00467\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00467\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00467\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00467\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00467\n",
      "Epoch 32: early stopping\n",
      "57th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.06764, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.06764 to 0.02721, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02721 to 0.01892, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.01892 to 0.01527, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01527 to 0.01256, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01256 to 0.01069, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01069 to 0.00866, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.00866 to 0.00727, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.00727 to 0.00655, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00655 to 0.00602, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00602 to 0.00559, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00559 to 0.00544, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00544 to 0.00509, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss did not improve from 0.00509\n",
      "\n",
      "Epoch 15: loss improved from 0.00509 to 0.00485, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00485\n",
      "\n",
      "Epoch 17: loss improved from 0.00485 to 0.00478, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00478\n",
      "\n",
      "Epoch 20: loss improved from 0.00478 to 0.00463, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00463\n",
      "\n",
      "Epoch 22: loss improved from 0.00463 to 0.00459, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00459 to 0.00450, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss did not improve from 0.00450\n",
      "\n",
      "Epoch 25: loss improved from 0.00450 to 0.00440, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00440 to 0.00420, saving model to ../result\\lstm_gru_ema\\56\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00420\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00420\n",
      "Epoch 31: early stopping\n",
      "58th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.07578, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.07578 to 0.02828, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02828 to 0.02043, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02043 to 0.01658, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01658 to 0.01476, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01476 to 0.01316, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01316 to 0.01224, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01224 to 0.01115, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01115 to 0.00948, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.00948 to 0.00820, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00820 to 0.00739, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00739 to 0.00657, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00657 to 0.00635, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00635 to 0.00584, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00584 to 0.00547, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss did not improve from 0.00547\n",
      "\n",
      "Epoch 17: loss improved from 0.00547 to 0.00527, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00527 to 0.00508, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss did not improve from 0.00508\n",
      "\n",
      "Epoch 20: loss did not improve from 0.00508\n",
      "\n",
      "Epoch 21: loss did not improve from 0.00508\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00508\n",
      "\n",
      "Epoch 23: loss improved from 0.00508 to 0.00497, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00497 to 0.00489, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00489 to 0.00480, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 28: loss did not improve from 0.00480\n",
      "\n",
      "Epoch 29: loss improved from 0.00480 to 0.00471, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00471 to 0.00469, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00469 to 0.00469, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00469 to 0.00419, saving model to ../result\\lstm_gru_ema\\57\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00419\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00419\n",
      "Epoch 37: early stopping\n",
      "59th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.09000, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.09000 to 0.02860, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.02860 to 0.02103, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02103 to 0.01797, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01797 to 0.01638, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01638 to 0.01478, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01478 to 0.01380, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01380 to 0.01176, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01176 to 0.01053, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01053 to 0.00949, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.00949 to 0.00903, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.00903 to 0.00810, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.00810 to 0.00779, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00779 to 0.00747, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00747 to 0.00693, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00693 to 0.00665, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00665 to 0.00638, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00638 to 0.00622, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00622 to 0.00601, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00601 to 0.00581, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00581 to 0.00556, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss did not improve from 0.00556\n",
      "\n",
      "Epoch 23: loss improved from 0.00556 to 0.00537, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00537 to 0.00519, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00519\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00519\n",
      "\n",
      "Epoch 27: loss improved from 0.00519 to 0.00505, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00505 to 0.00493, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00493 to 0.00475, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00475\n",
      "\n",
      "Epoch 33: loss improved from 0.00475 to 0.00465, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00465 to 0.00456, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00456\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00456\n",
      "\n",
      "Epoch 37: loss improved from 0.00456 to 0.00443, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00443\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00443\n",
      "\n",
      "Epoch 40: loss improved from 0.00443 to 0.00440, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00440\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00440\n",
      "\n",
      "Epoch 43: loss improved from 0.00440 to 0.00428, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 47: loss improved from 0.00428 to 0.00428, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00428\n",
      "\n",
      "Epoch 49: loss improved from 0.00428 to 0.00425, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00425\n",
      "\n",
      "Epoch 51: loss improved from 0.00425 to 0.00422, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 52: loss improved from 0.00422 to 0.00414, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00414\n",
      "\n",
      "Epoch 56: loss improved from 0.00414 to 0.00405, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00405\n",
      "\n",
      "Epoch 58: loss improved from 0.00405 to 0.00400, saving model to ../result\\lstm_gru_ema\\58\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 59: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 60: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 61: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 62: loss did not improve from 0.00400\n",
      "\n",
      "Epoch 63: loss did not improve from 0.00400\n",
      "Epoch 63: early stopping\n",
      "60th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10234, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.10234 to 0.03229, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.03229 to 0.02180, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02180 to 0.01919, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.01919 to 0.01762, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.01762 to 0.01614, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01614 to 0.01482, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01482 to 0.01407, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01407 to 0.01347, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01347 to 0.01268, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01268 to 0.01159, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01159 to 0.01006, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01006 to 0.00924, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.00924 to 0.00857, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.00857 to 0.00806, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.00806 to 0.00760, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00760 to 0.00725, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00725 to 0.00710, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00710 to 0.00698, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00698 to 0.00676, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00676 to 0.00630, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00630 to 0.00606, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss did not improve from 0.00606\n",
      "\n",
      "Epoch 24: loss improved from 0.00606 to 0.00606, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00606 to 0.00596, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00596 to 0.00564, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00564 to 0.00550, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00550 to 0.00532, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00532 to 0.00530, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00530 to 0.00514, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00514\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00514\n",
      "\n",
      "Epoch 33: loss improved from 0.00514 to 0.00510, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss improved from 0.00510 to 0.00487, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00487 to 0.00469, saving model to ../result\\lstm_gru_ema\\59\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00469\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00469\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00469\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00469\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00469\n",
      "Epoch 40: early stopping\n",
      "61th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10806, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.10806 to 0.04223, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04223 to 0.02935, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02935 to 0.02355, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02355 to 0.02018, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02018 to 0.01768, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01768 to 0.01596, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01596 to 0.01481, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01481 to 0.01402, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01402 to 0.01334, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01334 to 0.01270, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01270 to 0.01190, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01190 to 0.01121, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01121 to 0.01100, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01100 to 0.01021, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01021 to 0.00964, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00964 to 0.00907, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00907 to 0.00748, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00748 to 0.00693, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00693 to 0.00629, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00629 to 0.00619, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00619 to 0.00601, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00601 to 0.00589, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00589 to 0.00551, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00551 to 0.00528, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss did not improve from 0.00528\n",
      "\n",
      "Epoch 27: loss improved from 0.00528 to 0.00526, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00526 to 0.00497, saving model to ../result\\lstm_gru_ema\\60\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00497\n",
      "\n",
      "Epoch 30: loss did not improve from 0.00497\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00497\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00497\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00497\n",
      "Epoch 33: early stopping\n",
      "62th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.10905, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.10905 to 0.04600, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.04600 to 0.02957, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02957 to 0.02534, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02534 to 0.02099, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02099 to 0.01964, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01964 to 0.01757, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01757 to 0.01647, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01647 to 0.01525, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01525 to 0.01450, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01450 to 0.01400, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01400 to 0.01282, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01282 to 0.01259, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01259 to 0.01179, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01179 to 0.01078, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01078 to 0.00947, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.00947 to 0.00869, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00869 to 0.00820, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00820 to 0.00772, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00772 to 0.00711, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00711 to 0.00685, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00685 to 0.00652, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00652 to 0.00625, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00625 to 0.00601, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00601 to 0.00589, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00589 to 0.00574, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00574 to 0.00573, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00573 to 0.00536, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00536 to 0.00527, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00527 to 0.00508, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss did not improve from 0.00508\n",
      "\n",
      "Epoch 32: loss did not improve from 0.00508\n",
      "\n",
      "Epoch 33: loss improved from 0.00508 to 0.00500, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 34: loss did not improve from 0.00500\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00500\n",
      "\n",
      "Epoch 36: loss improved from 0.00500 to 0.00486, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00486\n",
      "\n",
      "Epoch 40: loss improved from 0.00486 to 0.00479, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00479 to 0.00476, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00476 to 0.00461, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss improved from 0.00461 to 0.00461, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 44: loss improved from 0.00461 to 0.00460, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss did not improve from 0.00460\n",
      "\n",
      "Epoch 46: loss did not improve from 0.00460\n",
      "\n",
      "Epoch 47: loss improved from 0.00460 to 0.00445, saving model to ../result\\lstm_gru_ema\\61\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 48: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 50: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00445\n",
      "\n",
      "Epoch 52: loss did not improve from 0.00445\n",
      "Epoch 52: early stopping\n",
      "63th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11705, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11705 to 0.05566, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05566 to 0.02996, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.02996 to 0.02511, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02511 to 0.02073, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02073 to 0.01927, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.01927 to 0.01731, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01731 to 0.01689, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01689 to 0.01605, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01605 to 0.01473, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01473 to 0.01455, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01455 to 0.01376, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01376 to 0.01312, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01312 to 0.01242, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01242 to 0.01197, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01197 to 0.01081, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01081 to 0.00963, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.00963 to 0.00890, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00890 to 0.00856, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00856 to 0.00812, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00812 to 0.00800, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00800 to 0.00753, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00753 to 0.00724, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00724 to 0.00706, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss improved from 0.00706 to 0.00705, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 26: loss improved from 0.00705 to 0.00671, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss improved from 0.00671 to 0.00646, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 28: loss improved from 0.00646 to 0.00645, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss improved from 0.00645 to 0.00627, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 30: loss improved from 0.00627 to 0.00620, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00620 to 0.00600, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00600 to 0.00590, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00590\n",
      "\n",
      "Epoch 34: loss improved from 0.00590 to 0.00578, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss improved from 0.00578 to 0.00558, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 36: loss did not improve from 0.00558\n",
      "\n",
      "Epoch 37: loss improved from 0.00558 to 0.00551, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss did not improve from 0.00551\n",
      "\n",
      "Epoch 39: loss improved from 0.00551 to 0.00519, saving model to ../result\\lstm_gru_ema\\62\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 40: loss did not improve from 0.00519\n",
      "\n",
      "Epoch 41: loss did not improve from 0.00519\n",
      "\n",
      "Epoch 42: loss did not improve from 0.00519\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00519\n",
      "\n",
      "Epoch 44: loss did not improve from 0.00519\n",
      "Epoch 44: early stopping\n",
      "64th combination: \n",
      "\n",
      "--------------------------------------------------------------------\n",
      "\n",
      "Epoch 1: loss improved from inf to 0.11627, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 2: loss improved from 0.11627 to 0.05629, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 3: loss improved from 0.05629 to 0.03134, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 4: loss improved from 0.03134 to 0.02798, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 5: loss improved from 0.02798 to 0.02324, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 6: loss improved from 0.02324 to 0.02003, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 7: loss improved from 0.02003 to 0.01848, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 8: loss improved from 0.01848 to 0.01796, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 9: loss improved from 0.01796 to 0.01656, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 10: loss improved from 0.01656 to 0.01544, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 11: loss improved from 0.01544 to 0.01522, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 12: loss improved from 0.01522 to 0.01444, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 13: loss improved from 0.01444 to 0.01374, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 14: loss improved from 0.01374 to 0.01335, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 15: loss improved from 0.01335 to 0.01264, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 16: loss improved from 0.01264 to 0.01204, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 17: loss improved from 0.01204 to 0.01086, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 18: loss improved from 0.01086 to 0.00984, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 19: loss improved from 0.00984 to 0.00965, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 20: loss improved from 0.00965 to 0.00910, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 21: loss improved from 0.00910 to 0.00866, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 22: loss improved from 0.00866 to 0.00850, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 23: loss improved from 0.00850 to 0.00828, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 24: loss improved from 0.00828 to 0.00769, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 25: loss did not improve from 0.00769\n",
      "\n",
      "Epoch 26: loss improved from 0.00769 to 0.00727, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 27: loss did not improve from 0.00727\n",
      "\n",
      "Epoch 28: loss improved from 0.00727 to 0.00693, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 29: loss did not improve from 0.00693\n",
      "\n",
      "Epoch 30: loss improved from 0.00693 to 0.00667, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 31: loss improved from 0.00667 to 0.00657, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 32: loss improved from 0.00657 to 0.00637, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 33: loss did not improve from 0.00637\n",
      "\n",
      "Epoch 34: loss improved from 0.00637 to 0.00623, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 35: loss did not improve from 0.00623\n",
      "\n",
      "Epoch 36: loss improved from 0.00623 to 0.00608, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 37: loss improved from 0.00608 to 0.00591, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 38: loss improved from 0.00591 to 0.00566, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 39: loss did not improve from 0.00566\n",
      "\n",
      "Epoch 40: loss improved from 0.00566 to 0.00554, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 41: loss improved from 0.00554 to 0.00539, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 42: loss improved from 0.00539 to 0.00529, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 43: loss did not improve from 0.00529\n",
      "\n",
      "Epoch 44: loss improved from 0.00529 to 0.00522, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 45: loss improved from 0.00522 to 0.00520, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 46: loss improved from 0.00520 to 0.00499, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 47: loss did not improve from 0.00499\n",
      "\n",
      "Epoch 48: loss improved from 0.00499 to 0.00496, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 49: loss did not improve from 0.00496\n",
      "\n",
      "Epoch 50: loss improved from 0.00496 to 0.00494, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 51: loss did not improve from 0.00494\n",
      "\n",
      "Epoch 52: loss improved from 0.00494 to 0.00484, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 53: loss improved from 0.00484 to 0.00463, saving model to ../result\\lstm_gru_ema\\63\\best_lstm_m2m_model.keras\n",
      "\n",
      "Epoch 54: loss did not improve from 0.00463\n",
      "\n",
      "Epoch 55: loss did not improve from 0.00463\n",
      "\n",
      "Epoch 56: loss did not improve from 0.00463\n",
      "\n",
      "Epoch 57: loss did not improve from 0.00463\n",
      "\n",
      "Epoch 58: loss did not improve from 0.00463\n",
      "Epoch 58: early stopping\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#TODO: [layers, units, batch_size, dropout, look_back, is_ema]\n",
    "num_features = [1,2]\n",
    "layers = [[False, True, True],[True, False, True]]\n",
    "units = [[64]]\n",
    "config = [num_features, layers, units, [1, 2, 4, 8], [0.2],[10,12,15,17], [True]] \n",
    "df = read_data('../temp_data/influA_vietnam_last_10_days.csv', num_features=1)\n",
    "hist = LSTM_HyperParameter_Tuning(config, df, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "actual_infections = np.array([100, 150, 200, 180, 220, 250])\n",
    "forecast_infections = np.array([120, 160, 190, 210, 240, 260])\n",
    "\n",
    "# Calculate squared error\n",
    "squared_error = np.square(actual_infections - forecast_infections)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(actual_infections, forecast_infections, label='Actual vs. Forecast')\n",
    "plt.plot([0, max(actual_infections)], [0, max(actual_infections)], 'r--', label='Ideal 45-degree line')\n",
    "plt.plot(actual_infections, squared_error, 'g-', label='Squared Error')\n",
    "\n",
    "plt.xlabel('Actual Infections')\n",
    "plt.ylabel('Forecast Infections')\n",
    "plt.title('Actual vs. Forecast Infections with Squared Error')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Day'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_data('../temp_data/influA_vietnam_last_10_days.csv', num_features=1)\n",
    "df.diff().plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
